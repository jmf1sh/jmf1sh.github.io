
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
 <channel>
   <title>Posts on jonathan&#39;s blog</title>
   <link>https://jmf1sh.github.io/posts/</link>
   <description>Recent content in Posts on jonathan&#39;s blog</description>
   <generator>Hugo -- gohugo.io</generator>
   <language>en-us</language>
   <lastBuildDate>Wed, 14 Apr 2021 00:00:00 -0400</lastBuildDate>
   
       <atom:link href="https://jmf1sh.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
   
   
     <item>
       <title>Stochastic functions and the Giry monad</title>
       <link>https://jmf1sh.github.io/posts/2021-04-14-giry/</link>
       <pubDate>Wed, 14 Apr 2021 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2021-04-14-giry/</guid>
       <description>&lt;h2 id=&#34;stochastic-functions&#34;&gt;Stochastic functions&lt;/h2&gt;&lt;p&gt;A &lt;em&gt;function&lt;/em&gt; \(f\) between sets \(X\) and \(Y\) is a mapping\[\begin{aligned}f &amp;amp;:&amp;amp; X &amp;amp;\to&amp;amp; Y \crf &amp;amp;:&amp;amp; x &amp;amp;\mapsto&amp;amp; f(y)\end{aligned}\]and one of the most important properties of functions is that they &lt;em&gt;compose&lt;/em&gt;,i.e. if we have \(f: X \to Y\) and \(g: Y \to Z\) then we can constructa mapping \(g \circ f: X \to Z\) defined by \((g\circ f)(x) = g(f(x))\).When the sets involved have additional structure (topology, smooth structure,etc.), composition often preserves nice properties of the involved functions,e.g. continuity, differentiability, etc. This allows one to constructinteresting categories of &amp;ldquo;nice&amp;rdquo; functions between &amp;ldquo;nice&amp;rdquo; spaces.&lt;/p&gt;&lt;p&gt;What about the real world? In practice, very few &amp;ldquo;functions&amp;rdquo; are truefunctions in the mathematical sense. Among others, there are some obviousexamples of non-functions&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\(f(x)\) is a &lt;em&gt;measurement&lt;/em&gt;, and necessarily comes with error bars&lt;/li&gt;&lt;li&gt;\(f(x)\) is unknown but approximated by some known function \(\hat{f}(x)\)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In the first case, repeated measurements could produce different values, andwe would like to capture the &lt;em&gt;distribution&lt;/em&gt; of possible values upon repeatedmeasurements. In the second case, we would like to have some way to capturethe &lt;em&gt;uncertainty&lt;/em&gt; in the estimated values. So the question is, what kind ofmathematical objects are these not-quite-functions?&lt;/p&gt;&lt;p&gt;Let&amp;rsquo;s start with a simple example. Let&amp;rsquo;s suppose that we are measuring somefunction \(f: X \to \mathbb R\). Suppose that for repeated measurementsat a point \(x \in X\), the distribution of observed values is approximatelynormal with mean \(\mu(x)\) and standard deviation \(\sigma(x)\). So foreach \(x\), we have a random variable\[f(x) \sim \mathcal{N}(\mu(x), \sigma(x)).\]Fine. But what is \(f\) as a &lt;em&gt;map&lt;/em&gt;? Rewriting the above, we have\[f: x \mapsto \mathcal{N}(\mu(x), \sigma(x)) \in P(\mathbb R) \]where \(P(\mathbb R)\) denotes the set of probability measures on\(\mathbb R\). In other words, we can model the distribution of possiblemeasurements as a map\[ f: X \to P(\mathbb R). \]Taking inspiration from this, we can define a &lt;em&gt;stochastic function&lt;/em&gt; from \(X\)to \(Y\) to be a map \(X \to P(Y)\). Now here is the problem: how dostochastic functions &lt;em&gt;compose&lt;/em&gt;?&lt;/p&gt;&lt;h2 id=&#34;compostion-of-stochastic-functions&#34;&gt;Compostion of stochastic functions&lt;/h2&gt;&lt;p&gt;Suppose then that we have stochastic functions \(f: X \to P(Y)\) and\(g: Y \to P(Z)\). We would like to contruct \(g \circ f: X \to P(Z)\).Is there any reasonable way to do this?&lt;/p&gt;&lt;p&gt;First, let&amp;rsquo;s think about it from the point of view of sampling. Given\(x \in X\), \(f\) gives us a probability measure \(\mu_{f(x)}\) on\(Y\), from which we can sample some \(y \in Y\). Given a sampled \(y\),the stochastic map \(g\) produces a probability measure \(\mu_{g(y)}\) on\(Z\), but of course this depends on the sampled point \(y\). How do weproduce something that depends only on \(\mu_{f(x)}\) and not on theparticular sampled point \(y\)? We can take the expectation! We can definethe probability measure \(\mu_{(g \circ f)(x)}\) by defining what it doeson a measurable set \(A \subset Z\):\[ \mu_{(g \circ f)(x)}(A) := \int_Y \mu_{g(y)}(A) d\mu_{f(x)} \]To make this a little bit more explicit, we can take a special case and unwindthe definitions. Suppose that \(X = \mathbb{R}^m\), \(Y = \mathbb{R}^n\),and \(Z=\mathbb{R}^k\). Suppose that \(f\) can be represented as aconditional probability density \(p_f(y|x)\) and that \(g\) can likewisebe represented by a conditionall probability density \(p_g(z|y)\) (all takenwith respect to the usual Lebesgue measure). Thenwhat is \(p_{g\circ f}(z|x)\)? Let&amp;rsquo;s expand the right hand side of the abovedefinition:\[\begin{aligned}&amp;amp; \int_Y \mu_{g(y)}(A) d\mu_{f(x)} \cr=&amp;amp; \int_Y \left[\int_A p_g(z|y) dz \right] p_f(y|x) dy \cr=&amp;amp; \int_A \left[\int_Y p_g(z|y) p_f(y|x) dy \right] dz\end{aligned}\]from which we deduce that\[ p_{g \circ f}(z|x) = \int_Y p_g(z|y) p_f(y|x) dy. \]In other words, compostion of stochastic functions is just a fancy way to talkabout conditional probability!&lt;/p&gt;&lt;h2 id=&#34;the-giry-monad&#34;&gt;The Giry monad&lt;/h2&gt;&lt;p&gt;The above construction turns out to be &lt;em&gt;monadic&lt;/em&gt;. Recall that a monad on acategory \(\mathcal{C}\) is a tuple \((T, \eta, \mu)\) satisfying&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\(T\) is an endofunctor \(\mathcal{C} \to \mathcal{C}\)&lt;/li&gt;&lt;li&gt;\(\eta\) is a natural transformation \(1_{\mathcal{C}} \to T\)&lt;/li&gt;&lt;li&gt;\(\mu\) is a natural transformation \(T^2 \to T\)&lt;/li&gt;&lt;li&gt;\(\mu \circ T\mu = \mu \circ \mu T\) as natural transformations\(T^3 \to T\)&lt;/li&gt;&lt;li&gt;\(\mu \circ T \eta = \mu \circ \eta T = 1_T \)as natural transformations \(T \to T\)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;(Note carefully that now \(\mu\) refers to the multiplication operation,no longer a measure. In what follows below, we&amp;rsquo;ll use \(\nu\) to denotemeasures, to avoid overloading.)If you&amp;rsquo;ve never seen this definition before, it may seem a bit abstract. Butif we think about it in terms of function composition, it is &lt;em&gt;exactly&lt;/em&gt; thekind of structure that we have described above.&lt;/p&gt;&lt;p&gt;First, what is the functor \(T\) in our case? Given a reasonable space\(X\), we can take \(T(X)\) to be the set of probability measures on\(X\). To make this into a functor, we need to define how \(T\) actson maps \(f \in \mathrm{Hom}_{\mathcal{C}}(X, Y)\). There is anatural choice here, the &lt;em&gt;pushforward measure&lt;/em&gt;. Suppose we have\(f \in \mathrm{Hom}_{\mathcal{C}}(X, Y)\) and \(\nu \in T(X)\).Then the pushforward measure \(f_\ast\nu \in T(Y)\) is defined by\((f_\ast\nu)(A) := \nu(f^{-1}(A))\). This yields the desired lift\(Tf \in \mathrm{Hom}_{\mathcal{C}}(TX, TY)\).&lt;/p&gt;&lt;p&gt;Second, we need to define the embedding \(\eta: 1_\mathcal{C} \to T \).This is actually very simple: there is a natural map \(X \to TX\) definedby mapping \(x \in X\) to the Dirac measure \(\delta_x\) on \(X\).&lt;/p&gt;&lt;p&gt;And finally, we have to define the multiplication map \(\mu\). For a space\(X\), we need to define \(\mu_X: T(T(X)) \to T(X)\), where \(T\) denotesthe operation of taking probability measures, i.e. we need a map from theset of probability measures on the set of probability measures on \(X\), tothe set of probability measures on \(X\). This is effectively just anexpectation. Let \(M \in T(T(X))\) be a measure on the space of probabilitymeasures. We need to define a measure \(\mu M\) on \(X\). We can definethis for \(A \subset X\) as\[ (\mu M)(A) := \mathbb{E}_{\nu \sim M}\left[\nu(A) \right], \]i.e. the expected measure of \(A\) with respect to the distribution \(M\)on the space of probability measures.&lt;/p&gt;&lt;p&gt;Under suitable assumptions on spaces and maps under consideration, one canprove that the above operations are well-defined and indeed satisfy the monadlaws.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let \(\mathrm{Meas}\) be the category of measurable spaces andmeasurable maps. Then the operations \((T, \eta, \mu)\) described aboveare well-defined and satisfy the monad laws. We call this the &lt;em&gt;Giry monad&lt;/em&gt;.&lt;/p&gt;&lt;h2 id=&#34;the-kleisli-category-of-a-monad&#34;&gt;The Kleisli category of a monad&lt;/h2&gt;&lt;p&gt;Let&amp;rsquo;s recall monadic compostion. Assume that \((T, \eta, \mu)\) is a monadon some category \(\mathcal{C}\). For \(X, Y \in \mathrm{Ob}(\mathcal{C})\),it makes sense to talk about the set of maps\(\mathrm{Hom}_\mathcal{C}(X, T(Y))\), since \(T\) is an endofunctor.What if we have \(f \in \mathrm{Hom}_\mathcal{C}(X, T(Y))\) and\(g \in \mathrm{Hom}_\mathcal{C}(Y, T(Z))\)? The ordinary rules of categorydo not allow composing \(f\) and \(g\). A monad is exactly the kind ofstructure that we need to make the composition well-defined!&lt;/p&gt;&lt;p&gt;Recall that a natural transformation between functors \(F\) and \(G\) is afamily of maps \(F(X) \to G(X)\) parametrized by\(X \in \mathrm{Ob}(\mathcal{C})\) that makes the obvious diagram commute.In the monad case, this means that we have maps \(\eta_X: X \to T(X)\) and\(\mu_X: T(T(X)) \to T(X)\). In particular, \(\mu\) allows us to definea &lt;em&gt;monadic lift&lt;/em&gt; operation\[(-)^\ast: \mathrm{Hom}_\mathcal{C}(X, T(Y)) \to \mathrm{Hom}_\mathcal{C}(T(X), T(Y))\]by \(f^\ast := \mu_Y \circ Tf\). Then for functions\(f \in \mathrm{Hom}_\mathcal{C}(X, T(Y))\) and\(g \in \mathrm{Hom}_\mathcal{C}(Y, T(Z))\), we can define &lt;em&gt;monadiccomposition&lt;/em&gt;\[ g \circ_T f := g^\ast \circ f. \]Now comes the question: is monadic composition associative? For functions\(f\), \(g\), and \(h\), we have\[ h \circ_T (g \circ_T f) = h^\ast \circ g^\ast \circ f, \]and\[ (h \circ_T g) \circ_T f = (h^\ast \circ g)^\ast \circ f. \]So associativity amounts to the condition\((h^\ast \circ g)^\ast \stackrel{?}{=} h^\ast \circ g^\ast\).Explicitly, we suppose that \(g: Y \to T(Z)\) and \(h: Z \to T(W)\).Expanding definitions and using the monad laws, we have\[\begin{aligned}(h^\ast \circ g)^\ast&amp;amp;= \mu_W \circ T(\mu_W \circ Th \circ g) \cr&amp;amp;= \mu_W \circ T\mu_W \circ T^2 h \circ Tg \cr&amp;amp;= \mu_W \circ \mu_{T(W)} \circ T^2 h \circ Tg \cr&amp;amp;= \mu_W \circ Th \circ \mu_Z \circ Tg \cr&amp;amp;= (\mu_W \circ Th) \circ (\mu_Z \circ Tg) \cr&amp;amp;= h^\ast \circ g^\ast.\end{aligned}\]&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Theorem.&lt;/strong&gt; Let \(\mathcal{C}\) be a category and let \((T, \eta, \mu)\) bea monad on \(\mathcal{C}\). Then we define a new category \(\mathcal{C}_T\)as the category with$$ \mathrm{Ob}(\mathcal{C}_T) := \mathrm{Ob}(\mathcal{C}) $$$$ \mathrm{Hom}_{\mathcal{C}_T}(X, Y) := \mathrm{Hom}_{\mathcal{C}}(X, T(Y)) $$with identity function \(1_{X_T} := \eta_X\) and compostion defined by$$g \circ_T f := g^\ast \circ f.$$Then these objects and morphisms indeed form a category. We call this the&lt;em&gt;Kleisli category of the monad&lt;/em&gt;.&lt;/p&gt;&lt;h2 id=&#34;composition-of-stochastic-functions-is-monadic&#34;&gt;Composition of stochastic functions is monadic&lt;/h2&gt;&lt;p&gt;Now we can apply the Kleisli category construction to the Giry monad \(G\).Spelling things out explicitly, we have a category \(\mathcal{C}_G\) whoseobjects are measurable spaces, and whose morphisms are stochastic maps.Then composition of stochastic functions as we defined above is simply monadiccomposition as we defined it in the previous section.&lt;/p&gt;&lt;p&gt;Let&amp;rsquo;s spell it outexplicitly. Suppose that \(f: X \to P(Y)\) is a stochastic map, which wecan think of as being represented by a probability density \(p_f(y|x)\).What is the monadic lift of \(f\)? This is a map \(P(X) \to P(Y)\).How does it act on a measure \(\nu_X \in P(X)\) represented by aprobability density \(p_{\nu_X}(x)\)? I.e. how do we combine\(p_f(y|x)\) and \(p_{\nu_X}(x)\) to produce a probability density\(p(y)\) on \(Y\)? The answer should be obvious, so let&amp;rsquo;s see how it followsfrom the Kleisli construction.&lt;/p&gt;&lt;p&gt;Recall that the Giry monad acts on functions by taking the pushfoward measure,and that the monad multiplication \(\mu\) is the operation of takingexpectation. If we have a function \(h: Y \to \mathbb R\), then itsexpectation with respect to the monadic lift\(f^\ast := \mu_Y \circ f_\ast \nu_X\) is\[\begin{aligned}&amp;amp;\int_Y h(y) d(\mu_Y \circ f_\ast \nu_X) \cr&amp;amp;= \int_{P(Y)} \left[\int_Y h(y) d\nu \right] d(f_\ast \nu_X)\end{aligned}\]The expression in the square brackets can the thought of as a function\(\tilde{h}: P(Y) \to \mathbb R\) mapping a measure \(\nu\) to theexpectation of \(h\) with respect to \(\nu\). Rewriting and using the changeof variables formula, we have\[\begin{aligned}&amp;amp; \int_{P(Y)} \left[\int_Y h(y) d\nu \right] d(f_\ast \nu_X) \cr&amp;amp;= \int_X \tilde{h} \circ f d\nu_X \cr&amp;amp;= \int_X \tilde{h}(p_f(-|x)) p_{\nu_X}(x) dx\end{aligned}\]What does the integrand look like in coordinates? By definition,\(\tilde{h}(p_f(-|x))\) is just the expectation of \(h\) with respect tothe measure on \(Y\) defined by the density \(p_f(y|x)\), i.e.\[ \tilde{h}(p_f(-|x)) = \int_Y h(y) p_f(y|x) dy\]Combining this with with the above calculation, we see that\(\mu_Y \circ f_\ast \nu_X\) is the map\[ f^\ast: p_{\nu_X}(x) \mapsto \int_X p_f(y|x) p_{\nu_X}(x)dx \]In other words, the monadic lift operation is simply the operation that,given a conditional probability \(p(y|x)\) and an unconditional probability\(p(x)\) on \(X\), and produces an unconditional probability density\(p(y)\) on \(Y\) by integrating over \(X\).&lt;/p&gt;&lt;p&gt;Now suppose that we have stochastic functions \(f: X \to P(Y)\) and\(g: Y \to P(Z)\) represented by conditional probability densities\(p(y|x)\) and \(p(z|y)\). Then we can compute that the monadic composition\( g^\ast \circ f: X \to P(Z)\) is represented by the probability density\[ p(z|x) = \int_Y p(z|y) p(y|x) dx, \]so we find that the previously defined composition of stochastic functionscoincides with monadic composition with respect to the Giry monad.&lt;/p&gt;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Pushforward_measure&#34;&gt;Pushforward measure&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Natural_transformation&#34;&gt;Natural transformation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Monad_(category_theory)&#34;&gt;Monad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Kleisli_category&#34;&gt;Kleisli category&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://ncatlab.org/nlab/show/Giry+monad&#34;&gt;Giry monad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://golem.ph.utexas.edu/category/2014/10/where_do_probability_measures.html&#34;&gt;Where do probability measures come from?&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Variational autoencoders</title>
       <link>https://jmf1sh.github.io/posts/2018-12-24-vae/</link>
       <pubDate>Mon, 24 Dec 2018 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2018-12-24-vae/</guid>
       <description>&lt;p&gt;The following is a summary of some of the results of &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34; title=&#34;Autoencoding variational Bayes&#34;&gt;KW2013&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;evidence-lower-bound&#34;&gt;Evidence lower bound&lt;/h2&gt;&lt;p&gt;Suppose we have a probability space \(X\) from which we can sample, but whoseprobability density \(p(x)\) is unknown. How can we try to estimate \(p(x)\)?Imagine that \(X\) is the set of all possible natural images, or the set of allEnglish sentences. How do we assign probabilities to such objects?&lt;/p&gt;&lt;p&gt;We can try to model \(X\) as follows. Let&amp;rsquo;s suppose that there is some generativeprocess \(Z \to X\) from some &lt;em&gt;latent variable&lt;/em&gt; \(z\). We assume the following&lt;/p&gt;&lt;ul&gt;&lt;li&gt;There is some process \(Z \to X\) with &lt;em&gt;tractable&lt;/em&gt; condtional density\(p(x|z)\)&lt;/li&gt;&lt;li&gt;There is some tractable prior \(p(z)\)In this setup, we are free to choose \(p(z)\) and \(p(x|z)\). However, once we havefixed these densities, the posterior \(p(z|x)\) is completely determined by Bayes&#39;rule\[ p(z|x) = \frac{p(x|z)p(z)}{p(x)}, \]and is typically intractible.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;So once we have specified the prior \(p(z)\) and the decoder \(p(x|z)\), we have nofreedom to choose \(p(z|x)\). Furthermore, without access to \(p(x)\), we have noway to recover \(p(x|z)\) analytically. To get around this problem, we introduceanother probability density \(q(z|x)\), the &lt;em&gt;approximate posterior&lt;/em&gt;, which isintended to be a tractable approximation to the intractable \(p(z|x)\). We canquantify the difference between the true posterior and approximate posteriorwith the Kullback-Leiber divergence,&lt;/p&gt;&lt;p&gt;\[\begin{aligned}&amp;amp; D_{KL}(q(z|x)||p(z|x)) \cr&amp;amp;= E_{z \sim q(z|x)}\left(\frac{\log q(z|x)}{\log p(z|x)}\right) \cr&amp;amp;=E_{z \sim q(z|x)}\left(\log q(z|x)-\log p(z|x)\right) \cr&amp;amp;=E_{z \sim q(z|x)}\left(\log q(z|x)-\log p(x,z)+\log p(x)\right) \cr&amp;amp;=E_{z \sim q(z|x)}\left(\log q(z|x)-\log p(x|z) - \log p(z) +\log p(x)\right) \cr&amp;amp;=\log p(x)  + D_{KL}(q(z|x)||p(z)) - E_{z \sim q(z|x)}\left(\log p(x|z) \right)\end{aligned}\]&lt;/p&gt;&lt;p&gt;Rearranging this expression, we have&lt;/p&gt;&lt;p&gt;\[ \log p(x) = D_{KL}(q(z|x)||p(z|x)) + L \]&lt;/p&gt;&lt;p&gt;where \(L\) is the &lt;em&gt;variational lower bound&lt;/em&gt;,&lt;/p&gt;&lt;p&gt;\[ L = -D_{KL}(q(z|x)||p(z)) + E_{z \sim q(z|x)}(\log p(x|z)) \]&lt;/p&gt;&lt;p&gt;Since the Kullback-Leibler divergence is non-negative, we can we obtain the&lt;em&gt;evidence lower bound&lt;/em&gt; (ELBO)&lt;/p&gt;&lt;p&gt;\[ \log p(x) \geq -D_{KL}(q(z|x)||p(z)) + E_{z \sim q(z|x)}(\log p(x|z)) \]&lt;/p&gt;&lt;p&gt;This inequality is true for &lt;em&gt;any&lt;/em&gt; choice of \(p(z)\), \(q(z|x)\), and \(p(x|z)\). Thisgives us a natural optimization objective. Given a sample from \(X\), we typicallytry to maximize the likelihood of the observed data. Since the intractible\(\log p(x)\) is bounded by ELBO, we can maximize the ELBO as a proxy for the truelog-likelihood.&lt;/p&gt;&lt;h2 id=&#34;reparametrization-trick&#34;&gt;Reparametrization trick&lt;/h2&gt;&lt;p&gt;The second term in the RHS of ELBO is an expectation over \(z \sim q(z|x)\).Suppose that our model \(q(z|x)\) depends differentiably on some parameters\(\phi\). The expectation can be approximated by taking a sample of \(z\) values.The question is, can we make this expression &lt;em&gt;differentiable&lt;/em&gt; in \(\phi\)?Differentiability is a necessary conditon to be able to solve this problem usinggradient descent/ascent.&lt;/p&gt;&lt;p&gt;To obtain a differentiable expression, we assume that there is some &lt;em&gt;fixed&lt;/em&gt;random variable \(\epsilon\), and that \(z\) is a &lt;em&gt;deterministic&lt;/em&gt; function of\(\epsilon\) and \(x\):\[ z = g_\phi(\epsilon, x) \]Then we have\[ \begin{aligned}E_{z \sim q(z|x)}[f(z)]&amp;amp;= \int f(z) q(z|x) dz \cr&amp;amp;= \int f(g_\phi(\epsilon, x)) p(\epsilon) d\epsilon\end{aligned} \]The latter expression can be approximated using a finite sample\(\epsilon \sim p(\epsilon)\), which is independent of \(\phi\), and therefore theapproximation will be differentiable in \(\phi\).&lt;/p&gt;&lt;p&gt;The mapping \(g_\phi: (x, \epsilon) \mapsto z\) can be interpreted as an&lt;em&gt;encoder&lt;/em&gt; from \(X\) to \(Z\).&lt;/p&gt;&lt;h2 id=&#34;variational-autoencoder&#34;&gt;Variational autoencoder&lt;/h2&gt;&lt;p&gt;By making a few simplifications, including the reparametrization trick above,we can reinterpret aforementioned ELBO optimization problem as an autoencoder.Let us consider the following setup:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\(p(\epsilon)\) is standard normal in \(d\) dimensions&lt;/li&gt;&lt;li&gt;\(p(z)\) is standard normal in \(d\) dimensionsdimensions&lt;/li&gt;&lt;li&gt;\(q(z|x)\) is determined implictly by\(z = \mu_\phi(x) + \sigma_\phi(x) \cdot \epsilon\) via the reparametrizationtrick&lt;/li&gt;&lt;li&gt;We have a &lt;em&gt;decoder&lt;/em&gt; map \(f_\theta: Z \to X\)&lt;/li&gt;&lt;li&gt;The conditional probability density \(p(x|z)\) is modeled as a Gaussiandistribution centered on \(f(z)\) with some fixed covariance matrix&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Then in this case, the RHS of ELBO can be approximated by an expression thatis &lt;em&gt;differentiable&lt;/em&gt; in \((\phi, \theta)\). The expectation term involving\(p(x|z)\) simplifies to the sample-wise (negative) MSE between \(x\) and \(f(z)\),i.e. it is a kind of reconstruction error, and the KL-divergence term acts as aregularizer for the latent embedding. In summary, under the abovesimplifcations, &lt;em&gt;maximizing ELBO corresponds to training and autoencoder with aregularization term that encourages the distribution of observed data in latentspace to be consistent with a fixed prior distribution&lt;/em&gt; \(p(z)\).&lt;/p&gt;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;KW2013: &lt;a href=&#34;https://arxiv.org/abs/1312.6114&#34; title=&#34;Autoencoding variational Bayes&#34;&gt;Autoencoding variational bayes&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Euler beta function and Dirichlet distribution</title>
       <link>https://jmf1sh.github.io/posts/2018-07-10-beta-function/</link>
       <pubDate>Tue, 10 Jul 2018 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2018-07-10-beta-function/</guid>
       <description>&lt;p&gt;Let&amp;rsquo;s remind ourselves how about the Euler beta function, defined as&lt;/p&gt;&lt;p&gt;\[ B(x,y) = \int_0^1 t^{x-1} (1-t)^{y-1} dt. \]&lt;/p&gt;&lt;p&gt;First, we will express \(B(x,y)\) in terms of the more familiar Gamma function,defined as&lt;/p&gt;&lt;p&gt;\[ \Gamma(x) = \int_0^\infty t^{x-1} e^{-t} dt. \]&lt;/p&gt;&lt;p&gt;First, we have&lt;/p&gt;&lt;p&gt;\[ \Gamma(x) \Gamma(y) = \int_0^\infty \int_0^\infty s^{x-1} t^{y-1} e^{-s-t} ds dt \]&lt;/p&gt;&lt;p&gt;Now, suppose we have a multinomial distribution over \(k\) classes with probabilites \(p_1, \ldots, p_k\). In for \(n\) trials, the probability of observing \(k_i\) instances of class \(i\) is given by&lt;/p&gt;&lt;p&gt;\[ P(n_1, \ldots, n_k) = {n \choose n_1, \ldots, n_k} \prod_i p_i^{n_i} \]&lt;/p&gt;&lt;p&gt;Suppose that initially the probabilities \(p_i\) are unknown, and we wish to infer them froma given observation of \(n\) trials. Using a conjugate prior, we can take the unknown probabilitesto follow the Dirichlet distribution&lt;/p&gt;&lt;p&gt;\[ P(p_1, \ldots, p_k) = C_\alpha \prod_i p_i^{\alpha_i-1} \]&lt;/p&gt;&lt;p&gt;(where the normalization constant \(C_\alpha\) can be computed explicitly in terms of thegeneralized beta function, or equivalently in terms of the Gamma function).Using Bayes&#39; theorem we have&lt;/p&gt;&lt;p&gt;\[\begin{aligned}P(\alpha | n_1, \ldots, n_k) &amp;amp;= C P(n_1, \ldots, n_k | \alpha) P(\alpha) \cr&amp;amp;= C&#39; \prod_i p_i^{n_i+\alpha_i-1}\end{aligned}\]&lt;/p&gt;&lt;p&gt;This gives a new Dirichlet distribution with \(\alpha_i\) replaced by \(\alpha_i+n_i\).Taking expectation values of the posterior we have&lt;/p&gt;&lt;p&gt;\[E[p_i] = \frac{n_i+\alpha_i}{n+\sum_i \alpha_i}\].&lt;/p&gt;&lt;p&gt;Taking the Jeffreys prior \(\alpha_i = 1/2\), we have finally&lt;/p&gt;&lt;p&gt;\[E[p_i] = \frac{n_i+1/2}{n+n/2}\].&lt;/p&gt;&lt;p&gt;Note that this assigns a non-zero value to \(p_i\) even in the case that \(n_i = 0\)!&lt;/p&gt;&lt;p&gt;For comparison, consider taking instead the estimate from maximum likelihood. We have&lt;/p&gt;&lt;p&gt;\[ \log L(p, n) = C + \sum_i n_i \log p_i. \]&lt;/p&gt;&lt;p&gt;Maximizing subject to the constraints \(\sum_i p_i = 1\), we have&lt;/p&gt;&lt;p&gt;\[ n_i / p_i = \lambda \]&lt;/p&gt;&lt;p&gt;for some Lagrange multiplier \(\lambda\), for all \(i\). Hence we obtain&lt;/p&gt;&lt;p&gt;\[ p_i = n_i / n \]&lt;/p&gt;&lt;p&gt;and note that in this case, we assign zero probability to any class which is not observed.So we see that the expected distribution derived though Bayesian inference is moreconservative than maximum likelihood, in the sense that zero probabilities are assignedonly in the limit of infinitely many trials.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Introduction to Reinforcement Learning</title>
       <link>https://jmf1sh.github.io/posts/2018-01-14-reinforcement-learning/</link>
       <pubDate>Sun, 14 Jan 2018 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2018-01-14-reinforcement-learning/</guid>
       <description>&lt;p&gt;I would like to record the basic formalism of reinforcement learning. Hopefully,this will lead to a post or series of posts giving a basic tensorflowimplementation of a simple deep reinforcement learning model. But first, we haveto know what problem we are trying to solve.&lt;/p&gt;&lt;p&gt;To begin, we have the following data (which are considered to be given as partof the problem):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;a set of states \(\mathcal{S}\)&lt;/li&gt;&lt;li&gt;for each state \(s \in \mathcal{S}\), a set \(\mathcal{A}_s\) of actions&lt;/li&gt;&lt;li&gt;for each state \(s\), a mapping \(t_s: \mathcal{A}_s \to \mathcal{S}\) evolvingthe system according to the chosen state&lt;/li&gt;&lt;li&gt;for each state \(s\), a reward function \(r_s: \mathcal{A}_s \to \mathbb{R}\)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In addition, we also introduce a &lt;em&gt;discount factor&lt;/em&gt; \(\gamma \in (0,1)\) as ameasure of ``impatience,&#39;&#39; with 0 representing infinite impatience and 1representing infinite patience. The importance of \(\gamma\) will become clearerbelow.&lt;/p&gt;&lt;p&gt;Now for a definition: a &lt;em&gt;policy&lt;/em&gt; \(\pi\) is a choice, for each state \(s\), of aprobability distribution on the set of actions \(\mathcal{A}_s\). Associated tothe above data, we also have&lt;/p&gt;&lt;ul&gt;&lt;li&gt;the set \(\mathcal{P}\) of policies associated with the states and actions&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now, consider a sequnce of actions \(a_0, a_1, \ldots\) starting from an initial state \(s_0\) transforming the system in a sequence of states \(s_0, s_1, \ldots\). Associated to this, we can define a total reward&lt;/p&gt;&lt;p&gt;\[ r_{\mathrm{total}} = r_0(s_0, a_0) + \gamma r(s_1, a_1) + \gamma^2 r(s_2, a_2) + \cdots\]&lt;/p&gt;&lt;p&gt;The weighting by \(\gamma\) will turn out to be very important shortly. Now recall that a policy \(\pi\) assigns a probability distribution to the viable actions, and therefore for a given policy \(\pi\) we can consider the expected value of the above quantity. We define the \(Q\)-function to be&lt;/p&gt;&lt;p&gt;\[ Q(s, a) = \max_{\pi} \mathbb{E}_\pi[r_{\mathrm{total}}] \]&lt;/p&gt;&lt;p&gt;From the definition, we see that \(Q\) measures the maximum possible expected reward starting from the initial state \(s\) and action \(a\). The importance of \(Q\) is clear&amp;ndash;if we know \(Q\), then we can find the best sequence of actions greedily: at each state \(s\), we simply choose an action \(a\) that maximizes \(Q(s,a)\).&lt;/p&gt;&lt;p&gt;Now comes the magic. From the definition of \(r_{\mathrm{total}}\) above, we have&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}Q(s,a) &amp;amp;= \max_{\pi} \mathbb{E}_\pi[r(s,a) + \gamma r(s_1, a_1) + \cdots] \cr&amp;amp;= r(s,a) + \gamma \max_\pi \mathbb{E}_\pi[r(s_1, a_1) + \gamma r(s_2, a_2) + \cdots] \cr&amp;amp;= r(s,a) + \gamma \max_{a&#39;} Q(t(a), a&#39;)\end{aligned} \]&lt;/p&gt;&lt;p&gt;This recursive relation is known as the &lt;em&gt;Bellman equation&lt;/em&gt;. To understand how tosolve this equation, let us introduce the space \(\mathcal{F}\) as follows:&lt;/p&gt;&lt;p&gt;\[ \mathcal{F} = { (s,a) \ | \ s \in \mathcal{S}, a \in \mathcal{A}_s } \]&lt;/p&gt;&lt;p&gt;Using the sup-norm, we obtain a Banach space of functions\(\mathcal{F} \to \mathbb{R}\). Let \(B\) be the (non-linear) operator on this spacedefined by&lt;/p&gt;&lt;p&gt;\[ B(q)(s,a) = r(s,a) + \gamma \max_{a&#39;} q(t(s,a), a&#39;) \]&lt;/p&gt;&lt;p&gt;which is known as the &lt;em&gt;Bellman operator&lt;/em&gt;. As stated above, the desired\(Q\)-function satisfies the fixed-point equation \(Q = B(Q)\). Under reasonableassumptions, it can be verified that&lt;/p&gt;&lt;p&gt;\[| B(q_1) - B(q_2) | \leq \gamma | q_1 - q_2 | \]&lt;/p&gt;&lt;p&gt;making \[B\] into a contraction on the space of functions\(\mathcal{F} \to \mathbb{R}\), provided that \(\gamma \in (0,1)\). Therefore, bythe &lt;a href=&#34;https://en.wikipedia.org/wiki/Banach_fixed-point_theorem&#34;&gt;Banach fixed-point theorem&lt;/a&gt;,the Bellman equation has a unique solution \(Q^\ast\). Furthermore, thissolution can be constructed as follows: we take an initial function \(Q_0\), andtake \(Q^\ast\) to be the limit of the sequence defined by\(Q_{n+1} = B(Q_n)\).&lt;/p&gt;&lt;p&gt;Now, the basic ideas of deep reinforcement learning are the following&lt;/p&gt;&lt;ul&gt;&lt;li&gt;use a neural network to provide a reasonable finite-dimensional approximationto the aforementioned Banach space&lt;/li&gt;&lt;li&gt;using an approximate \(Q\), generate new sequences of actions and add these to arunning list of &lt;em&gt;experiences&lt;/em&gt;&lt;/li&gt;&lt;li&gt;periodically, take a random sample of past experiences and use these to updatethe \(Q\) function via the Bellman equation&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;For more details, see &lt;a href=&#34;https://www.nature.com/articles/nature14236&#34;&gt;Human-level control through deep reinforcement learning&lt;/a&gt;. I plan to follow up with more posts giving a basic implementation using &lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;tensorflow&lt;/a&gt; and &lt;a href=&#34;https://github.com/openai/gym&#34;&gt;OpenAI Gym&lt;/a&gt;.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Variance Stabilizing Transformations</title>
       <link>https://jmf1sh.github.io/posts/2017-12-19-variance-stabilizing/</link>
       <pubDate>Tue, 19 Dec 2017 13:49:09 +0100</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2017-12-19-variance-stabilizing/</guid>
       <description>&lt;p&gt;I want to record here a very interesting thing which I recently discovered, &lt;a href=&#34;https://en.wikipedia.org/wiki/Variance-stabilizing_transformation&#34;&gt;variance-stabilizing transformations&lt;/a&gt;. The idea is very simple: suppose we have a random variable \(x\), which follows a probability distribution which is parametrized solely by its mean \(\mu\), with variance \(var(x) = g(\mu)\) a known function of the mean.&lt;/p&gt;&lt;p&gt;Now, suppose we take the new random variable \(y = f(x)\), for some yet-to-be-determined function \(f\). Assuming that \(x\) is reasonably localized about its mean, we can make the approximation&lt;/p&gt;&lt;p&gt;\( f(x) = f(\mu + (x-\mu)) \approx f(\mu) + f&#39;(\mu)(x-\mu). \)&lt;/p&gt;&lt;p&gt;Then we have&lt;/p&gt;&lt;p&gt;\[\begin{aligned}E[y] &amp;amp;\approx f(\mu) \crvar(y) &amp;amp;\approx f&#39;(\mu)^2 var(x) \cr&amp;amp;= f&#39;(\mu)^2 g(\mu)\end{aligned}\]&lt;/p&gt;&lt;p&gt;Now, suppose we want to choose \(f(x)\) so that \(var(y) \approx 1\). Using the above approximation, we have \( f&#39;(\mu) = \frac{1}{\sqrt{g(\mu)}} \), which we can solve as&lt;/p&gt;&lt;p&gt;\( f(\mu) = \int \frac{1}{\sqrt{g(\mu)}} d\mu\)&lt;/p&gt;&lt;p&gt;Now let&amp;rsquo;s take the special case of the Poisson distrubution, where \(var(x) = \mu\). Then \(f(\mu) = \int \frac{1}{\sqrt \mu} d\mu = 2\sqrt{\mu}\). This is very nearly the &lt;a href=&#34;https://en.wikipedia.org/wiki/Anscombe_transform&#34;&gt;Anscombe transform&lt;/a&gt; \(x \mapsto 2\sqrt{x+3/8}\). The additional shift by \(3/8\) can be understood by doing a more careful analysis of the variance under the transformation.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Santalo Formula</title>
       <link>https://jmf1sh.github.io/posts/2015-09-15-santalo-formula/</link>
       <pubDate>Tue, 15 Sep 2015 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-09-15-santalo-formula/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Let \(M\) be a simple Riemannian manifold with boundary \(\partial M\). For \((x,v) \in SM\), let \(\tau(x,v)\) denote the exit time of the geodesic starting at \(x\) with tangent vector \(v\), i.e. \(\tau(x,v)\) is the (necessarily unique, and finite) time at which \(\exp_x(tv) \in \partial M\).&lt;/p&gt;&lt;p&gt;We let \(\partial_+(SM)\) denote the set&lt;/p&gt;&lt;p&gt;\[ \partial_+(SM) = { (x,v) \in SM \ | \ x \in \partial M, \langle v, \nu\rangle &amp;gt; 0 } \]&lt;/p&gt;&lt;p&gt;where \(\nu\) denotes the inward unit normal to \(\partial M\) in \(M\). The exponential map identifies \(SM\) with the set&lt;/p&gt;&lt;p&gt;\[ \Omega = { (x,v,t) \in \partial_+(SM) \times \mathbf{R} \ | \ 0 \leq t \leq \tau(x,v)  }, \]&lt;/p&gt;&lt;p&gt;via \((x,v,t) \mapsto \exp_x(tv)\). Let \(\Phi: \Omega \to M\) denote this diffeomorphism. Then we have, for all \(f \in C^\infty(SM)\)&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\int_{SM} f dvol(SM) &amp;amp;= \int_\Omega (\Phi^\ast f) (\Phi^\ast dvol(SM)) \cr&amp;amp;= \int_{\partial_+(SM)} \int_0^{\tau(x,v)} f(\phi_t(x,v)) \Phi^\ast dvol(SM).\end{aligned} \]&lt;/p&gt;&lt;p&gt;Therefore, we can compute integrals of functions over \(SM\) by integrating along geodesics, provided that we can cmopute \(\Phi^\ast dvol(SM)\). This is the content of the Santalo formula.&lt;/p&gt;&lt;p&gt;Theorem (Santalo formula). For all \(f \in C^\infty(SM)\), we have&lt;/p&gt;&lt;p&gt;\[ \int_{SM} f dvol(SM) = \int_{\partial_+(SM)} \int_0^{\tau(x,v)} f(\phi_t(x,v)) \langle v, \nu\rangle dt dvol(\partial(SM)) \]&lt;/p&gt;&lt;p&gt;Proof. Necessarily, we must have&lt;/p&gt;&lt;p&gt;\[ \Phi^\ast(dvol(SM)) = a(x,v) dt \wedge dvol(\partial(SM))), \]&lt;/p&gt;&lt;p&gt;for some function \(a(x,v)\). The reason we can assume that \(a\) is independent of \(t\) is that \(\Phi\) is defined via geodesic flow, and geodesic flow preserves the volume form on \(SM\). To compute the factor \(a(x,v)\), we just need to compute&lt;/p&gt;&lt;p&gt;\[ i_{\partial / \partial t} \Phi^\ast(dvol(SM)) = \Phi^\ast(i_{\Phi_\ast(\partial / \partial t)} dvol(SM)) \]&lt;/p&gt;&lt;p&gt;From the definition of \(\Phi\), we have that \(\Phi_\ast(\partial / \partial t)\) is the Reeb vector field on \(SM\), i.e. the vector field generating geodesic flow. Therefore, \(\Phi_\ast(\partial / \partial t)\) is equal, at a point \((x,v)\) to the horizontal lift of the vector \(v\). Therefore, using the definition of the induced volume form on a hypersurface of a Riemannian manifold, we find&lt;/p&gt;&lt;p&gt;\[ i_{\partial / \partial t} \Phi^\ast(dvol(SM)) = \langle v, \nu \rangle dvol(\partial(SM)) \]&lt;/p&gt;&lt;p&gt;where \(\nu\) is the inward pointing unit normal to \(\partial(SM)\) in \(SM\). This shows that \(a(x,v) = \langle v, \nu \rangle\) and completes the proof.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>The Index Form</title>
       <link>https://jmf1sh.github.io/posts/2015-09-11-index-form/</link>
       <pubDate>Fri, 11 Sep 2015 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-09-11-index-form/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Let \(f: [0,T] \times (-\epsilon, \epsilon) \to M\) be a family of parametrizedcurves in a Riemannian manifold \((M, g)\). To simplify this calculation, weassume that \(f(0,s) = p, f(T, s) = q\) for some \(p,q \in M\) and all\(s \in (-\epsilon, \epsilon)\). (This assumption is not necessary, but withoutit our variational formulae will have additional boundary terms.)&lt;/p&gt;&lt;p&gt;For convenience, set \(\dot f = \partial f / \partial t\) and \(f&#39; = \partial f / \partial s\). For each \(s \in (-\epsilon, \epsilon)\) we define the energy functional \(E = E(s)\) to be&lt;/p&gt;&lt;p&gt;\[ E(s) = \frac{1}{2} \int_0^T |\dot f|^2 dt. \]&lt;/p&gt;&lt;p&gt;The first variation is&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\frac{dE}{ds} &amp;amp;= \int_0^T \langle \nabla_{f&#39;} \dot f, \dot f \rangle dt \cr&amp;amp;= \int_0^T \langle \nabla_{\dot f} f&#39;, \dot f \rangle dt \cr&amp;amp;= -\int_0^T \langle f&#39;, \nabla_{\dot f}\dot f \rangle dt\end{aligned} \]&lt;/p&gt;&lt;p&gt;Set \(\gamma(t) := f(t,0)\) and \(X(t) = f&#39;(t)\) (thought of as a vector field supported on \(\gamma\)). Evaluating the above at \(s=0\) we obtain&lt;/p&gt;&lt;p&gt;\[ \left.\frac{dE}{ds}\right|_{s=0} = -\int_0^T \langle X, \nabla_{\dot \gamma} \dot \gamma \rangle dt, \]&lt;/p&gt;&lt;p&gt;which shows immediately that&lt;/p&gt;&lt;p&gt;Theorem. \(\gamma\) is a critical point of the energy functional if and only if \(\nabla_{\dot \gamma} \dot \gamma = 0\).&lt;/p&gt;&lt;p&gt;The second variation is&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\frac{d^2 E}{ds^2}&amp;amp;= -\int_0^T \langle \nabla_{f&#39;}f&#39;, \nabla_{\dot f}\dot f \rangle+ \langle f&#39;, \nabla_{f&#39;}\nabla_{\dot f}\dot f \rangle dt \cr&amp;amp;= -\int_0^T \langle \nabla_{f&#39;}f&#39;, \nabla_{\dot f}\dot f \rangle+ \langle f&#39;, \nabla_{\dot f}\nabla_{f&#39;}\dot f \rangle dt+ \langle f&#39;, R(f&#39;, \dot f)\dot f \rangle dt \cr&amp;amp;= -\int_0^T \langle \nabla_{f&#39;}f&#39;, \nabla_{\dot f}\dot f \rangle- \langle \nabla_{\dot f}f&#39;, \nabla_{f&#39;}\dot f \rangle dt+ \langle f&#39;, R(f&#39;, \dot f)\dot f \rangle dt \cr&amp;amp;= -\int_0^T \langle \nabla_{f&#39;}f&#39;, \nabla_{\dot f}\dot f \rangle- \langle \nabla_{\dot f} f&#39;, \nabla_{\dot f} f&#39;\rangle dt+ \langle f&#39;, R(f&#39;, \dot f)\dot f \rangle dt\end{aligned} \]&lt;/p&gt;&lt;p&gt;Assume now that \(\gamma\) is a geodesic, i.e. \(\nabla_{\dot \gamma} \dot \gamma = 0\). Then evaluating the above at \(s=0\), we obtain&lt;/p&gt;&lt;p&gt;\[ \frac{d^2 E}{ds^2} = \int_0^T |\nabla_{\dot \gamma} X|^2 - \langle X, R(X, \dot \gamma) \dot \gamma \rangle dt. \]&lt;/p&gt;&lt;p&gt;Definition. Let \(\gamma\) be a geodesic. The index form associated to variations \(X,Y\) of \(\gamma\) is&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}I(X,Y) &amp;amp;= \int_0^T \langle \nabla_{\dot \gamma} X, \nabla_{\dot \gamma} Y \rangle dt- \langle Y, R(X, \dot \gamma) \dot \gamma \rangle \cr&amp;amp;= -\int_0^T \langle Y, \nabla_{\dot \gamma}^2 X + R(X, \dot\gamma)\dot \gamma \rangle\end{aligned} \]&lt;/p&gt;&lt;p&gt;It follows from symmetries of the Riemann tensor that \(I(X,Y) = I(Y, X)\) and also \(I(X,X) = E&#39;&#39;\) as above.&lt;/p&gt;&lt;p&gt;Theorem. Suppose that \(X\) is the infinitesimal variation of a family of affine geodesics about a fixed geodesic \(\gamma\). Then&lt;/p&gt;&lt;p&gt;\[ \nabla_{\dot \gamma}^2 X + R(X, \dot\gamma)\dot\gamma = 0. \]&lt;/p&gt;&lt;p&gt;In particular, \(I(X, -) = 0\).&lt;/p&gt;&lt;p&gt;Proof. Let \(f(t,s)\) denote the family as above. By hypothesis, we have that \(\nabla_{\dot f} \dot f = 0\) for all \(s\), so that&lt;/p&gt;&lt;p&gt;\[ \nabla_{f&#39;} \nabla_{\dot f} \dot f = 0. \]&lt;/p&gt;&lt;p&gt;Commuting the derivatives using the curvature tensor, we have&lt;/p&gt;&lt;p&gt;\[ 0 = \nabla_{\dot f} \nabla_{f&#39;} \dot f + R(f&#39;, \dot f) \dot f. \]&lt;/p&gt;&lt;p&gt;Now use \(\nabla_{\dot f} f&#39; = \nabla_{f&#39;} \dot f\) and evaluate at \(s=0\) to obtain&lt;/p&gt;&lt;p&gt;\[ 0 = \nabla_{\dot \gamma}^2 X + R(X, \dot \gamma)\dot\gamma. \]&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Boundary Distance</title>
       <link>https://jmf1sh.github.io/posts/2015-09-03-boundary-distance/</link>
       <pubDate>Thu, 03 Sep 2015 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-09-03-boundary-distance/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Recently, I&amp;rsquo;ve been learning some topics related to machine learning, and especially manifold learning. These both fall under the general notion of inverse problems: given some mathematical object \(X\) (it could be a function \(f: A \to B\), or a Riemannian manifold \((M,g)\), or a probability measure \(d\mu\) on a space \(X\), etc.), can we effectively reconstruct \(X\) given only the information of some auxiliary measurements? What if we can only perform finitely many measurements? What if the measurements are noisy? Can we reconstruct \(X\) at least approximately? Can we measure in some precise way, how close our approximate reconstruction is to the unknown object \(X\)? And so on, and so forth.&lt;/p&gt;&lt;p&gt;Anyway, this post is about a cute observation, which I was reminded of while reading a paper on the inverse Gel&amp;rsquo;fand problem. Let \(M\) be a compact manifold with smooth boundary \(\partial M\). Then with no additional data required, we have a Banach space \(L^\infty(\partial M)\) consisting of the essentially bounded measureable functions on the boundary. Since it is a Banach space, it comes with a complete metric \(d_\infty(f,g) := |f-g|_{L^\infty(\partial M)}\).&lt;/p&gt;&lt;p&gt;Now, suppose that \(g\) is a Riemannian metric on \(M\). Then we have the Riemannian distance function \(d_g(x,y)\) which is defined to be the infimum of arclengths of all smooth paths connecting \(x\) and \(y\). For any \(x \in M\), we obtain a function \(r_x \in L^\infty(\partial M)\) defined by&lt;/p&gt;&lt;p&gt;\[ r_x(z) = d_g(x,z), \forall z \in \partial M. \]&lt;/p&gt;&lt;p&gt;This gives a map \(\phi_g: M \to L^\infty(\partial M)\), defined by \(x \mapsto r_x\).&lt;/p&gt;&lt;p&gt;Theorem. Suppose that for any two distinct \(x,y \in M\), there is a unique length-minimizing geodesic connecting \(x\) and \(y\). Then \(\phi_g: M \to L^\infty(\partial M)\) is an isometric embedding, i.e. \(d_g(x,y) = d_\infty(r_x, r_y)\) for all \(x,y \in M\).&lt;/p&gt;&lt;p&gt;Proof. Let \(x,y\) be distinct and let \(\gamma\) be the unique geodesic from \(x\) to \(y\). For any point \(z\) on the boundary, we have&lt;/p&gt;&lt;p&gt;\[ |d_g(x,z) - d_g(y,z)| \leq d_g(x,y). \]&lt;/p&gt;&lt;p&gt;which is the triangle inequality. Now let \(\gamma\) be the unique geodesic from \(x\) to \(y\), and extend \(\gamma\) until it hits some boundary point \(z_\ast\). Then since \(x,y,z_\ast\) all lie on a length-minimizing geodesic, we have&lt;/p&gt;&lt;p&gt;\[ d_g(x,z_\ast) - d_g(y,z_\ast) = d_g(x,y). \]&lt;/p&gt;&lt;p&gt;Therefore, the bound above is always saturated, and we find&lt;/p&gt;&lt;p&gt;\[ \sup_{z \in \partial M} |d_g(x,z) - d_g(y,z)| = d_g(x,y). \]&lt;/p&gt;&lt;p&gt;But the expression on the left is nothing but the \(L^\infty(\partial M)\)-norm of \(r_x-r_y\), so the theorem is proved.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Hamilton-Jacobi equation and Riemannian distance</title>
       <link>https://jmf1sh.github.io/posts/2015-08-31-hamilton-jacobi-distance/</link>
       <pubDate>Mon, 31 Aug 2015 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-08-31-hamilton-jacobi-distance/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Consider the cotangent bundle \(T^\ast X\) as a symplectic manifold with canonical symplectic form \(\omega\). Consider the Hamilton-Jacobi equation&lt;/p&gt;&lt;p&gt;\[ \frac{\partial S}{\partial t} + H(x, \nabla S) = 0, \]&lt;/p&gt;&lt;p&gt;for the classical Hamilton function \(S(x,t)\). Setting \(x=x(t), p(t) = (\nabla S)(x(t), t)\) one sees immediately from the method of characteristics that this PDE is solved by the classical action&lt;/p&gt;&lt;p&gt;\[ S(x,t) = \int_0^t (p \dot{x} - H) ds, \]&lt;/p&gt;&lt;p&gt;where the integral is taken over the solution \((x(s),p(s))\) of Hamilton&amp;rsquo;s equations with \(x(0)=x_0\) and \(x(t) = x\). The choice of basepoint \(x_0\) involves an overall additive constant of \(S\), and really this solution is only valid in some neighbourhood \(U\) of \(x_0\). (Reason: \(S\) is in general multivalued, as the differential &amp;ldquo;\(dS\)&amp;rdquo; is closed but not necessarily exact.)&lt;/p&gt;&lt;p&gt;Now consider the case where \(X\) is Riemannian, with Hamiltonian \(H(x,p) = \frac{1}{2} |p|^2\). The solutions to Hamilton&amp;rsquo;s equations are affinely parametrized geodesics, and by a simple Legendre transform we have&lt;/p&gt;&lt;p&gt;\[ S(x, t) = \frac{1}{2} \int_0^t |\dot x|^2 ds \]&lt;/p&gt;&lt;p&gt;where the integral is along the affine geodesic with \(x(0) = x_0\) and \(x(t) = x\). Since \(x(s)\) is a geodesic, \(|\dot x(s)|\) is a constant (in \(s\)) and therefore&lt;/p&gt;&lt;p&gt;\[ S(x, t) = \frac{t}{2} |\dot x(0)|^2. \]&lt;/p&gt;&lt;p&gt;Now consider the path \(\gamma(s) = x(|\dot x(0)|^{-1}s)\). This is an affine geodesic with \(\gamma(0) = x_0\), \(\gamma(|\dot x(0)|t) = x\) and \(|\dot \gamma| = 1\). Therefore, the Riemannian distance between \(x_0\) and \(x\) (provided \(x\) is sufficiently close to \(x_0\)) is&lt;/p&gt;&lt;p&gt;\[ d(x_0, x) = |\dot x(0)| t. \]&lt;/p&gt;&lt;p&gt;Combining this with the previous calculation, we see that&lt;/p&gt;&lt;p&gt;\[ S(x, t) = \frac{1}{2t} d(x_0, x)^2. \]&lt;/p&gt;&lt;p&gt;Now insert this back into the Hamilton-Jacobi equation above. With a bit of rearranging, we have the following.&lt;/p&gt;&lt;p&gt;Theorem. Let \(x_0\) denote a fixed basepoint of \(X\). Then for all \(x\) in a sufficiently small neighborhood \(U\) of \(x_0\), the Riemannian distance function satisfies the Eikonal equation&lt;/p&gt;&lt;p&gt;\[ |\nabla_x d(x_0, x)|^2 = 1. \]&lt;/p&gt;&lt;p&gt;Now, for convenience set \(r(x) = d(x_0, x)\). Then \(|\nabla r|^2 = 1\), from which we obtain (by differentiating twice and contracting)&lt;/p&gt;&lt;p&gt;\[ g^{ij} g^{kl}\left(\nabla_{lki} r \nabla_j r + \nabla_{ki}r \nabla_{lj} r\right) = 0.\]&lt;/p&gt;&lt;p&gt;Quick calculation shows that&lt;/p&gt;&lt;p&gt;\[ \nabla_{lki} r = \nabla_{ilk} r - \left.R_{li}\right.^{b}_k \nabla_b r \]&lt;/p&gt;&lt;p&gt;Therefore, tracing over \(l\) and \(k\) we obtain&lt;/p&gt;&lt;p&gt;\[ g^{lk} \nabla_{lki} r = \nabla_i ( \Delta r) + Rc(\nabla r, -) \]&lt;/p&gt;&lt;p&gt;Plugging this back into the equation derived above, we have&lt;/p&gt;&lt;p&gt;\[ \nabla r \cdot \nabla(\Delta r) + Rc(\nabla r, \nabla r) + |Hr|^2 = 0, \]&lt;/p&gt;&lt;p&gt;where \(Hr\) denotes the Hessian of \(r\) regarded as a 2-tensor. Now, using \(r\) as a local coordinate, it is easy to see that \(\partial_r = \nabla r\) (as vector fields). So we can rewrite this identity as&lt;/p&gt;&lt;p&gt;\[ \partial_r (\Delta r) + Rc(\partial_r, \partial_r) + |Hr|^2 = 0. \]&lt;/p&gt;&lt;p&gt;Now, we can get a nice result out of this. First, note that the Hessian \(Hr\) always has at least one eigenvalue equal to zero, because the Eikonal equation implies that \(Hr(\partial_r, -)=0\). Let \(\lambda_2, \dots, \lambda_n\) denote the non-zero eigenvalues of \(Hr\). We have&lt;/p&gt;&lt;p&gt;\[ |Hr|^2 = \lambda_2^2 + \dots + \lambda_n^2, \]&lt;/p&gt;&lt;p&gt;while on the other hand&lt;/p&gt;&lt;p&gt;\[ |\Delta r|^2 = (\lambda_2 + \dots + \lambda_n)^2 \]&lt;/p&gt;&lt;p&gt;By Cauchy-Schwarz, we have&lt;/p&gt;&lt;p&gt;\[ |\Delta r|^2 \leq (n-1)|Hr|^2 \]&lt;/p&gt;&lt;p&gt;Proposition. Suppose that the Ricci curvature of \(X\) satisfies \(Rc \geq (n-1)\kappa\), and let \(u = (n-1)(\Delta r)^{-1}\). Then&lt;/p&gt;&lt;p&gt;\[ u&#39; \geq 1 + \kappa u^2. \]&lt;/p&gt;&lt;p&gt;Proof. From preceding formulas, \(|Hr|^2\) can be expressed in terms of the Ricci curvature and the radial derivative of \(\Delta r\). On the other hand, \(|\Delta|^2\) is bounded above by \((n-1) |Hr|^2\). The claimed inequality then follows from simple rearrangement.&lt;/p&gt;&lt;p&gt;Now, the amazing thing is that this deceptively simple inequality is the main ingredient of the Bishop-Gromov comparison theorem. The Bishop-Gromov comparison theorem, in turn, is the main ingredient of the proof of Gromov(-Cheeger) precompactness. I hope to discuss these topics in a future post.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical partition function</title>
       <link>https://jmf1sh.github.io/posts/2015-08-18-classical-partition-function/</link>
       <pubDate>Tue, 18 Aug 2015 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-08-18-classical-partition-function/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Let \((M, \omega)\) be a symplectic manifold of dimension \(2n\), and let \(H: M \to \mathbf{R}\) be a classical Hamiltonian. The symplectic form \(\omega\) allows us to define a measure on \(M\), given by integration against the top form \(\omega^n / n!\). We will denote this measure by \(d\mu\).&lt;/p&gt;&lt;p&gt;We imagine that \((M, \omega, H)\) represents some classical mechanical system. We suppose that the dynamics of this dynamical system are very complicated, e.g. some system of \(10^{23}\) particles. The system is so complicated that not only can we not solve the equations of motion exactly, and even if we could, their solutions might be so complicated that we can&amp;rsquo;t expect to learn very much from them.&lt;/p&gt;&lt;p&gt;So instead, we ask statistical questions. Imagine that we cannot measure the state of the system exactly (e.g. particles in a box), so we try to guess a probability distribution \(\rho(x,p,t)\) on \(M\) indicating that at time \(t\) the system has probability \(\rho(x,p,t) d\mu\) of being in the state \((x,p)\). Obviously, \(\rho\) should satisfy the constraint \(\int_M \rho d\mu = 1\).&lt;/p&gt;&lt;p&gt;How does \(\rho\) evolve in time? We know that the system obeys Hamilton&amp;rsquo;s equations,&lt;/p&gt;&lt;p&gt;\[ (\dot x, \dot p) = X_H = (\partial H / \partial p, -\partial H / \partial x) \]&lt;/p&gt;&lt;p&gt;in local Darboux coordinates. Therefore, a particle located at \((x,p)\) in phase space at time \(t\) will be located at \((x,p)+X_H dt\) in phase space at time \(t+dt\). Therefore, the probability that a particle is at point \((x,p)\) at time \(t+dt\), should be equal to the probability that the particle is at point \((x,p)-X_H dt\) at time \(t\). Therefore, we have&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \rho}{\partial t} = \frac{\partial H}{\partial x} \frac{\partial \rho}{\partial p} - \frac{\partial H}{\partial p} \frac{\partial \rho}{\partial x} = {H, \rho} \]&lt;/p&gt;&lt;p&gt;Given a probability distribution \(\rho\), the entropy is defined to be&lt;/p&gt;&lt;p&gt;\[ S[\rho] = -\int_M  \rho \log \rho d\mu. \]&lt;/p&gt;&lt;p&gt;(A version of) the second law of thermodynamics. For a given average energy \(U\), the system assumes a distribution of maximal possible entropy at thermodynamic equilibrium.&lt;/p&gt;&lt;p&gt;The goal now, is to determine what distribution \(\rho\) will maximize the entropy, subject to the constraints (for fixed \(U\))&lt;/p&gt;&lt;p&gt;\begin{aligned} \int_M H \rho d\mu &amp;amp;= U \\&lt;/p&gt;&lt;p&gt;\int_M \rho d\mu &amp;amp;= 1 \end{aligned}&lt;/p&gt;&lt;p&gt;Setting aside technical issues of convergence, etc., this variational problem is easily solved using the method of Lagrange multipliers. Introducing parameters \(\lambda_1, \lambda_2\), we consider the modified functional&lt;/p&gt;&lt;p&gt;\[ S[\rho, \lambda_1, \lambda_2, U] = \int_M\left(-\rho \log \rho +\lambda_1\rho +\lambda_2(H\rho)\right)d\mu -\lambda_1-\lambda_2 U. \]&lt;/p&gt;&lt;p&gt;Note that \(\partial S / \partial U = -\lambda_2\), and this is conventionally identified with (minus) the inverse temperature.&lt;/p&gt;&lt;p&gt;Taking the variation with respect to \(\rho\), we find&lt;/p&gt;&lt;p&gt;\[ 0= \frac{\delta S}{\delta \rho} = -\log \rho-1+\lambda_1+H\lambda_2\]&lt;/p&gt;&lt;p&gt;Therefore, \(rho\) is proportional to \(e^{-\beta H}\) where we have set \(\beta=-\lambda_2\). Define the partition function \(Z\) to be&lt;/p&gt;&lt;p&gt;\[ Z = \int_M e^{-\beta H} d\mu. \]&lt;/p&gt;&lt;p&gt;We therefore have proved (formally and heuristically only!):&lt;/p&gt;&lt;p&gt;Theorem. The probability distribution \(\rho\) assumed by the system at thermodynamic equilibrium is given by&lt;/p&gt;&lt;p&gt;\[  \rho = \frac{e^{-\beta H}}{Z} \]&lt;/p&gt;&lt;p&gt;where \(\beta &amp;gt; 0\) is a real parameter, called the inverse temperature.&lt;/p&gt;&lt;p&gt;Corollary. At thermodynamic equilibrium, the average energy is given by&lt;/p&gt;&lt;p&gt;\[ U = -\frac{\partial \log Z}{\partial \beta} , \]&lt;/p&gt;&lt;p&gt;and the entropy is given by&lt;/p&gt;&lt;p&gt;\[ S = \beta U + \log Z.\]&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>What is generalized geometry?</title>
       <link>https://jmf1sh.github.io/posts/2015-01-29-generalized-geometry/</link>
       <pubDate>Thu, 29 Jan 2015 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2015-01-29-generalized-geometry/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The following are my notes for a short introductory talk. References below are not intended to be comprehensive!&lt;/p&gt;&lt;p&gt;Math references:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Courant,  Dirac manifolds&lt;/li&gt;&lt;li&gt;Hitchin, Generalized Calabi-Yau manifolds&lt;/li&gt;&lt;li&gt;Gualtieri, Generalized complex geometry&lt;/li&gt;&lt;li&gt;Cavalcanti, New aspects of the ddc-lemma&lt;/li&gt;&lt;li&gt;Cavalcanti and Gualtieri, Generalized complex geometry and T-duality&lt;/li&gt;&lt;li&gt;Bailey and Gualtieri, Local analytic geometry of generalized complex structures&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Physics references:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Dijkgraaf, Gukov, Neitzke, Vafa, Topological M-theory as unification of form theories of gravity&lt;/li&gt;&lt;li&gt;Grana, Flux compactifications in string theory: a comprehensive review&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;what-is-geometry&#34;&gt;What is geometry?&lt;/h2&gt;&lt;p&gt;Before trying to define generalized geometry, we should first decide what we mean by ordinary geometry. Of course, this question doesn&amp;rsquo;t have a unique answer, so there are many ways to generalize the classical notions of manifolds and varieties. The viewpoint taken in generalized geometry is the following: the distinguishing feature of smooth manifolds is the existence of a tangent bundle&lt;/p&gt;&lt;p&gt;\[ TM \to M \]&lt;/p&gt;&lt;p&gt;which satisfies some nice axioms. The basic idea of generalized geometry is to replace the tangent bundle with some other vector bundle \(L \to M\), again satisfying some nice axioms. Different generalized geometries on \(M\) will correspond to different choices of bundle \(L \to M\), as well as auxiliary data compatible with \(L\) in some appropriate sense.&lt;/p&gt;&lt;p&gt;Definition. A Lie algebroid over \(M\) is a smooth vector bundle \(L \to M\) together with a vector bundle map \(a: L \to TM\) called the anchor map and a bracket \([\cdot, \cdot]: H^0(M, L) \otimes H^0(M, L) \to H^0(M, L)\) satisfying the following axioms:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;\([\cdot,\cdot]\) is  a Lie bracket on \(H^0(M, L)\)&lt;/li&gt;&lt;li&gt;\([X, fY] = f[X,Y] + a(X)f \cdot Y\) for \(X,Y \in H^0(M,L)\) and \(f \in H^0(M, \mathcal{O}_M)\)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Note that we can take \(L\) to be either a real or complex vector bundle. In the latter case the anchor map should map to the complexified tangent bundle.&lt;/p&gt;&lt;p&gt;Example 1. We can take \(L\) to be \(TM\) with anchor map the identity.&lt;/p&gt;&lt;p&gt;Example 2. Let \(\sigma\) be a Poisson tensor on \(M\). Then we define a bracket by \([X,Y] = \sigma(X,Y)\) and an anchor by \(X \mapsto \sigma(X, \cdot)\). This makes \(T^\ast M\) into a Lie algebroid.&lt;/p&gt;&lt;p&gt;Example 3. Let \(M\) be a complex manifold of and let \(L \subset TM \otimes \mathbf{C}\) be the sub-bundle of vectors spanned by \({\partial / \partial z_1, \dots, \partial / \partial z_n}\) in local holomorphic coordinates. Then \(L \to M\) is a (complex) Lie algebroid.&lt;/p&gt;&lt;h2 id=&#34;courant-bracket&#34;&gt;Courant Bracket&lt;/h2&gt;&lt;p&gt;We&amp;rsquo;d like to try to fit the preceding examples into a common framework. Let \(\mathbf{T}M = TM \oplus T^\ast M\). This bundle has a natural symmetric bilinear pairing given by&lt;/p&gt;&lt;p&gt;\[ \langle X \oplus \alpha, Y \oplus \beta \rangle = \frac{1}{2} \alpha(Y) + \frac{1}{2} \beta(X) \]&lt;/p&gt;&lt;p&gt;Note that this bilinear form is of split signature \((n,n)\). We define a bracket on sections of \(\mathbf{T}M\) by&lt;/p&gt;&lt;p&gt;\[ [X\oplus \alpha, Y\oplus \beta] = [X,Y] \oplus \left(L_X \beta + \frac{1}{2}(d \alpha(Y))- L_Y \alpha -\frac{1}{2} d( \beta(X)) \right ) \]&lt;/p&gt;&lt;p&gt;Note that this bracket is not a Lie bracket. We also have an anchor map \(a: \mathbf{T}M \to TM\) which is just the projection.&lt;/p&gt;&lt;p&gt;Let \(B\) be a 2-form on \(M\). Define an action of \(B\) on sections of \(\mathbf TM\) by&lt;/p&gt;&lt;p&gt;\[ X + \alpha \mapsto X + \alpha + i_X B \]&lt;/p&gt;&lt;p&gt;Proposition. This action preserves the Courant bracket if and only if \(B\) is closed.&lt;/p&gt;&lt;p&gt;This shows that the diffeomorphisms of \(M\) as a generalized manifold are large than the ordinary diffeomorphisms of \(M\). In fact is is the semidirect product of the diffeomorphism group of \(M\) with the vector space of closed 2-forms.&lt;/p&gt;&lt;h2 id=&#34;dirac-structures&#34;&gt;Dirac Structures&lt;/h2&gt;&lt;p&gt;Definition. A Dirac structure on \(M\) is an Lagrangian sub-bundle \(L \subset \mathbf{T}M\) which is closed under the Courant bracket.&lt;/p&gt;&lt;p&gt;Theorem (Courant). A Lagrangian sub-bundle \(L \subset \mathbf{T} M\) is a Dirac structure if and only if \(L \to M\) is a Lie algebroid over \(M\), with bracket induced by the Courant bracket and anchor given by projection.&lt;/p&gt;&lt;p&gt;Example 1. \(TM \subset \mathbf{T}M\).&lt;/p&gt;&lt;p&gt;Example 2. Take \(L\) to be the graph of a Poisson tensor.&lt;/p&gt;&lt;p&gt;Example 3. Take \(L\) to be the graph of a closed 2-form.&lt;/p&gt;&lt;h2 id=&#34;admissible-functions&#34;&gt;Admissible Functions&lt;/h2&gt;&lt;p&gt;We now let \(L \to M\) be a Dirac structure on \(M\).&lt;/p&gt;&lt;p&gt;Definition. A smooth function \(f\) on \(M\) is called admissible if there exists a vector field \(X_f\) such that \((X_f, df)\) is a section of \(L\).&lt;/p&gt;&lt;p&gt;The Poisson bracket is defined as follows. If \(f,g\) are admissible, then define&lt;/p&gt;&lt;p&gt;\[ \{f, g\} = X_f g. \]&lt;/p&gt;&lt;p&gt;It is easy to check from the definitions that the bracket on admissible functions is well-defined (independent of choice of \(X_f\)) and skew-symmetric. With a little bit of calculation, we find the following.&lt;/p&gt;&lt;p&gt;Proposition. The vector space of admissible functions is naturally a Poisson algebra, and moreover the natural bracket satisfies the Leibniz rule.&lt;/p&gt;&lt;h2 id=&#34;generalized-complex-structures&#34;&gt;Generalized Complex Structures&lt;/h2&gt;&lt;p&gt;Definition. A generalized complex structure is a skew endomorphism \(J\) of \(\mathbf T M\) such that \(J^2 = -1\) and such that the \(+i\)-eigenbundle is involutive under the Courant bracket.&lt;/p&gt;&lt;p&gt;Equivalently: A generalized complex structure is a (complex) Dirac structure \(L \subset \mathbf TM\) satisfying the condition \(L \cap \overline L = 0\).&lt;/p&gt;&lt;p&gt;Example 1. Let \(J\) be an ordinary complex structure on \(M\). Then the endomorphism&lt;/p&gt;&lt;p&gt;\[ \begin{bmatrix} -J &amp;amp; 0 \cr 0 &amp;amp; J^\ast \end{bmatrix} \]&lt;/p&gt;&lt;p&gt;defines a generalized complex structure on \(M\).&lt;/p&gt;&lt;p&gt;Example 2. Let \(\omega\) be a symplectic form on \(M\). Then the endomorphism&lt;/p&gt;&lt;p&gt;\[ \begin{bmatrix} 0 &amp;amp; -\omega^{-1} \cr \omega &amp;amp; 0 \end{bmatrix} \]&lt;/p&gt;&lt;p&gt;defines a generalized complex structure on \(M\).&lt;/p&gt;&lt;p&gt;Thus, generalized geometry gives a common framework for both complex geometry and symplectic geometry. Such a connection is exactly what is conjectured by mirror symmetry.&lt;/p&gt;&lt;p&gt;Example 3. Let \(J\) be a complex structure on \(M\) and let \(\sigma\) be a holomorphic Poisson tensor. Consider the subbundle \(L \subset \mathbf TM\) defined as the span of&lt;/p&gt;&lt;p&gt;\[ \frac{\partial}{\partial \bar z_1}, \dots, \frac{\partial}{\partial \bar z_n}, dz_1 - \sigma(dz_1), \dots, dz_n - \sigma(dz_n) \]&lt;/p&gt;&lt;p&gt;Then \(L\) defines a generalized complex structure on \(M\).&lt;/p&gt;&lt;p&gt;The last example shows that deformations of \(M\) as a generalized  complex manifold contain non-commutative deformations of the structure sheaf.  We also have the following theorem, which shows that there is an intimate relation between generalized complex geometry and holomorphic Poisson geometry.&lt;/p&gt;&lt;p&gt;Theorem (Bailey). Near any point of a generalized complex manifold, \(M\) is locally isomorphic to the product of a holomorphic Poisson manifold with a symplectic manifold.&lt;/p&gt;&lt;h2 id=&#34;generalized-kähler-manifolds&#34;&gt;Generalized Kähler Manifolds&lt;/h2&gt;&lt;p&gt;Let \((g, J, \omega)\) be a Kähler triple. The Kähler property requires that&lt;/p&gt;&lt;p&gt;\[ \omega = g J. \]&lt;/p&gt;&lt;p&gt;Let \(I_1\) denote the generalized complex structure induced by \(J\), and let \(I_1\) denote the generalized complex structure induced by the symplectic form \(\omega\). We have&lt;/p&gt;&lt;p&gt;\[ I_1 I_2 =\begin{bmatrix} - J &amp;amp; 0 \cr 0 &amp;amp; J^\ast \end{bmatrix}\begin{bmatrix} 0 &amp;amp; -\omega^{-1} \cr \omega &amp;amp; 0 \end{bmatrix}= \begin{bmatrix} 0 &amp;amp; g^{-1} \cr g &amp;amp; 0 \end{bmatrix} = I_2 I_1 \]&lt;/p&gt;&lt;p&gt;Definition. A generalized Kähler manifold is a manifold with two commuting generalized complex structure \(I_1, I_2\) such that the bilinear pairing \((I_1 I_2 u, v)\) is positive definite.&lt;/p&gt;&lt;p&gt;Theorem (Gualtieri). A generalized Kähler structure on \(M\) induces a Riemannian metric \(g\), two integrable almost complex structures \(J_\pm\) Hermitian with respect to \(g\), and two affine connections \(\nabla_\pm\) with skew-torsion \(\pm H\) which preserve the metric and complex structure \(J_\pm\). Conversely, these data determine a generalized Kähler structure which is unique up to a B-field transformation.&lt;/p&gt;&lt;p&gt;Thus the notion of generalized Kähler manifold recovers the bihermitian geometry investigated by physicists in the context of susy non-linear \(\sigma\)-models.&lt;/p&gt;&lt;h2 id=&#34;generalized-calabi-yau-manifolds&#34;&gt;Generalized Calabi-Yau Manifolds&lt;/h2&gt;&lt;p&gt;Definition. A generalized Calabi-Yau manifold is a manifold \(M\) together with a complex-valued differential form \(\phi\), which is either purely even or purely odd, which is a pure spinor for the action of \(Cl(\mathbf TM)\) and satisfies the non-degeneracy condition \((\phi, \bar \phi) \neq 0\).&lt;/p&gt;&lt;p&gt;Note that (by definition) \(\phi\) is pure if its annihilator is a maximal isotropic subspace. Let \(L \subset \mathbf TM\) be its annihilator. Then it is not hard to see that \(L\) defines a generalized complex structure on \(M\), so indeed a generalized Calabi-Yau manifold is in particular a generalized complex manifold.&lt;/p&gt;&lt;p&gt;Example. If \(M\) is a complex manifold with a nowhere vanishing holomorphic \((n,0)\) form, then it is generalized Calabi-Yau.&lt;/p&gt;&lt;p&gt;Example. If \(M\) is symplectic with symplectic form \(\omega\), then \(\phi = \exp(i\omega)\) gives \(M\) the structure of a generalized Calabi-Yau manifold.&lt;/p&gt;&lt;p&gt;If \((M, \phi)\) is generalized Calabi-Yau, then so is \((M, \exp(B) \phi)\) for any closed real 2-form \(B\). In the symplectic case, we obtain&lt;/p&gt;&lt;p&gt;\[ \phi = \exp(B+i\omega) \]&lt;/p&gt;&lt;p&gt;This explains the appearance of the \(B\)-field (or &amp;ldquo;complexified Kähler form&amp;rdquo;) in discussions of mirror symmetry.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Virasoro algebra from the free boson</title>
       <link>https://jmf1sh.github.io/posts/2014-12-11-virasoro-algebra-free-boson/</link>
       <pubDate>Thu, 11 Dec 2014 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-12-11-virasoro-algebra-free-boson/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Usual physics derivations of the Virasoro algebra from the free boson in two dimensions usually use some sort of regularization procedure to compute the central charge. Following these notes I&amp;rsquo;d like to give a purely algebraic calculation of the central charge.&lt;/p&gt;&lt;p&gt;Let \(A = \mathbf C[x_1, x_2, \dots]\) be the polynomial algebra in countably many generators. For an integer \(k &amp;gt; 0\), define a \(k\)-linear operator \(a_k\) on \(A\) by&lt;/p&gt;&lt;p&gt;\[ a_k = \frac{\partial}{\partial x_k}, \ k &amp;gt; 0 \]&lt;/p&gt;&lt;p&gt;Similarly, for \(k &amp;lt; 0\) we define \(a_k\) by multiplication:&lt;/p&gt;&lt;p&gt;\[ a_{-k} = k x_k, k &amp;gt; 0 \]&lt;/p&gt;&lt;p&gt;For \(k = 0\), we define \(a_0\) to be multiplication by some fixed complex number (which by abuse of notation we also denote by \(a_0\)).&lt;/p&gt;&lt;p&gt;Lemma. We have the commutation relation \([a_m, a_n] = m \delta_{m+n}\) as linear operators on \(A\).&lt;/p&gt;&lt;p&gt;For any monomial in the \(a_k\), we define normal ordering \(::\) to be the monomial obtained by reordering the terms so that the indices are increasing. (Mathematical interpretation: it is a section of the quotient map from the tensor algebra in the \(a_k\) to the symmetric algebra, defined by lexicographic order.) For example,&lt;/p&gt;&lt;p&gt;\[ :a_j a_k:\ = \left\{\begin{array}{rr}a_j a_k, &amp;amp; j \leq k \cra_k a_j, &amp;amp; j &amp;gt; k\end{array} \right. \]&lt;/p&gt;&lt;p&gt;Next we formally define a set of operators \(L_k\) by&lt;/p&gt;&lt;p&gt;\[ L_k = \frac{1}{2}\sum_j :a_j a_{k-j}: \]&lt;/p&gt;&lt;p&gt;Proposition. The \(L_k\) are well-defined as linear operators on \(A\).&lt;/p&gt;&lt;p&gt;Proof. For sufficiently large \(|j|\), at least one of \(j\) or \(k-j\) is positive, and hence \(:a_j a_{k-j}:\) contains a differentiation (on the right). Since any element \(f \in A\) is annihilated by all but finitely many of the differentiation operators \(\partial_j\), the formal expression \(L_k f\) contains only finitely many non-zero terms, and hence is well-defined.&lt;/p&gt;&lt;p&gt;Lemma. As operators on \(A\), we have \([a_k, L_n] = k a_{k+n}\).&lt;/p&gt;&lt;p&gt;Theorem. As operators on \(A\), we have&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n] = (m-n) L_{m+n} + \frac{1}{12} (m^3-m) \delta_{m+n} \]&lt;/p&gt;&lt;p&gt;Proof. Fix \(m,n\). For the sake of simplicity we will assume \(m \neq n\) and \(mn \neq 0\). (The other special cases can be treated by similar arguments.) By the same argument as the proof of the preceding proposition, for any fixed element \(f \in A\) there exists some \(N \gg 0\) such that&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n]f = [L_m^N, L_n] f \]&lt;/p&gt;&lt;p&gt;where \(L_m^N\) is the truncated operator&lt;/p&gt;&lt;p&gt;\[ L_m^N = \frac{1}{2}\sum_{|j| &amp;lt; N} :a_j a_{m-j}: \]&lt;/p&gt;&lt;p&gt;Let us compute (noting that since \(m \neq 0\), \(:a_j a_{m-j}: = a_j a_{m-j}\))&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}[L_m^N, L_n] &amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N} [a_j a_{m-j}, L_n] \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N} (m-j) a_j a_{m+n-j} + \frac{1}{2} \sum_{|j| &amp;lt; N}j a_{n+j} a_{m-j}\end{aligned} \]&lt;/p&gt;&lt;p&gt;Denote the two sums above by \(S_1\) and \(S_2\). It is clear that these should be related to the operator \(L_{m+n}\), but to see the exact relation we will have to normal order the terms. Let&amp;rsquo;s start with \(S_1\). Note that \(a_j a_{m+n-j}\) is already normal ordered, unless \(j &amp;gt; m+n-j\). Hence&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}S_1 &amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N} (m-j) :a_j a_{m+n-j}: +  \frac{1}{2} \sum_{m+n\lt2j\lt2N} (m-j) [a_j, a_{m+n-j}] \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N} (m-j) :a_j a_{m+n-j}: +  \frac{\delta_{m+n}}{2} \sum_{m+n\lt2j\lt2N} j(m-j) \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N} (m-j) :a_j a_{m+n-j}: +  \frac{\delta_{m+n}}{2} \sum_{0\lt j\lt N} j(m-j)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Similarly, we normal order the terms in \(S_2\):&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}S_2 &amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N}j :a_{n+j} a_{m-j}: -\frac{1}{2} \sum_{m-n\lt2j\lt2N}j [a_{m-j}, a_{n+j}] \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N}j :a_{n+j} a_{m-j}: -\frac{\delta_{m+n}}{2} \sum_{m\lt j\lt N}j (m-j) \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N}j :a_{n+j} a_{m-j}: -\frac{\delta_{m+n}}{2} \sum_{m\lt j\lt N}j (m-j) \cr&amp;amp;= \frac{1}{2} \sum_{|j| &amp;lt; N}j :a_{n+j} a_{m-j}: -\frac{\delta_{m+n}}{2} \sum_{m\lt j\lt N}j (m-j)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Hence we have&lt;/p&gt;&lt;p&gt;\[ S_1 + S_2 = \frac{1}{2} \sum_{|j| &amp;lt; N} (m-j) :a_j a_{m+n-j}: +  \frac{1}{2} \sum_{|j| &amp;lt; N}j :a_{n+j} a_{m-j}: + \frac{\delta_{m+n}}{2} \sum_{0\lt j\leq m} j(m-j)  \]&lt;/p&gt;&lt;p&gt;Now that everything is normal ordered, we can take the limit \(N \to \infty\) without fear. After a simple cancellation, and explicitly summing the last term using well-known formulas for sums of powers of integers, we obtain:&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n] = (m-n) L_{m+n} + \frac{1}{12} (m^3-m) \delta_{m+n} \]&lt;/p&gt;&lt;p&gt;For the usual conventions of the Virasoro algebra, this shows that this representation corresponds to central charge \(c=1\).&lt;/p&gt;&lt;p&gt;Remark. If we tried to take the limit \(N \to \infty\) in each of the terms \(S_1, S_2\) separately, before taking their sum, we would obtain a formal infinite constant \(\sum_{j} j(m-j)\). In any physics textbook, the author will simply zeta-regularize this sum to obtain a fininte result. However, the above calculation shows that this is not necessary. By taking care that each term in the expression \(S_1+S_2\) was normal-ordered, before taking the limit, we obtain only finite constants with no need to regularize. Zeta regularization certainly has its uses (for example in rigorous definitions of functional determinants), but as the above calculation shows, it can also be an unnecessary crutch that obscures the underlying mathematical phenomena.&lt;/p&gt;&lt;p&gt;Remark. There is an analogous calculation which shows that one obtains a Virasoro representation from affine Lie algebras. Physically, this corresponds to the WZW model. Roughly, the generators of the affine Lie algebra behave as an infinite set of harmonic oscillators, similar to the Heisenberg algebra above. Sometime in the future I may write a sequel to this post giving the details of this calculation.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>The basic idea of the quantum BV complex</title>
       <link>https://jmf1sh.github.io/posts/2014-05-14-quantum-bv-complex/</link>
       <pubDate>Wed, 14 May 2014 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-05-14-quantum-bv-complex/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. Theoriginal post can still be found&lt;a href=&#34;https://mathphysseminar.blogspot.com/2014/05/the-basic-idea-of-quantum-bv-complex.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;This post was originally written by &lt;a href=&#34;https://www.math.toronto.edu/dbutson/&#34;&gt;Dylan Butson&lt;/a&gt; (&lt;a href=&#34;https://arxiv.org/search/?searchtype=author&amp;amp;query=Butson%2C+D&#34;&gt;arxiv&lt;/a&gt;).&lt;/p&gt;&lt;p&gt;Let \(M\) be an oriented \(n\)-dimensional manifold and \(\mathfrak{X}^\bullet(M):=\Gamma(M,\wedge^{-\bullet} TM)\), so that \(\mathfrak{X}^\bullet(M)\) is concentrated in non-positive degree. Let \(\mu\in \Omega^n(M)\) a volume form on \(M\). Then interior product with \(\mu\) gives an isomorphism \(\vee\mu: \mathfrak{X}^k(M)\xrightarrow{\cong}\Omega^{n-k}(M)\). From this, we induce a degree 1 differential \(\Delta_\mu\) on \(\mathfrak{X}^\bullet(M)\) from the de Rham differential \(d\) on \(\Omega^\bullet(M)\), defined by \(\Delta_\mu= (\vee\mu)^{-1}\circ d\circ\vee\mu\), making \(\mathfrak{X}^\bullet(M)\) into a cochain complex isomorphic to \(\Omega^\bullet(M)[k]\); in particular \(H^k(\mathfrak{X})=H^{n+k}(\Omega)\).&lt;/p&gt;&lt;p&gt;If \(M\) is compact and connected, then \(H^0(\mathfrak{X})=H^n(\Omega)\) is one dimensional, and upon fixing a basis to identify \(H^0(\mathfrak{X})\xrightarrow{\cong}\mathbb{R}\), the quotient map gives a map \(\pi:C^\infty(M)\to \mathbb{R}\). We have the following:&lt;/p&gt;&lt;p&gt;Proposition Let \(1\in C^\infty(M)\) be the constant function taking the value \(1\). Then \([1]\in H^0(\mathfrak{X})\) is nontrivial and after choosing it as a basis the resulting map \(\pi:C^\infty(M)\to \mathbb{R}\) is given by \[ f\mapsto\frac{ \int_M f\mu}{\int_M \mu}\] Proof Let \(f\in C^\infty(M)\) and suppose \(f=\Delta_\mu(X)\) for \(X\in\mathfrak{X}^1(M)\). Then \[f\mu = f\vee \mu = \Delta_\mu(X)\vee\mu= d(X\vee \mu)\] so that \(f\mu\) is exact and by Stokes&#39; theorem integrates to \(0\) on \(M\). Thus all \(f\in \text{Im } \Delta_\mu\) integrate to zero against \(\mu\) on \(M\), so that the above map indeed descends to the quotient.&lt;/p&gt;&lt;p&gt;The above arguement also implies that were \(1\in\text{Im }\Delta_\mu\) then \(\mu\) would integrate to zero, contradicting that \(\mu\) is a volume form, so that \([1]\in H^0(\mathfrak{X})\) is indeed nontrivial. The map is thus well-defined, linear, and has the appropriate action on a basis so that it is correct as claimed. \(\square\)&lt;/p&gt;&lt;p&gt;This recovers the standard definition of the expectation of an observable in the path integral picture of quantum field theory. The upshot is that having formulated the integration homologically, we can hope to extend this homological definition of expectation to situations where the integral itself is not well defined.&lt;/p&gt;&lt;p&gt;Consider the case \(M=V\) a vector space, which in particular described the situation in coordinates on \(M\). We are interested in measures of the form \(\mu=e^{-S/\hbar}\mu_0\) where \(\mu_0\) is the Lesbesgue measure on \(V\), given by \(\mu_0=dx^1\wedge &amp;hellip;\wedge dx^n\). Let \(X\in \mathfrak{X}^k(M)\), we have:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned} d(X\vee \mu) &amp;amp; = d(e^{-S/\hbar}(X\vee\mu_0)) \cr&amp;amp;= de^{-S/\hbar}\wedge (X\vee \mu_0)+e^{-S/\hbar}d(X\vee \mu_0)\cr&amp;amp;= -\frac{1}{\hbar}e^{-S/\hbar} dS\wedge (X\vee \mu_0) + e^{-S/\hbar} (\Delta_{\mu_0}X)\vee \mu_0 \cr&amp;amp;= -\frac{1}{\hbar}e^{-S/\hbar} (dS\vee X)\vee \mu_0 + (\Delta_{\mu_0}X)\vee \mu\cr&amp;amp;= \left(-\frac{1}{\hbar}dS\vee X + \Delta_{\mu_0}X \right)\vee \mu\end{aligned} \]&lt;/p&gt;&lt;p&gt;so that \[\Delta_\mu=\Delta_{\mu_0}-\frac{1}{\hbar}\iota_{dS}\] Further, we can explicitly compute \(\Delta_{\mu_0}\): for \(X\in\mathfrak{X}^k(M)\) we have that \(X=\sum_I X^I \partial_I\), where the sum is over increasing \(k\)-tuples \(I\subset{1,&amp;hellip;,n}\). We have&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}d(X\vee \mu_0) &amp;amp; = d\left( \sum_I X^I \partial_I\vee(dx^1\wedge &amp;hellip;\wedge dx^n)\right)\cr&amp;amp; = d\left( \sum_I X^I (-1)^?dx^1\wedge &amp;hellip;\wedge \hat{dx^I} \wedge &amp;hellip;\wedge dx^n \right)\cr&amp;amp; = \sum_I \sum_{i\in I} \partial_{x^i} X^I (-1)^?dx^i\wedge dx^1\wedge &amp;hellip;\wedge \hat{ dx^I}\wedge &amp;hellip;\wedge dx^n\cr&amp;amp; = \left( \sum_i \partial_{x^i} (dx^i\vee X) \right) \vee \mu\end{aligned} \]&lt;/p&gt;&lt;p&gt;so that \[\Delta_{\mu_0} = \sum_i \partial_{x^i} \iota_{dx^i}\] To be slightly more careful about the formal variable \(\hbar\) and allow the \(\hbar\to 0\) limit to be more clear, we refine our complex to be:\[ \mathfrak{X}^\bullet(M)[[\hbar]] \quad\quad\text{equipped with}\quad\quad \hbar \Delta_\mu= \hbar\Delta_{\mu_0} -\iota_{dS}\]Next, we restrict consideration only to polynomial observables (functions), and vector fields with polynomial coefficients, denoting the resulting complex \(\text{PV}^\bullet\). One can check that \(H^0(\text{PV})\) is still one dimensional, so that the above proposition holds and we maintain the integral intepretation of this cohomology.&lt;/p&gt;&lt;p&gt;Now, we can identify \(\text{PV}^\bullet[[\hbar]]\) with the graded-commutative graded algebra \(\mathbb{K}[[x^1,&amp;hellip;,x^n,\xi_1,&amp;hellip;,\xi_n,\hbar]]\) where \(x^1,&amp;hellip;,x^n,\hbar\) are in degree 0 and \(\xi_1,&amp;hellip;,\xi_n\) are in degree -1 as follows: \[ x^i \mapsto x^i \quad\quad \partial_i\mapsto \xi_i\quad\quad \partial_i\wedge\partial_j\mapsto \xi_i\xi_j \quad\quad \hbar\mapsto \hbar\] Under this identification, the map \(\iota_{dx^i}:PV^k(M)\to \text{PV}^{k-1}(M)\) is identified with \(\partial_{\xi_i}\). Now, we require our action function \(S:M\to \mathbb{R}\) also be polynomial, and further, that \[S(x)=\frac{1}{2}\sum_{i,j} a_{ij}x^ix^j- b(x)\] for \(a_{ij}\) symmetric and non-degenerate and for \(b\in I^3\) where \(I=(x^1,&amp;hellip;,x^n)\subset \mathbb{K}[[x^1,&amp;hellip;,x^n]]\), that is, \(b(x)\) a polynomial with no terms of degree less than 3. This implies that&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\hbar\Delta_\mu &amp;amp; = \hbar\Delta_{\mu_0} -\iota_{dS} \cr&amp;amp; = \hbar \sum_i \partial_{x^i} \iota_{dx^i} - \sum_i (\partial_{x^i}S) \iota_{dx^i} \cr&amp;amp; = \hbar \sum_i \partial_{x^i} \iota_{dx^i} + \sum_i (\partial_{x^i}b) \iota_{dx^i} - \sum_{i,j}a_{ij}x^i\iota_{dx^j}\end{aligned} \]&lt;/p&gt;&lt;p&gt;and under our identification this becomes \[\hbar\Delta_\mu = \hbar \sum_i \partial_{x^i}\partial_{\xi_i} + \sum_i (\partial_{x^i}b)\partial_{\xi_i} - \sum_{i,j}a_{ij}x^i\partial_{\xi_j}\] The computation of the degree 0 cohomology of a given polynomial \(f\in\mathbb{K}[[x_1,&amp;hellip;,x_n]]\) under this differential is taken up in Gwilliam, Johnson-Freyd where it is shown the answer is precisely the Feynman diagram expansion for the expectation of \(f\) which we expect.&lt;/p&gt;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://inspirehep.net/literature/294397&#34;&gt;A note on the anti-bracket formalism&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Clifford algebras and spinors part 3: Bochner identity</title>
       <link>https://jmf1sh.github.io/posts/2014-03-18-clifford-algebras-part-3/</link>
       <pubDate>Tue, 18 Mar 2014 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-03-18-clifford-algebras-part-3/</guid>
       <description>&lt;p&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-0/&#34;&gt;Other articles in this series&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Let \(M\) be a Riemannian manifold, and let \(Cl(M)\) be its Clifford bundle. Let \(E \to M\) be any vector bundle with connection, and assume that \(C^\infty(M, E)\) is a \(Cl(M)\)-module. We can define a Dirac operator \(\mathcal{D}\) acting on sections of \(E\) via the formula&lt;/p&gt;&lt;p&gt;\[ \mathcal{D} \sigma = \sum_{i=1}^n e_i \cdot \nabla_i \sigma \]&lt;/p&gt;&lt;p&gt;for any orthonormal frame \({e_1, \dots, e_n}\) on \(M\), and where \(\cdot\) denotes the Clifford module action. We demand that the connection on \(E\) is compatible with Clifford multiplication in the following sense:&lt;/p&gt;&lt;p&gt;\[ \nabla_j (e_i \cdot \sigma) = (\nabla_j e_i) \cdot \sigma + e_i \cdot \nabla_j \sigma. \]&lt;/p&gt;&lt;p&gt;Let \(R\) denote the curvature of \(E\), i.e. we have&lt;/p&gt;&lt;p&gt;\[ [\nabla_i, \nabla_j] \sigma =  R(e_i, e_j) \sigma+ \nabla_{[e_i, e_j]} \sigma \]&lt;/p&gt;&lt;p&gt;We can define an endomorphism \(\mathcal{R}\) on \(E\) by&lt;/p&gt;&lt;p&gt;\[ \mathcal{R} = \frac{1}{2} \sum_{ij} R(e_i, e_j). \]&lt;/p&gt;&lt;p&gt;Theorem. We have the identity \(\mathcal{D}^2 = -\Delta + \mathcal{R}\).&lt;/p&gt;&lt;p&gt;Proof. We compute&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\mathcal{D}^2 \sigma &amp;amp;= \sum_{ij} e_i \nabla_i \left( e_j \nabla_j \sigma \right) \cr&amp;amp;= \sum_{ij} e_i e_j \nabla_i \nabla_j \sigma + e_i ( \nabla_i e_j ) \nabla_j \sigma \cr&amp;amp;= -\Delta \sigma + \frac{1}{2}\sum_{ij}e_i e_j [\nabla_i, \nabla_j] \sigma + \sum_{ij} e_i ( \nabla_i e_j) \nabla_j \sigma \cr&amp;amp;= -\Delta \sigma + \frac{1}{2}\sum_{ij}e_i e_j R(e_i, e_j) \sigma + \frac{1}{2}\sum_{ij} e_i e_j \nabla_{[e_i, e_j]} \sigma+ \sum_{ij} e_i ( \nabla_i e_j) \nabla_j \sigma \cr&amp;amp;= (-\Delta + \mathcal{R})\sigma + \frac{1}{2} \sum_{ij} \left( e_i e_j \nabla_{[e_i, e_j]}\sigma +  e_i (\nabla_i e_j) \nabla_j + e_j (\nabla_j e_i) \nabla_i \right)\sigma\end{aligned} \]&lt;/p&gt;&lt;p&gt;We will be done provided we can show that the last term vanishes. Notice that it is fully tensorial, since it can be expressed as \(\mathcal{D}^2 + \Delta - \mathcal{R}\). On the other hand, the terms \([e_i, e_j]\) and \(\nabla_j e_i\) are (by definition!) proportional to Christoffel symbols. Since we can always choose a frame so that these vanish at a point, these terms must vanish identically. Hence we have \(0 = \mathcal{D}^2 + \Delta - \mathcal{R}\), as desired.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Clifford algebras and spinors, part 2: spin structures and Dirac operators</title>
       <link>https://jmf1sh.github.io/posts/2014-03-06-clifford-algebras-part-2/</link>
       <pubDate>Thu, 06 Mar 2014 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-03-06-clifford-algebras-part-2/</guid>
       <description>&lt;p&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-0/&#34;&gt;Other articles in this series&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;A very good reference for today&amp;rsquo;s material is Dan Freed&amp;rsquo;s (unpublished) notes on Dirac operators, available here.&lt;/p&gt;&lt;p&gt;Spin(n)&lt;/p&gt;&lt;p&gt;Consider the Clifford algebra \(Cl(\mathbb E^n)\) as constructed in yesterday&amp;rsquo;s post. Define maps \(t, \beta: Cl(\mathbb E^n) \to Cl(\mathbb E^n)\) via&lt;/p&gt;&lt;p&gt;\[ (e_1 \cdots e_k)^t = e_k \cdots e_1, \ \beta(e_1 \dots e_k) = (-1)^k e_k \dots e_2 e_1 \]&lt;/p&gt;&lt;p&gt;There is a natural inclusion \(\mathbb E^n \hookrightarrow Cl(\mathbb E^n)\). Given \(x \in Cl(\mathbb E^n)\) and \(v \in \mathbb E^n\), we can consider the product \(x v x^t\). In general, this might not be contained in \(\mathbb E^n \subset Cl(\mathbb E^n)\).&lt;/p&gt;&lt;p&gt;Definition. We define the group \(Pin(n)\) to consist of all those \(g \in Cl(\mathbb E^n)\) such that&lt;/p&gt;&lt;p&gt;\[ g \beta(g) = 1, \ \ g v \beta(g) \subset \mathbb E^n \ \forall\ v \in \mathbb E^n. \]&lt;/p&gt;&lt;p&gt;Similarly, we define the group \(Spin(n)\) to be the subgroup of \(Pin(n)\) such that \(gg^t = 1\).&lt;/p&gt;&lt;p&gt;Theorem. The natural action of \(Pin(n)\) on \(\mathbb E^n\) is by othogonal transformations, giving a natural map \(Pin(n) \to O(n)\). This map is a double cover. Similarly, \(Spin(n)\) is a double cover of \(SO(n)\). If \(n \geq 2\), \(Spin(n)\) is simply connected.&lt;/p&gt;&lt;p&gt;The importance of the spin groups is due to the following basic fact. Suppose that \(G\) is a Lie group with Lie algebra \(\mathfrak{g}\). Any representation of \(G\) induces a representation of \(\mathfrak{g}\). However,  given a representation of \(\mathfrak{g}\), it is not always possible to integrate it to a representation of \(G\). But it is always possible to integrate a representation of \(\mathfrak{g}\) to produce a representation of the universal cover of \(G\). For \(n \geq 2\), \(Spin(n)\) is the universal cover of \(SO(n)\).&lt;/p&gt;&lt;p&gt;Spin Structures&lt;/p&gt;&lt;p&gt;Let \((M^n, g)\) be a Riemannian manifold. Recall that the frame bundle \(O(M)\) is the manifold consisting of pairs \((x, \mathbb{e})\) where \(x \in M\) and \(\mathbb{e} = {e_1, \dots, e_n}\) is an orthonormal frame in \(T_x M\). Since the orthogonal group \(O(n)\) acts on the set of orthonormal frames, this makes \(F(M)\) into a principal \(O(n)\) bundle over \(M\). Let us assume that \(M\) is oriented, so that we may reduce its structure group to \(SO(n)\).&lt;/p&gt;&lt;p&gt;Suppose that \(V\) is a representation of \(SO(n)\). Then we may form the associated bundle \(SO(M) \times_{SO(n)} V\), which is a vector bundle over \(M\) with structure group \(SO(n)\). If we take the defining representation then we obtain the tangent bundle, but of course there are many others. Unfortunately, since \(SO(n)\) is not simply connected, not every representation of \(\mathfrak{so}_n\) can be integrated to a representation of \(SO(n)\). At the level of geometry, this means that in a certain sense there are certain vector bundles over \(M\) that are &amp;ldquo;missing&amp;rdquo;! Even more disturbing, is that these &amp;ldquo;missing&amp;rdquo; bundles appear to be necessary to describe many of the fundamental particles that appear in the standard model&amp;ndash;so this has real world consequences. The solution is to equip \(M\) with a spin structure.&lt;/p&gt;&lt;p&gt;Definition. A spin structure on \(M\) is a principal \(Spin(n)\)-bundle \(Spin(M)\) over \(M\) together with a bundle morphism \(Spin(M) \to SO(M)\) which is a reduction of structure (i.e., satisfies the obvious axioms).&lt;/p&gt;&lt;p&gt;As you might expect, not every manifold admits a spin structure, and spin structures may not be unique. Loosely speaking, a spin structure is a slightly stronger notion of orientability. Spin structures may always be chosen locally, and the obstruction to consistent gluing is not too difficult to characters as a certain \(\mathbb Z_2\) cohomology class, called the second Stiefel-Whitney class.&lt;/p&gt;&lt;p&gt;Spin Connection and Dirac Operators&lt;/p&gt;&lt;p&gt;The reduction of structure \(Spin(M) \to SO(M)\) allows us to pull back the Levi-Civita connection on \(SO(M)\) to obtain a connection on \(Spin(M)\), called the spin connection. Let \(S_0\) be the spinor module described in the previous post. Then we may construct the associated bundle&lt;/p&gt;&lt;p&gt;\[ S = Spin(M) \times_{Spin(n)} S_0 \]&lt;/p&gt;&lt;p&gt;which is called the spinor bundle. Moreover, since \(S_0\) is a Clifford module, there is well-defined notion of Clifford multiplication on sections of \(S\). We may then define the Dirac operator \(\mathcal{D}\) by&lt;/p&gt;&lt;p&gt;\[ \mathcal{D} = \sum_{a=1}^n c(e_a) \nabla_{e_a} \]&lt;/p&gt;&lt;p&gt;where \({e_a}\) is any orthonormal frame, \(\nabla\) is the spin connection, and \(c\) denotes Clifford multiplication.&lt;/p&gt;&lt;p&gt;Next time: the Weitzenböck formula, and maybe a vanishing theorem.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Clifford algebras and spinors: part 1</title>
       <link>https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-1/</link>
       <pubDate>Wed, 05 Mar 2014 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-1/</guid>
       <description>&lt;p&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-0/&#34;&gt;Other articles in this series&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;clifford-algebras&#34;&gt;Clifford Algebras&lt;/h2&gt;&lt;p&gt;Today I&amp;rsquo;d like to write some brief notes about Clifford algebras and spinors. Aclassic reference is the paper &amp;ldquo;Clifford Modules&amp;rdquo; by Atiyah-Bott-Shapiro.Clifford algebras not only useful in algebra and geometry, but are essential forthe construction of theories with fermions. Let \(V\) be a vector space with anon-degenerate symmetric bilinear form \(B\). We define the Clifford algebra\(Cl(V, B)\) to be the unital associative algebra generated by \(v \in V\) subjectto the relation&lt;/p&gt;&lt;p&gt;\[ vw + wv = -2B(v,w) \]&lt;/p&gt;&lt;p&gt;Equivalently, the definiting relation is \(v^2 = -B(v,v)\).&lt;/p&gt;&lt;p&gt;The Clifford algebra inherits a \(\mathbb Z\)-filtration as well as a\(\mathbb Z_2\)-grading from the tensor algebra. In fact, we have an analogueof the Poincare-Birkhoff-Witt theorem for Lie algebras:&lt;/p&gt;&lt;p&gt;Theorem The associated graded algebra of \(Cl(V,B)\) is naturally isomorphic tothe exterior algebra on \(V\).&lt;/p&gt;&lt;p&gt;In this way, we may view the Clifford algebra as a quantization of theexterior algebra, much in the same way that \(U(\mathfrak g)\) is aquantization of the Poisson algebra of functions on\(\mathfrak g^\ast\) for a Lie algebra \(\mathfrak g\).&lt;/p&gt;&lt;p&gt;Example. Take (V,B) to be the Euclidean space \(\mathbb E^1\). Then we have asingle generator \(e\) satisfying the relation \(e^2 =  -1\). Hence&lt;/p&gt;&lt;p&gt;\[ Cl(\mathbb R) \cong \mathbb R \cdot 1 \oplus \mathbb R \cdot e \cong \mathbb C \]&lt;/p&gt;&lt;p&gt;Where the isomorpism is given by \(e \mapsto i = \sqrt{-1}\).&lt;/p&gt;&lt;p&gt;Example. Take \(\mathbb E^2\). We have generators \(e_1, e_2\) both squaring to -1,and additionally we have \(e_1 e_2 = e_2 e_1\). We can define an isomorphism from\(Cl(\mathbb E^2)\) to the quaternions \(\mathbb H\) by\(e_1 \mapsto i, e_2 \mapsto j\).&lt;/p&gt;&lt;h2 id=&#34;spinors&#34;&gt;Spinors&lt;/h2&gt;&lt;p&gt;Now consider the complexified Clifford algebra, denoted \(\mathbb{C}l(V)\). Sincewe can now take square roots of negative numbers, the complex Clifford algebrais insensitive to the signature (as long as our bilinear form isnon-degenerate). Denote by \(C_n\) the complex Clifford algebra \(Cl(\mathbb C^n)\),where \(\mathbb C^n\) is equipped with the standard bilinear form\((x,y) = \sum_{i=1}^n x_i y_i\).&lt;/p&gt;&lt;p&gt;Definition. A subspace \(W \subset \mathbb C^n\) is isotropic if the restrictionof the standard bilinear form to \(W\) is identically 0. A maximal isotropicsubspace is an isotropic subspace that is not properly contained in any otherisotropic subspace.&lt;/p&gt;&lt;p&gt;Theorem. Let \(W\) be a maximal isotropic subspace, and let\( {w_1, \dots, w_k}\)be a basis of \(W\). Let \(\omega = w_1 \cdots w_k \in C_n\), and let\(S = C_n \cdot \omega\). If n is even, then \(S\) is an irreducible Cliffordmodule. If n is odd, then \(S=S^+ \oplus S^-\) is a direct sum irreducibleClifford modules, and \(S^+ \cong S^-\).&lt;/p&gt;&lt;p&gt;Irreducible Clifford modules are called spinor modules. This description ofspinor modules allows one to prove straightforwardly the following completeclassification of complex Clifford algebras.&lt;/p&gt;&lt;p&gt;Corollary. We have \(C_{2m} \cong \mathrm{End}(\mathbb C^m)\) and\(C_{2m+1} \cong \mathrm{End}(\mathbb C^m) \oplus \mathrm{End}(\mathbb C^m)\).&lt;/p&gt;&lt;p&gt;Note that this classification depends on n mod 2, which is closely related toBott periodicity. There is a similar classification of real Clifford algebras.&lt;/p&gt;&lt;h2 id=&#34;dirac-operators&#34;&gt;Dirac Operators&lt;/h2&gt;&lt;p&gt;Now we come to the real importance of Clifford algebras. Consider Euclideanspace \(\mathbb{E}^n\) and let \(S\) be a spinor module for its Clifford algebra.We define the Dirac operator acting on \(S\)-valued functions as&lt;/p&gt;&lt;p&gt;\[ D f = \sum_{i=1}^n e_i \cdot \partial_i f \]&lt;/p&gt;&lt;p&gt;Now the amazing property of \(D\) is the following:&lt;/p&gt;&lt;p&gt;\[ D^2 = \sum_{i,j} e_i e_j \partial_i \partial_j = \sum_i e_i^2 \partial_i^2 + \sum_{i,j} e_i e_j [\partial_i, \partial_j] = -\Delta \]&lt;/p&gt;&lt;p&gt;hence the Dirac operator provides an algebraic (as opposed topseudodifferential) square root of the Laplacian.&lt;/p&gt;&lt;p&gt;To Be Added in an Update&amp;hellip;&lt;/p&gt;&lt;p&gt;Supersymmetric point particle, Dirac operators on spin manifolds, Weitzenböckformula, spinor reps of Lorentz algebra, N=1 susy.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Clifford algebras and spinors: table of contents</title>
       <link>https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-0/</link>
       <pubDate>Wed, 05 Mar 2014 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-0/</guid>
       <description>&lt;p&gt;Table of contents:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-1/&#34;&gt;Part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-06-clifford-algebras-part-2/&#34;&gt;Part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-18-clifford-algebras-part-3/&#34;&gt;Part 3&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Virasoro algebra</title>
       <link>https://jmf1sh.github.io/posts/2014-02-23-virasoro-algebra/</link>
       <pubDate>Sun, 23 Feb 2014 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2014-02-23-virasoro-algebra/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Conformal Invariance in 2D&lt;/p&gt;&lt;p&gt;To begin, recall that in two dimensions, the conformal transformations are generated by holomorphic and anti-holomorphic transformations. At the infinitesimal level, let \(\ell_n := -z^{n+1} \partial_z\) be a basis of holomorphic vector fields. These satisfy the Witt algebra&lt;/p&gt;&lt;p&gt;\[ [\ell_m, \ell_n] = (m-n)\ell_{m+n}. \]&lt;/p&gt;&lt;p&gt;Similarly, we can define \(\bar{\ell}_m = -\bar{z}^{n+1} \partial_{\bar{z}}\), and in addition to the Witt algebra these new generators satisfy \([\bar{\ell}_m, \ell_n]=0\).&lt;/p&gt;&lt;p&gt;Now, we could try to define a 2D conformal quantum field theory to be a unitary representation of the Witt algebra (or rather, of two copies of the Witt algebra, since we have both holomorphic and anti-holomorphic vector fields&amp;ndash;but nevermind that). But this is too naive.&lt;/p&gt;&lt;p&gt;Central Extensions&lt;/p&gt;&lt;p&gt;Recall that in quantum mechanics, states are represented by vectors in some Hilbert space \(\mathcal{H}\). However, the state \(|\phi\rangle\) and \(\alpha|\phi\rangle\) are physically equivalent for any non-zero complex number \(\alpha\). The reason, of course, is that the expectation value of an operator \(\mathcal{O}\) is defined to be \(\langle \phi|\mathcal{O}|\phi\rangle / \langle \phi|\phi\rangle\), and such expressions are invariant under rescaling in \(\mathcal{H}\).&lt;/p&gt;&lt;p&gt;Thus,  a symmetry group \(G\) for a theory does not necessarily act via a map \(G \to U(\mathcal{H})\). It suffices to have a projective representation \(G \to PU(\mathcal{H})\). Let \(\mathfrak{g}, \mathfrak{pu}\) be the Lie algebras of \(G\) and \(PU\), respectively. A projective representation gives a map&lt;/p&gt;&lt;p&gt;\[ \mathfrak{g} \to \mathfrak{pu}. \]&lt;/p&gt;&lt;p&gt;Since \(PU\) is a quotient of \(U\), we have a short exact sequence&lt;/p&gt;&lt;p&gt;\[ 0 \to \mathbb{C} \to \mathfrak{u} \to \mathfrak{pu} \to 0. \]&lt;/p&gt;&lt;p&gt;Now let \(\hat{\mathfrak{g}}\) be defined as&lt;/p&gt;&lt;p&gt;\[ \hat{\mathfrak{g}} = { (\xi, \eta) \in \mathfrak{u}\oplus\mathfrak{g} \ | \ \pi(\xi) = \rho(\eta) } \]&lt;/p&gt;&lt;p&gt;This comes with a natural projection \(\hat{\mathfrak{g}} \to \mathfrak{g}\). If we suppose that the projective representation \(\rho\) is faithful, then the kernel of this map is exactly \(\mathbb{C}\). Hence, a faithful projective representation of \(\mathfrak{g}\) yields a short exact sequence of Lie algebras&lt;/p&gt;&lt;p&gt;\[ 0 \to \mathbb{C} \to \hat{\mathfrak{g}} \to \mathfrak{g} \to 0. \]&lt;/p&gt;&lt;p&gt;We have obtained a central extension of \(\mathfrak{g}\).&lt;/p&gt;&lt;p&gt;Virasoro Algebra&lt;/p&gt;&lt;p&gt;Finally, we can define the Virasoro algebra. It has generators \(L_n\) and \(c\), with defining relations&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n] = (m-n) L_{m+n} + \frac{c}{12}(m^3-m) \delta_{m+n,0}, [c, L_n] = 0. \]&lt;/p&gt;&lt;p&gt;The generator \(c\) acts as a scalar in any irreducible representation, and its value is called the central charge. The factor of \(1/12\) is entirely conventional. Now, the amazing fact is the following.&lt;/p&gt;&lt;p&gt;Theorem. Up to equivalence, the Virasoro algebra is the unique non-trivial central extension of the Witt algebra.&lt;/p&gt;&lt;p&gt;Proof sketch. This is essentially just a calculation. Any central extension has to be of the form&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n] = (m-n) L_{m+n} + A(m,n) c \]&lt;/p&gt;&lt;p&gt;for some function \(A(m,n)\). If we make the replacement \(L_m \mapsto L_m + a_m c\), then we have&lt;/p&gt;&lt;p&gt;\[ [L_m, L_n] = (m-n) L_{m+n} + \left( A(m,n) + (m-n) a_{m+n} \right) c \]&lt;/p&gt;&lt;p&gt;Taking \(n = 0\), we have&lt;/p&gt;&lt;p&gt;\[ [L_m, L_0] = m L_{m} + \left( A(m,0) + m a_{m} \right) c \]&lt;/p&gt;&lt;p&gt;Hence for \(m\neq0\) we can take \(a_m = m^{-1} A(m,0)\). Having done this, we are now free to assume that \(A(m,0) = 0 \) for all \(m\). Then we may apply the Jacobi identity to deduce that \(A(m,n)=0\) except possibly for \(m=-n\), so that \(A(m,n)\) can be written in the form \(A(m,n) = A_m \delta_{m+n, 0}\). Finally, another application of the Jacobi identity yields a simple recurrence relation for the coefficients \(A_m\), and it is easily seen that every solution of this recurrence is proportional to \(m^3-m\).&lt;/p&gt;&lt;p&gt;Now we can take our (preliminary, and still too naive) definition of a quantum conformal field theory to be a unitary representation of the Virasoro algebra.&lt;/p&gt;&lt;p&gt;Stress-Energy Tensor and OPE&lt;/p&gt;&lt;p&gt;The operator \(L_0\) behaves like the Hamiltonian of the theory, and the Virasoro relations show that \(L_n\) for \(n&amp;gt;0\) act as lowering operators. Hence, in a physically sensible representation, the vacuum vector \(|\Omega\rangle\) will be annihilated by \(L_n\) for all \(n &amp;gt; 0\). Unitary requires \(L_n^\dagger = L_{-n}\), so additionally we have \(\langle \Omega|L_n = 0\) for \(n &amp;lt; 0\). Hence&lt;/p&gt;&lt;p&gt;\[ \langle \Omega | L_m L_n | \Omega \rangle = 0 \ \textrm{unless}\ n \leq 0, m \geq 0 \]&lt;/p&gt;&lt;p&gt;Now define the stress-energy tensor to be the operator-valued formal power series&lt;/p&gt;&lt;p&gt;\[ T(z) = \sum_n \frac{L_n}{z^{n+2}} \]&lt;/p&gt;&lt;p&gt;We can consider the vacuum expectation of the product \(T(z) T(w)\). By the above remarks, many terms in the expansion will vanish. In fact, it is a straightforward (but tedious!) exercise to check the following.&lt;/p&gt;&lt;p&gt;Theorem. The stress-energy tensor satisfies the operator product expansion&lt;/p&gt;&lt;p&gt;\[ T(z) T(w) \sim \frac{c/2}{(z-w)^4} + \frac{2 T(w)}{(z-w)^2} + \frac{\partial_w T(w)}{z-w} \]&lt;/p&gt;&lt;p&gt;where \(\sim\) denotes that the left- and right-hand sides are equal up to the addition of terms with vanishing vev and/or regular as \(z \to w\).&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>BRST and Lie algebra cohomology</title>
       <link>https://jmf1sh.github.io/posts/2012-12-28-brst-lie-algebra/</link>
       <pubDate>Fri, 28 Dec 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-12-28-brst-lie-algebra/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;We saw in previous posts that gauge-fixing is intimately related to BRST cohomology. Today I want to explain the underlying mathematical formalism, as it is actually something very well-known: Lie algebra cohomology. Let \(\mathfrak{g}\) be a Lie algebra and \(M\) a \(\mathfrak{g}\)-module. We will construct a cochain complex that computes the Lie algebra cohomology with values in \(M\), \(H^i(\mathfrak{g}, M)\). Out of thin air, we define&lt;/p&gt;&lt;p&gt;\[ C^\ast(\mathfrak{g}, M) = M \otimes \wedge^\ast \mathfrak{g}^\ast. \]&lt;/p&gt;&lt;p&gt;The grading is just the grading induced by the grading on \(\wedge^\ast \mathfrak{g}^\ast\), which we identify with the BRST ghost number. Let \(e_i\) be a basis for \(M\) and \(T_a\) be a basis for \(\mathfrak{g}\), with canonical dual basis \(S^a\). The differential is defined on generators to be&lt;/p&gt;&lt;p&gt;\[ d e_i = \rho(T_a) e_i \otimes S^a \]&lt;/p&gt;&lt;p&gt;\[ d S^a = \frac{1}{2} f^a_{bc} S^b \wedge S^c \]&lt;/p&gt;&lt;p&gt;where \(\rho: \mathfrak{g} \to \mathrm{End}(M)\) is the representation and \(f^a_{bc}\) are the structure constants of the group. This differential is then extended to satisfy the graded Leibniz rule, and is easily verified to satisfy \(d^2 = 0\) (this is just the Jacobi identity). The Lie algebra cohomology is just the cohomology of this cochain complex. Essentially by definition, we see that&lt;/p&gt;&lt;p&gt;\[ H^0(\mathfrak{g}, M) = {m \in M \ | \ \xi \cdot m = 0 \ \forall \ \xi \in \mathfrak{g} }, \]&lt;/p&gt;&lt;p&gt;i.e. \(H^0(\cdot) = (\cdot)^\mathfrak{g}\) is the invariants functor. In fact, this can be taken to be the defining property of Lie algebra cohomology:&lt;/p&gt;&lt;p&gt;Theorem \(H^k(\mathfrak{g}, M) = R^k (M)^\mathfrak{g}\).&lt;/p&gt;&lt;p&gt;Returning to field theory, we see (modulo some hard technicalities!) that, roughly, \(\mathfrak{g}\) is the Lie algebra of infinitesimal gauge transformations, and \(M\) is the algebra of functions on the space of all connections. The ghost and anti-ghost fields can then be seen to be the multiplication and contraction operators. To wit, we can take \(c^a\) to be the operator&lt;/p&gt;&lt;p&gt;\[ c^a: f \mapsto S^a \wedge f \]&lt;/p&gt;&lt;p&gt;and take \(\bar{c}^a\) to be the operator&lt;/p&gt;&lt;p&gt;\[ \bar{c}^a: f \mapsto \frac{\partial}{\partial S^a} f  = T_a \lrcorner f.\]&lt;/p&gt;&lt;p&gt;Then we have&lt;/p&gt;&lt;p&gt;\[ [c^a, \bar{c}^b] = \delta^{ab} \]&lt;/p&gt;&lt;p&gt;so that \(\bar{c}\) is indeed the antifield of \(c\).&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>BRST</title>
       <link>https://jmf1sh.github.io/posts/2012-12-23-brst/</link>
       <pubDate>Sun, 23 Dec 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-12-23-brst/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Finally, I want to discuss gauge-invariant of the gauge-fixed theory. (!?) We saw in the previous posts that if we have a gauge theory with connection \(A\) and matter fields \(\psi\), in order to derive sensible Feynman rules we have to introduce a gauge-fixing function \(G\) as well as Fermionic fields \(c, \bar{c}\), the ghosts. (Note: last time I used \(\eta, \bar{\eta}\) for the ghosts but I want to match the more standard notation, so I&amp;rsquo;ve switched to \(c, \bar{c}\)).&lt;/p&gt;&lt;p&gt;Usually it is convenient to use the gauge-fixing function \(G(A) = \partial^\mu A_\mu\). Under an infinitesimal gauge-transformation \(\lambda\), \(A\) transforms as&lt;/p&gt;&lt;p&gt;\[ A \mapsto -\nabla \lambda, \]&lt;/p&gt;&lt;p&gt;so \(G(A)\) transforms as&lt;/p&gt;&lt;p&gt;\[ G(A) \mapsto G(A) - \partial^\mu \nabla_\mu \lambda. \]&lt;/p&gt;&lt;p&gt;Hence the term in the Lagrangian involving the ghosts is&lt;/p&gt;&lt;p&gt;\[ -\bar{c}^a \partial^\mu \nabla_\mu^{ab} c^b, \]&lt;/p&gt;&lt;p&gt;and our gauge-fixed Lagrangian is&lt;/p&gt;&lt;p&gt;\[ \mathcal{L} = -\frac{1}{4} |F|^2 + \bar{\psi}(iD\!\!\!/-m)\psi + -\frac{|\partial^\mu A_\mu|^2}{2\xi} - \bar{c}^a \nabla_\mu^{ab} c^b \]&lt;/p&gt;&lt;p&gt;Introducing an auxiliary filed \(B^a\), this is of course equivalent to&lt;/p&gt;&lt;p&gt;\[ \mathcal{L} = -\frac{1}{4} |F|^2 + \bar{\psi}(iD\!\!\!/-m)\psi + \frac{\xi}{2} B^a B_a +B^a \partial^\mu A_{\mu a} - \bar{c}^a \nabla_\mu^{ab} c^b. \]&lt;/p&gt;&lt;p&gt;Now, there are two questions one might ask: (1) how can we tell that this is a gauge-theory? i.e., what remains of the original gauge symmetry? and (2) does the resulting theory depend in any way on the choice of gauge-fixing function?&lt;/p&gt;&lt;p&gt;The answer to both of these questions is BRST symmetry. The field \(c\) is Lie-algebra valued, so we could think of it as being an infinitesimal gauge transformation. Rather, for \(\epsilon\) a constant odd variable, \(\epsilon c\) is even and an honest infinitesimal gauge transformation. Under this transformation, we have&lt;/p&gt;&lt;p&gt;\[ \delta_\epsilon A = -\nabla (\epsilon c) = -\epsilon \nabla c. \]&lt;/p&gt;&lt;p&gt;Then we define a graded derivation \(\delta\) by&lt;/p&gt;&lt;p&gt;\[ \delta A = - \nabla c. \]&lt;/p&gt;&lt;p&gt;We have a grading by ghost number, where \(\mathrm{gh}(A) = 0\), \(\mathrm{gh}(\psi) = 0\), \(\mathrm{gh}(c) = 1\), \(\mathrm{gh}(\bar{c}) = -1\). We would like to extend \(\delta\) to a derivation of degree \(+1\) that squares to 0. First, we should figure out what \(\delta c\) is. We compute:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}0 &amp;amp;= \delta^2 A \cr&amp;amp;= \delta(-\nabla c) \cr&amp;amp;= -\partial \delta c - (\delta A) c - A (\delta c) + (\delta c) A - c (\delta A) \cr&amp;amp;= -\partial \delta c + (\nabla c) c + c (\nabla c) - [A, \delta c] \cr&amp;amp;= -\nabla(\delta c) + \nabla(c^2).\end{aligned} \]&lt;/p&gt;&lt;p&gt;From this, we see that \(\nabla(\delta c) = \nabla(c^2)\), so we can set&lt;/p&gt;&lt;p&gt;\[ \delta c = c^2 = \frac{1}{2}[c, c]. \]&lt;/p&gt;&lt;p&gt;Then \(\delta^2 c = 0\) is just the Jacobi identity for the group&amp;rsquo;s Lie algebra! Finally, we would like to extend \(\delta\) to act on \(\psi\), \(B\), and \(\bar{c}\) so that \(\delta \mathcal{L} = 0\), and \(\delta^2 = 0\). Since the action on \(A\) is by infinitesimal gauge transformation, this leaves the curvature term of \(\mathcal{L}\) invariant. Similarly, the \(\psi\) term is invariant if we simply take&lt;/p&gt;&lt;p&gt;\[ \delta \psi = c \cdot \psi \]&lt;/p&gt;&lt;p&gt;where dot denotes the infinitesimal gauge transformation. Using the known rules for \(\delta\), we find that&lt;/p&gt;&lt;p&gt;\[ \delta \mathcal{L} = \frac{\xi}{2} \left(\delta B B + B \delta B \right) + \delta B \cdot \partial^\mu A_\mu -B \cdot \partial^\mu \nabla_\mu c - \delta\bar{c} \cdot \partial^\mu \nabla_\mu c \]&lt;/p&gt;&lt;p&gt;By comparing coefficients, we find (together with what we&amp;rsquo;ve already computed)&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\delta A &amp;amp;= -\nabla c \cr\delta \psi &amp;amp;= c \cdot \psi \cr\delta c &amp;amp;= \frac{1}{2}[c,c] \cr\delta \bar{c} &amp;amp;= B \cr\delta B &amp;amp;= 0.\end{aligned} \]&lt;/p&gt;&lt;p&gt;This is the BRST differential. Now, suppose that \(\mathcal{O}(A, \psi)\) is a local operator involving the physical fields \(A\) and \(psi\). Then by construction, \(\delta O\) is the change of \(O\) under an infinitesimal gauge transformation. Hence, we find&lt;/p&gt;&lt;p&gt;An operator \(\mathcal{O}\) is gauge invariant \(\iff \delta\mathcal{O} = 0\).&lt;/p&gt;&lt;p&gt;Now, suppose the functional measure \(\mathcal{D}A \mathcal{D}\psi \mathcal{D}B \mathcal{D}c \mathcal{D}\bar{c}\) is gauge-invariant, i.e. is BRST closed. (This assumption is equivalent to the absence of anomalies, but we&amp;rsquo;ll completely ignore this in today&amp;rsquo;s post.) Then we have&lt;/p&gt;&lt;p&gt;\[ \langle \delta \mathcal{O} \rangle = 0 \]&lt;/p&gt;&lt;p&gt;for any local observable \(\mathcal{O}\). This just follows from integration by parts (this is where we have to assume the measure is \(\delta\)-closed). Now, why is this significant? First, this tells us that the space of physical observables is&lt;/p&gt;&lt;p&gt;\[ H^0(C^\ast_{\mathrm{BRST}}, \delta) \]&lt;/p&gt;&lt;p&gt;where \(C^\ast_{\mathrm{BRST}}\) is the cochain complex of local observables, graded by ghost number.&lt;/p&gt;&lt;p&gt;Now, the real power of the BRST formalism is the following. We find that the gauge-fixed Lagrangian can be written as&lt;/p&gt;&lt;p&gt;\[ \mathcal{L}_{gf} = \mathcal{L}_0 +\delta \left(\bar{c} \frac{B}{2} + \bar{c}\Lambda\right) \]&lt;/p&gt;&lt;p&gt;where \( \Lambda = \partial^\mu \nabla_\mu A \) is our gauge-fixing function, and \(\mathcal{L}_0\) is the original Lagrangian without gauge-fixing. Now the point is, any two choices of gauge fixing differ by terms which are BRST exact, and hence give the same expectation values on the physical observables \(H^0\). So we have restored gauge invariance, while obtaining a gauge-fixed perturbation theory!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Fadeev-Popov ghosts, continued</title>
       <link>https://jmf1sh.github.io/posts/2012-12-23-fadeev-popov-ghosts-continued/</link>
       <pubDate>Sun, 23 Dec 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-12-23-fadeev-popov-ghosts-continued/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Last time I sketched how we can represent an integral over a submanifold \(M \subset \mathbb{R}^n\) by an integral of the form&lt;/p&gt;&lt;p&gt;\[ \int_{\mathbb{R}^n} f(x) \delta(G(x)) \exp\left(\bar{\eta}G(x+\eta) \right) d\eta d\bar{\eta} dx. \]&lt;/p&gt;&lt;p&gt;Here, \(\eta, \bar{\eta}\) are Fermionic variables called Fadeev-Popov ghosts, which are introduced to cancel an unwanted determinant factor. The function \(G(x)\) singles out the submanifold \(M\) as \(M = G^{-1}(0)\).&lt;/p&gt;&lt;p&gt;Now suppose that we start with a vector (or affine) space \(V\), which is acted on by a group \(H\). We would like to undstand integrals over the quotient \(V / H\) in terms of integrals over \(V\). Suppose there is some function \(G(x)\) on \(V\) satisfying the following property:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;For each level \(w\) of \(G\), the subspace \(M_w := G^{-1}(w)\) intersects the orbits transversely, and furthermore every \(H\)-orbit intersects \(M_w\) exactly once. (*)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We call such a function a gauge-fixing function, and a level \(w\) a gauge-fixing. By assumption, we have \(V/H \cong M_w\) for any \(w\). Hence using the integral we derived last time, we can integrate over \(M_w\) for any particular choice of \(w\), and this ought to be the same as integrating over \(V/H\). The problem, however, is that in the QFT setting it&amp;rsquo;s not clear what the Feynman rules should be for such a path integral. The final trick is that since the answer should be independent of \(w\), and by integrating over all possible \(w\) we obtain a Lagrangian from which we can derive sensible Feynman rules.&lt;/p&gt;&lt;p&gt;We have some integral&lt;/p&gt;&lt;p&gt;\[Z = \int \delta(G(x) - w) \exp\left\{\frac{i}{\hbar}S(x) + \bar{\eta}dG \eta\right\} dx d\eta d\bar{\eta} \]&lt;/p&gt;&lt;p&gt;which is independent of \(w\). So we add a Gaussian weight an integrate over \(w\):&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}Z&#39; &amp;amp;= \int \delta(G(x) -w) \exp\left\{\frac{i}{\hbar}S(x) + \bar{\eta}dG \eta - \frac{1}{2\xi} |w|^2\right\}dx dw d\eta d\bar{\eta}\cr&amp;amp;= \int \exp\left\{\frac{i}{\hbar}S(x) + \bar{\eta}dG \eta - \frac{1}{2\xi} |G(x)|^2 \right\} dx d\eta d\bar{\eta}.\end{aligned} \]&lt;/p&gt;&lt;p&gt;Here, \(\xi\) is an arbitrary real positive constant, and we denote the new integral by \(Z&#39;\) to indicate that it differs from the old path integral \(Z\) by (at most) an overall constant. Now the important thing is that the new action appear in the integrand of \(Z&#39;\) is gauge-fixed and hence there is no problem whatsoever in deriving sensible, meaningful Feynman rules. The gauge-fixing term \(|G(x)|^2\) serves to make the action non-degenerate, so that propagators are well-defined, while the term involving the Fermions \(\eta, \bar{\eta}\) generates new Feynman rules that &amp;ldquo;cancel&amp;rdquo; the superfluous degrees of freedom due to gauge redundancy.&lt;/p&gt;&lt;p&gt;The question remains, what if we choose some other gauge-fixing function? i.e., what happens if we perturb \(G(x)\) to some new function satisfying property (*)? We&amp;rsquo;ll answer this using the BRST formalism.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Fadeev-Popov ghosts</title>
       <link>https://jmf1sh.github.io/posts/2012-12-21-fadeev-popov-ghosts/</link>
       <pubDate>Fri, 21 Dec 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-12-21-fadeev-popov-ghosts/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Today I want to review the Fadeev-Popov procedure, with a view toward BRST and eventually BV.&lt;/p&gt;&lt;p&gt;Gauge-Invariance and Gauge-Fixing&lt;/p&gt;&lt;p&gt;First we&amp;rsquo;ll review the Fedeev-Popov method, to motivate the introduction of ghosts. Suppose we have a gauge theory involving a \(G\)-connection \(A\) and some field \(\phi\) charged under \(G\). Under a gauge transformation \(g(x)\), \(\phi\) transforms as&lt;/p&gt;&lt;p&gt;\[ \phi \mapsto g \cdot \phi. \]&lt;/p&gt;&lt;p&gt;We would like that the covariant derivative transforms in the same way, i.e.&lt;/p&gt;&lt;p&gt;\[ \nabla \phi \mapsto g \nabla \phi. \]&lt;/p&gt;&lt;p&gt;In terms of the connection 1-form \(A\), the covariant derivative is&lt;/p&gt;&lt;p&gt;\[ \nabla = d + A. \]&lt;/p&gt;&lt;p&gt;Let \(\nabla&#39;\) denote the gauge-transformed covariant derivative, and \(\phi&#39;\) the gauge-transformed field. Then we want&lt;/p&gt;&lt;p&gt;\[ \nabla&#39; \phi&#39; = g \nabla \phi. \]&lt;/p&gt;&lt;p&gt;We compute&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\nabla&#39; \phi&#39; &amp;amp;= (d + A&#39;)(g \phi) \cr&amp;amp;= dg \phi + g d\phi + A&#39;(g\phi) \cr&amp;amp;= gg^{-1}dg \phi + gd\phi + g g^{-1} A&#39; g\phi \cr&amp;amp;= g(d\phi + g^{-1} A&#39; g \phi + g^{-1} dg \phi \cr&amp;amp;= g(d\phi + A\phi)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Comparing terms, we see that&lt;/p&gt;&lt;p&gt;\[ A = g^{-1} A&#39; g + g^{-1} dg, \]&lt;/p&gt;&lt;p&gt;so upon re-arranging we have&lt;/p&gt;&lt;p&gt;\[ A&#39; = g A g^{-1} - dg g^{-1} \]&lt;/p&gt;&lt;p&gt;This causes a problem: at critical points of the action, the Hessian of the action is degenerate in directions tangent to the gauge orbits. This means that the propagator is not well-defined, and there is no obvious way to derive the Feynman rules for perturbation theory. The solution is to take the quotient by gauge-transformations. To do this, we pick some gauge-fixing function \(G(A)\) which ought to be transverse to the orbits. Then we can restrict to the space \(G(A) = 0\), on which the Hessian of the action is non-degenerate, leading to a well-defined propagator. Formally, the path integral is&lt;/p&gt;&lt;p&gt;\[ Z = \int_{{G(A) = 0}} \exp{\frac{i}{\hbar} S[A, \phi]} \mathcal{D}A \mathcal{D}\phi  \]&lt;/p&gt;&lt;p&gt;Formally, this suggests that the path integral should be something like&lt;/p&gt;&lt;p&gt;\[ Z = \int \delta(G(A)) \exp{\frac{i}{\hbar} S[A, \phi]} \mathcal{D}A \mathcal{D}\phi, \]&lt;/p&gt;&lt;p&gt;but this is not quite right! To understand the source of the problem, we&amp;rsquo;ll first study the finite-dimensional case and then use this to solve the problem in infinite-dimensions.&lt;/p&gt;&lt;p&gt;The Fadeev-Popov Determinant&lt;/p&gt;&lt;p&gt;Suppose we are on \(\mathbb{R}^n\), and we would like to integrate a function \(f(x)\) over a submanifold \(M\) defined by \(M = G^{-1}(0)\) for some smooth function \(G: \mathbb{R}^n \to \mathbb{R}^k\). Naively, we might expect that the answer is&lt;/p&gt;&lt;p&gt;\[ \int_M f(x) \stackrel{?}{=} \int f(x) \delta(G(x)) dx. \]&lt;/p&gt;&lt;p&gt;To see why this is not correct, write the delta function as&lt;/p&gt;&lt;p&gt;\[ \delta(G(x)) = \frac{1}{(2\pi)^k}\int e^{ip\cdot G(x)} d^k p. \]&lt;/p&gt;&lt;p&gt;We can regularize this by taking the limit as \(\epsilon \to 0\) of&lt;/p&gt;&lt;p&gt;\[ \frac{1}{(2\pi)^k}\int \exp\left\{ip\cdot G(x) -\frac{\epsilon}{2} |p|^2\right\} d^k p \]&lt;/p&gt;&lt;p&gt;This integral is Gaussian, so we obtain explicitly&lt;/p&gt;&lt;p&gt;\[ \left(\frac{2\pi}{\epsilon} \right)^{\frac{k}{2}} \exp\left\{-\frac{1}{2\epsilon} |G(x)|^2 \right\}. \]&lt;/p&gt;&lt;p&gt;So our original guess becomes&lt;/p&gt;&lt;p&gt;\[ \left(\frac{1}{2\pi \epsilon}\right)^\frac{k}{2} \int f(x) \exp\left\{ -\frac{1}{2\epsilon} |G(x)|^2 \right\} dx .\]&lt;/p&gt;&lt;p&gt;As \(\epsilon \to 0\), this integral localizes on the locus \({G(x) = 0}\), as desired, but does not give the right answer! To see this, let \(u\) be a coordinate on \(M = G^{-1}(0)\) and \(v\) coordinates normal to \(M\). Then we have&lt;/p&gt;&lt;p&gt;\[ G(x) = G(u,v) = v^T H(u) v + o(|v|^3) \]&lt;/p&gt;&lt;p&gt;where \(H(x)\) is the Hessian of \(|G|^2\) at the point \(x = (u, 0)\). So the integral becomes (as \(\epsilon \to 0\))&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}I_\epsilon &amp;amp;= \left(\frac{1}{2\pi \epsilon}\right)^\frac{k}{2} \int\intf(u, v) \exp\left\{ -\frac{1}{2\epsilon} v^T H(u) v \right\} du dv \cr&amp;amp;= \int_M \frac{f(u)}{\sqrt{\det H(u)}} du.\end{aligned} \]&lt;/p&gt;&lt;p&gt;This is not correct. We have to account for the determinant of the Hessian. Now, the Hessian is given by&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}H_{ij} &amp;amp;= \frac{1}{2} \frac{\partial^2 |G|^2}{\partial v^i \partial v^j} \cr&amp;amp;= \frac{\partial}{\partial v^i} \left( G^a \partial_j G^a \right) \cr&amp;amp;=  \left(\partial_i G^a \partial_j G^a + G^a \partial_{ij} G^a \right) \cr&amp;amp;=  \partial_i G^a \partial_j G^a\end{aligned} \]&lt;/p&gt;&lt;p&gt;where we have used the fact that \(G = 0\) on \(x = (u, 0)\). Hence we see that&lt;/p&gt;&lt;p&gt;\[ \det H = (\det A)^2 \]&lt;/p&gt;&lt;p&gt;where \(A\) is the \(k \times k\) matrix with entries \(\partial_i G^a\). Hence&lt;/p&gt;&lt;p&gt;\[ \sqrt{\det H} = \det A. \]&lt;/p&gt;&lt;p&gt;Now there is a straightforward way to eliminate the determinant. We introduce Fermionic coordinates \(\eta^i, \theta^i\), \(i = 1, \ldots, k\). Then by Berezin integration, we have&lt;/p&gt;&lt;p&gt;\[ \int e^{\eta^i G^i(0, \theta^j)} d\theta d\eta = \det A. \]&lt;/p&gt;&lt;p&gt;So in the end, we find&lt;/p&gt;&lt;p&gt;\[ \int_M f(x) d\mu = \int_{\mathbb{R}^n}f(x) \delta(G(x)) \exp\left(\eta \cdot G(x+ \theta) \right)dx d\theta d\eta. \]&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>The Weyl and Wigner transforms</title>
       <link>https://jmf1sh.github.io/posts/2012-12-13-weyl-wigner-transform/</link>
       <pubDate>Thu, 13 Dec 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-12-13-weyl-wigner-transform/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Today I&amp;rsquo;d like to try to understand better how deformation quantization is related to the usual canonical quantization, and especially how the latter might be used to deduce the former, i.e., given an honest quantization (in the sense of operators), how might be reproduce the formula for the Moyal star product?&lt;/p&gt;&lt;p&gt;We&amp;rsquo;ll fix our symplectic manifold once and for all to be \(\mathbb{R}^2\) with its standard symplectic structure, with Darboux coordinates \(x\) and \(p\). Let \(\mathcal{A}\) be the algebra of observables on \(\mathbb{R}^2\). For technical reasons, we&amp;rsquo;ll restrict to those smooth functions that are polynomially bounded in the momentum coordinate (but of course the star product makes sense in general). Let \(\mathcal{D}\) be the algebra of pseudodifferential operators on \(\mathbb{R}\). We want to define a quantization map&lt;/p&gt;&lt;p&gt;\[ \Psi: \mathcal{A} \to \mathcal{D} \]&lt;/p&gt;&lt;p&gt;such that&lt;/p&gt;&lt;p&gt;\[ \Psi(x) = x \in \mathcal{D} \]&lt;/p&gt;&lt;p&gt;\[ \Psi(p) = -i\hbar \partial \]&lt;/p&gt;&lt;p&gt;Out of thin air, let us define&lt;/p&gt;&lt;p&gt;\[ \langle q| \Psi(f) |q&#39; \rangle = \int e^{ik(q-q&#39;)} f(\frac{q+q&#39;}{2}, k) dk \]&lt;/p&gt;&lt;p&gt;This is the Weyl transform. Its inverse is the Wigner transform, given by&lt;/p&gt;&lt;p&gt;\[ \Phi(A, q, k) = \int e^{-ikq&#39;} \left\langle q+\frac{q&#39;}{2} \right| A \left| q - \frac{q&#39;}{2} \right\rangle dq&#39; \]&lt;/p&gt;&lt;p&gt;Note: I am (intentionally) ignoring all factors of \(2\pi\) involved. It&amp;rsquo;s not hard to work out what they are, but annoying to keep track of them in calculations, so I won&amp;rsquo;t.&lt;/p&gt;&lt;p&gt;Theorem For suitably well-behaved \(f\), we have \( \Phi(\Psi(f)) = f\).&lt;/p&gt;&lt;p&gt;Proof Using the &amp;ldquo;ignore \(2\pi\)&amp;rdquo; conventions, we have the formal identities&lt;/p&gt;&lt;p&gt;\[ \int e^{ikx} dx = \delta(k), \ \ \int e^{ikx} dk = \delta(x). \]&lt;/p&gt;&lt;p&gt;The theorem is a formal result of these:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned} \Phi(\Psi(f))(q, k) &amp;amp;= \int e^{-ikq&#39;} \left\langle q + \frac{q&#39;}{2} \right| \Psi(f) \left| q - \frac{q&#39;}{2} \right\rangle \cr&amp;amp;= \int e^{-ikq&#39;} e^{ik&amp;rsquo;q&#39;} f(q, k) dk&#39; dq&#39; \cr&amp;amp;= f(q,k).\end{aligned} \]&lt;/p&gt;&lt;p&gt;One may easily check that \(\Psi(x) = x\) and \(Psi(k) = -i\partial\), so this certainly gives a quantization. But why is it particularly natural? To see this, let \(Q\) be the operator of multiplication by \(x\), and let \(P\) be the operator \(-i\partial\). We&amp;rsquo;d like to take \(f(q,p)\) and replace it by \(f(Q, P)\), but we can&amp;rsquo;t literally substitute like this due to order ambiguity. However, we could work formally as follows:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}f(Q, P) &amp;amp;= \int \delta(Q-q) \delta(P - p) f(q,p) dq dp \cr&amp;amp;= \int e^{ik(Q-q) + iq&#39;(P-p)} f(q,p) dq dq&#39; dp dk.\end{aligned} \]&lt;/p&gt;&lt;p&gt;In this last expression, there is no order ambiguity in the argument of the exponential (since it is a sum and not a product), and furthermore the expression itself make sense since it is the exponential of a skew-adjoint operator. So let&amp;rsquo;s check that this agrees with the Weyl transform. Using a special case of the Baker-Campbell-Hausdorff formula for the Heisenberg algebra, we have&lt;/p&gt;&lt;p&gt;\[ e^{ik(Q-q) + iq&#39;(P-p)} = e^{ik(Q-q)} e^{iq&#39;(P-p)} e^{-ikq&#39;/2} \]&lt;/p&gt;&lt;p&gt;Let us compute the matrix element:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\langle q_1 | P | q_2 \rangle &amp;amp;= \int \langle q_1 | p_1 \rangle\langle p_1 | P | p_2 \rangle \langle p_2 | q_2 \rangle dp_1 dp_2 \cr&amp;amp;= \int e^{iq_1p_1 - iq_2 p_2} p_2 \delta(p_2 - p_1) dp_1 dp_2 \cr&amp;amp;= \int e^{i p(q_1-q_2)} p dp.\end{aligned} \]&lt;/p&gt;&lt;p&gt;Hence we find that the matrix element for the exponential is&lt;/p&gt;&lt;p&gt;\[ \begin{aligned} \langle q_1 |e^{ik(Q-q) + iq&#39;(P-p)} | q_2 \rangle&amp;amp;= e^{-ikq&#39;/2 + ik(q_1-q)} \langle q_1 | e^{iq&#39;(P-p)} | q_2 \rangle \cr&amp;amp;=  \int e^{-ikq&#39;/2 + ik(q_1-q) -iq&amp;rsquo;p} e^{iq&amp;rsquo;p&#39;&#39; + ip&#39;&#39;(q_1-q_2)} dp&#39;&#39; \cr&amp;amp;= \delta(q&#39; + q_1 - q_2)  e^{-ikq&#39;/2 + ik(q_1-q) -iq&amp;rsquo;p}\end{aligned} \]&lt;/p&gt;&lt;p&gt;Plugging this back into the expression for \(f(Q, P)\) we find&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\langle q_1 | f(Q. P) | q_2 \rangle &amp;amp;= \int \delta(q&#39; + q_1 - q_2)  e^{-ikq&#39;/2 + ik(q_1-q) -iq&amp;rsquo;p}f(q,p) dq dq&#39; dp dk \cr&amp;amp;= \int  e^{ ik(q_1/2 +q_2/2-q) -ip(q_1-q_2)} f(q,p) dq dp dk \cr&amp;amp;= \int e^{ip(q_1-q_2)} f(\frac{q_1+q_2}{2}, p) dp,\end{aligned} \]&lt;/p&gt;&lt;p&gt;which is the original expression we gave for the Weyl transform.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Equations of motion and Noether&#39;s theorem in the functional formalism</title>
       <link>https://jmf1sh.github.io/posts/2012-11-29-equations-of-motion-noether/</link>
       <pubDate>Thu, 29 Nov 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-29-equations-of-motion-noether/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;First, let us recall the derivation of the equations of motion and Noether&amp;rsquo;s theorem in classical field theory. We have some action functional \(S[\phi]\) defined by some local Lagrangian:&lt;/p&gt;&lt;p&gt;\[ S[\phi] = \int L(\phi, \partial \phi) dx. \]&lt;/p&gt;&lt;p&gt;The classical equations of motion are just the Euler-Lagrange equations&lt;/p&gt;&lt;p&gt;\[ \frac{\delta S}{\delta \phi(x)} = 0\iff \partial_\mu \left( \frac{\partial L}{\partial(\partial_\mu\phi)} \right)= \frac{\partial L}{\partial \phi} \]&lt;/p&gt;&lt;p&gt;Now suppose that \(S\) is invariant under some transformation \(\phi(x) \mapsto \phi(x) + \epsilon(x) \eta(x)\), so that \(S[\phi] = S[\phi+\epsilon \eta]\). Here we treat \(\eta\) as a fixed function but \(\epsilon\) may be an arbitrary infinitesimal function. The Lagrangian is not necessarily invariant, but rather can transform with a total derivative:&lt;/p&gt;&lt;p&gt;\[ L(\phi+\epsilon \eta) = L(\phi) + \frac{\partial L}{\partial (\partial_\mu \phi)} \eta \partial_\mu \epsilon + \epsilon \partial_\mu f^\mu \]&lt;/p&gt;&lt;p&gt;For some unknown vector field \(f^\mu\) (which we could compute given any particular Lagrangian). So let&amp;rsquo;s compute&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\delta_\epsilon S &amp;amp;= \int \delta_\epsilon L \cr&amp;amp;= \int \frac{\partial L}{\partial (\partial_\mu \phi)}\eta \partial_\mu \epsilon + \epsilon \partial_\mu f^\mu \cr&amp;amp;= \int \partial_\mu \left(f^\mu - \frac{\partial L}{\partial (\partial_\mu \phi)} \eta \right) \epsilon\end{aligned} \]&lt;/p&gt;&lt;p&gt;Let us define the Noether current \(J^\mu\) by&lt;/p&gt;&lt;p&gt;\[ J^\mu = \frac{\partial L}{\partial (\partial_\mu \phi)} \eta - f^\mu. \]&lt;/p&gt;&lt;p&gt;Then the previous computation showed that&lt;/p&gt;&lt;p&gt;\[ \frac{\delta S}{\delta \epsilon} = -\partial_\mu J^\mu. \]&lt;/p&gt;&lt;p&gt;If \(\phi\) is a solution to the Euler-Lagrange equations, then the variation \(dS\) vanishes, hence we obtain:&lt;/p&gt;&lt;p&gt;Theorem (Noether&amp;rsquo;s theorem) The Noether current is divergence free, i.e.&lt;/p&gt;&lt;p&gt;\[ \partial_\mu J^\mu = 0.\]&lt;/p&gt;&lt;p&gt;Functional Version&lt;/p&gt;&lt;p&gt;First, we derive the functional analogue of the classical equations of motion. Consider an expectation value&lt;/p&gt;&lt;p&gt;\[ \langle \mathcal{O(\phi)} \rangle= \int \mathcal{O}(\phi) e^{\frac{i}{\hbar} S} \mathcal{D}\phi \]&lt;/p&gt;&lt;p&gt;We&amp;rsquo;ll assume that \(\phi\) takes values in a vector space (or bundle). Then we can perform a change of variables \(\psi = \phi + \epsilon\), and since \(\mathcal{D}\phi = \mathcal{D}\psi\) we find that&lt;/p&gt;&lt;p&gt;\[ \int \mathcal{O}(\phi+\epsilon) \exp\left(\frac{i}{\hbar} S[\phi] \right) \mathcal{D}\phi \]&lt;/p&gt;&lt;p&gt;is independent of \(\epsilon\). Expanding to first order in \(\epsilon\), we have&lt;/p&gt;&lt;p&gt;\[ 0 = \int \left(\frac{\delta\mathcal{O}}{\delta \phi} +\frac{i \mathcal{O}}{\hbar} \frac{\delta S}{\delta \phi} \right)\exp \left( \frac{i}{\hbar} S \right) \mathcal{D}\phi  \]&lt;/p&gt;&lt;p&gt;So we find the quantum analogue of the equations of motion:&lt;/p&gt;&lt;p&gt;\[ \left\langle \frac{\delta \mathcal{O}}{\delta \phi} \right\rangle +\frac{i}{\hbar} \left\langle \mathcal{O} \frac{\delta S}{\delta \phi} \right\rangle = 0\]&lt;/p&gt;&lt;p&gt;Next, we move on to the quantum version of Noether&amp;rsquo;s theorem. Suppose there is a transformation \(Q\) of the fields leaving the action invariant. Assuming the path integral measure is invariant, we obtain&lt;/p&gt;&lt;p&gt;\[ \left\langle QF \right \rangle + \frac{i}{\hbar} \left\langle F QS \right\rangle = 0\]&lt;/p&gt;&lt;p&gt;To compare with the classical result, consider \(Q\) to be the (singular) operator&lt;/p&gt;&lt;p&gt;\[ Q = \frac{\delta}{\delta \epsilon(x)} \]&lt;/p&gt;&lt;p&gt;Then by the previous calculations,&lt;/p&gt;&lt;p&gt;\[ Q S = -\delta_\mu J^\mu, \]&lt;/p&gt;&lt;p&gt;so we obtain&lt;/p&gt;&lt;p&gt;\[ \left\langle \frac{\delta \mathcal{O}}{\delta \epsilon(x)} \right\rangle= \frac{i}{\hbar} \left\langle \mathcal{O} \partial_\mu J^\mu \right\rangle.  \]&lt;/p&gt;&lt;p&gt;This is the Ward-Takahashi identity, the quantum analogue of Noether&amp;rsquo;s theorem.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>The Moyal product</title>
       <link>https://jmf1sh.github.io/posts/2012-11-24-moyal-product/</link>
       <pubDate>Sat, 24 Nov 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-24-moyal-product/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Today I want to understand the Moyal product, as we will need to understand it in order to construct quantizations of symplectic quotients. (More precisely, to incorporate stability conditions.)&lt;/p&gt;&lt;p&gt;Let \(A\) be the algebra of polynomial functions on \(T^\ast \mathbb{C}^n\). This algebra has a natural Poisson bracket, given by&lt;/p&gt;&lt;p&gt;\[ {p_i, x_j} = \delta_{ij}. \]&lt;/p&gt;&lt;p&gt;We would like to define a new associative product \(\ast\) on \(A((\hbar))\) satisfying:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}f  \ast g &amp;amp;= fg + O(\hbar) \crf \ast g - g \ast f &amp;amp;= \hbar \{f, g\} + O(\hbar^2) \cr1 \ast f &amp;amp;= f \ast 1 = f \cr(f \ast g)^\ast &amp;amp;= -g^\ast \ast f^\ast\end{aligned} \]&lt;/p&gt;&lt;p&gt;In the last line, the map \((\cdot)^\ast\) takes \(x_i \mapsto x_i\) and \(p_i \mapsto -p_i\). To figure out what this new product should be, let&amp;rsquo;s take \(f,g \in A\) and expand \(f \ast g\) in power series:&lt;/p&gt;&lt;p&gt;\[ f \ast g = \sum_{n=0}^\infty c_n(f,g) \hbar^n \]&lt;/p&gt;&lt;p&gt;Now, equations (1) and (2) will be satisfied by taking \(c_0(f,g) = fg\) and \(c_1(f,g) = {f,g}/2\). Let \(\sigma\) be the Poisson bivector defining the Poisson bracket. This defines a differential operator \(\Pi\) on \(A \otimes A\) by&lt;/p&gt;&lt;p&gt;\[ \Pi = \sigma^{ij} (\partial_i \otimes \partial_j) \]&lt;/p&gt;&lt;p&gt;Let \(B = \sum_{n=0}^\infty B_n \hbar^n\) and write the product as&lt;/p&gt;&lt;p&gt;\[ f \ast g = m \circ B(f \otimes g). \]&lt;/p&gt;&lt;p&gt;Now, condition (2) tells us that \(B(0) = 1\) and that&lt;/p&gt;&lt;p&gt;\[ \left. \frac{dB}{d\hbar} \right|_{\hbar=0} = \frac{\Pi}{2} \]&lt;/p&gt;&lt;p&gt;So&lt;/p&gt;&lt;p&gt;\[ B = 1 + \frac{\hbar \Pi}{2} + O(\hbar^2) \]&lt;/p&gt;&lt;p&gt;It is natural to guess that \(B\) should be built out of powers of \(\Pi\), and a natural guess is&lt;/p&gt;&lt;p&gt;\[ B = \exp(\frac{\hbar \Pi}{2}), \]&lt;/p&gt;&lt;p&gt;which certainly reproduces the first two terms of our expansion. Let&amp;rsquo;s see that this choice actually works, i.e. defines an associative \(\ast\)-product. Let \(m: A \otimes A \to A\) be the multiplication, and&lt;/p&gt;&lt;p&gt;\(m_{12}, m_{23}: A \otimes A \otimes A \to A \otimes A\), \(m_{123}: A \otimes A \otimes A \to A\) the induced multiplication maps. Then&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}f \ast (g \ast h) &amp;amp;= m \circ(B( f \otimes m \circ B(g \otimes h) ) ) \cr&amp;amp;= m \circ B( m_{23} \circ (1 \otimes B)(f \otimes g \otimes h) ) \cr&amp;amp;= m_{123} (B \otimes 1)(1 \otimes B)(f \otimes g \otimes h)\end{aligned} \]&lt;/p&gt;&lt;p&gt;On the other hand, we have&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}(f \ast g) \ast h) &amp;amp;= m \circ(B( m \circ B(f \otimes g) \otimes h) ) ) \cr&amp;amp;= m \circ B( m_{12} \circ (B \otimes 1)(f \otimes g \otimes h) ) \cr&amp;amp;= m_{123} (1 \otimes B)(B \otimes 1)(f \otimes g \otimes h)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Hence, associativity is the condition&lt;/p&gt;&lt;p&gt;\[ m_{123} \circ [1\otimes B, B \otimes 1] = 0. \]&lt;/p&gt;&lt;p&gt;On \(A \otimes A \otimes A\), write \(\partial_i^1\) for the partial derivative acting on the first factor, \(\partial_i^2\) on the second, etc. Then&lt;/p&gt;&lt;p&gt;\[ 1 \otimes B = \sum_n \frac{\hbar^n}{2^n n!}\Pi^{i_1 j_1} \cdots \Pi^{i_n j_n} \partial^2_{i_1} \partial^3_{j_1} \cdots\partial^2_{i_n} \partial^3_{j_n} \]&lt;/p&gt;&lt;p&gt;and similarly for \(B \otimes 1\). So we have&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}m_{123} (B\otimes 1)(1 \otimes B) &amp;amp;= \sum_n \sum_{k=0}^n \frac {\hbar^n}{2^n k! (n-k)!}\Pi^{k_1 l_1} \cdots \Pi^{k_k l_k} \partial_{k_1} \partial_{l_1} \cdots\partial_{k_k} \partial_{l_k} \cr&amp;amp; \ \times  \Pi^{i_1 j_1} \cdots \Pi^{i_{n-k} j_{n-k}} \partial_{i_1} \partial_{j_1} \cdots\partial_{i_{n-k}} \partial_{j_{n-k}} \cr&amp;amp;= m_{123}(1 \otimes B)(B \otimes 1)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Hence we obtain an associative \(\ast\)-product. This is called Moyal product.&lt;/p&gt;&lt;h2 id=&#34;sheafifying-the-construction&#34;&gt;Sheafifying the Construction&lt;/h2&gt;&lt;p&gt;Now suppose that \(U\) is a (Zariski) open subset of \(X = T^\ast \mathbb{C}^n\). Then the star product induces a well-defined map&lt;/p&gt;&lt;p&gt;\[ \ast: O_X(U)((\hbar)) \otimes_\mathbb{C} O_X(U)((\hbar)) \to O_X(U)((\hbar)) \]&lt;/p&gt;&lt;p&gt;In this way we obtain a sheaf \(\mathcal{D}\) of \(O_X\) modules with a non-commutative \(\ast\)-product defined as above.&lt;/p&gt;&lt;p&gt;Define a \(\mathbb{C}^\ast\) action on \(T^\ast \mathbb{C}^n\) by acting on \(x_i\) and \(p_i\) with weight 1. Extend this to an action on \(\mathcal{D}\) by acting on \(\hbar\) with weight -1.&lt;/p&gt;&lt;p&gt;Proposition: The algebra \(C^\ast\)-invariant global sections of \(\mathcal{D}\) is naturally identified with the algebra of differential operators on \(\mathbb{C}^n\).&lt;/p&gt;&lt;p&gt;Proof: The \(\mathbb{C}^\ast\)-invariant global sections are generated by \(\hbar^{-1} x_i\) and \(\hbar^{-1} p_i\). So define a map \(\Gamma(\mathcal{D})^{\mathbb{C}^\ast} \to \mathbb{D}\) by&lt;/p&gt;&lt;p&gt;\[ \hbar^{-1} x_i \mapsto x_i \]&lt;/p&gt;&lt;p&gt;\[ \hbar^{-1} p_i \mapsto \partial_i \]&lt;/p&gt;&lt;p&gt;From the definition of the star product, it is clear that this is an algebra map, and that it is both injective and surjective.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>An exercise in quantum Hamiltonian reduction</title>
       <link>https://jmf1sh.github.io/posts/2012-11-22-quantum-hamiltonian-reduction/</link>
       <pubDate>Thu, 22 Nov 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-22-quantum-hamiltonian-reduction/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;semiclassical-setup&#34;&gt;Semiclassical Setup&lt;/h2&gt;&lt;p&gt;Let the group \(GL(2)\) act on \(V = \mathrm{Mat}_{2\times n}\) and consider theinduced symplectic action on \(T^\ast V\). If we use variables \((x,p)\) with \(x\)a \(2 \times n\) matrix and \(p\) an \(n \times 2\) matrix, then the classical momentmap \(\mu\) is given by&lt;/p&gt;&lt;p&gt;\[ \mu(x,p) = xp \]&lt;/p&gt;&lt;p&gt;This is equivariant with respect to the adjoint action, so we can form the\(GL(2)\)-invariant functions&lt;/p&gt;&lt;p&gt;\[ Z_1 = \mathrm{Tr} \mu \]&lt;/p&gt;&lt;p&gt;\[ Z_2 = \mathrm{Tr} (\mu)^2 \]&lt;/p&gt;&lt;p&gt;If we think of \(x\) as being made of column vectors&lt;/p&gt;&lt;p&gt;\[ x = ( x_1 \cdots x_n ) \]&lt;/p&gt;&lt;p&gt;and similarly think of \(p\) as being made of row vectors, then there are actuallymany more \(GL(2)\) invariants, given by&lt;/p&gt;&lt;p&gt;\[ f_{ij} = \mathrm{Tr} x_i p_j = p_j x_i \]&lt;/p&gt;&lt;p&gt;In terms of the invariants, the \(Z\) functions are&lt;/p&gt;&lt;p&gt;\[ Z_1 = \sum_k f_{kk} \]&lt;/p&gt;&lt;p&gt;\[ Z_2 = \sum_{jk} f_{jk} f_{kj} \]&lt;/p&gt;&lt;p&gt;Let us compute Poisson brackets:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}{f_{ij}, f_{kl}} &amp;amp;= {p_j^\mu x_i^\mu, p_l^\nu x_k^\nu} \cr&amp;amp;= x_i^\mu p_l^\nu \delta_{jk} \delta^{\mu\nu} - p_j^\mu x_k^\nu \delta_{il} \delta^{\mu\nu} \cr&amp;amp;= f_{il} \delta_{jk} - f_{kj} \delta_{il}.\end{aligned} \]&lt;/p&gt;&lt;p&gt;So we see that the invariants form a Poisson subalgebra (as they should!). Let&amp;rsquo;scompute:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\{Z_1, f_{ij}\} &amp;amp;= \sum_k \{ f_{kk}, f_{ij} \} \cr&amp;amp;= \sum_k \left( f_{kj} \delta_{ki} - f_{ik} \delta_{kj} \right) \cr&amp;amp;= f_{ij} - f_{ij} = 0.\end{aligned} \]&lt;/p&gt;&lt;p&gt;Hence \(Z_1\) is central with respect to the invariant functions \(f_{ij}\). Similarly,&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}{Z_2, f_{kl}} &amp;amp;= \sum_{ij} {f_{ij} f_{ji}, f_{kl}} \cr&amp;amp;= \sum_{ij} f_{ij} \left(f_{jl} \delta_{ik} - f_{ki} \delta_{jl} \right) + f_{ji} \left(f_{il} \delta_{jk} - f_{kj} \delta_{il} \right) \cr&amp;amp;= \sum_j f_{kj} f_{jl} - \sum_i f_{il} f_{ki} + \sum_i f_{ki} f_{il} - \sum_j f_{jl} f_{kj} \cr&amp;amp;= 0.\end{aligned} \]&lt;/p&gt;&lt;p&gt;So we see that the \(Z_i\) are in the center of the invariant algebra. In fact,they generate it, so we&amp;rsquo;ll denote by \(Z\) the algebra generated by \(Z_1, Z_2\).Let \(A\) be the algebra generated by the \(f_{ij}\). The inclusion\(Z \hookrightarrow A\) can be thought of as a purely algebraic version of themoment map. In particular, given any character \(\lambda: Z \to \mathbb{C}\), wecan define the Hamiltonian reduction of \(A\) to be&lt;/p&gt;&lt;p&gt;\[ A_\lambda := A / A\langle \ker \lambda \rangle \]&lt;/p&gt;&lt;p&gt;The corresponding space is of course \(\mathrm{Spec} A\).&lt;/p&gt;&lt;h2 id=&#34;the-cartan-algebra-and-the-center&#34;&gt;The Cartan Algebra and the Center&lt;/h2&gt;&lt;p&gt;Define functions&lt;/p&gt;&lt;p&gt;\[ h_1 = Z_1 = \sum_i f_{ii} \]&lt;/p&gt;&lt;p&gt;\[ h_2 = Z_2 = \sum_{ij} f_{ij} f_{ji} \]&lt;/p&gt;&lt;p&gt;\[ h_3 = \sum_{ijk} f_{ij} f_{jk} f_{ki} \]&lt;/p&gt;&lt;p&gt;\[ h_k = \sum_{i_1, i_2, \ldots, i_k} f_{i_1 i_2} f_{i_2 i_3} \cdots f_{i_k i_1} \]&lt;/p&gt;&lt;p&gt;These are just the traces of various powers of the \(n \times n\) matrix \(px\). Inparticular, \(h_k\) for \(k&amp;gt;n\) may be expressed as a function of the \(h_i\) for\(i \leq n\). The algebra generated by the \(H\) plays the role of a Cartansubalgebra. So we have inclusions&lt;/p&gt;&lt;p&gt;\[ Z \subset H \subset A \]Quantization&lt;/p&gt;&lt;p&gt;Now we wish to construct a quantization of \(A\) and \(A_\lambda\). Thequantization of \(A\) is obvious: we quantize \(T^\ast V\) by taking the algebraicdifferential operators on \(V\). Denote this algebra by \(\mathbb{D}\). It isgenerated by \(x_i\) and (\partial_i\( satisfying the relation&lt;/p&gt;&lt;p&gt;\[ [\partial_i, x_j] = \delta_{ij} \]&lt;/p&gt;&lt;p&gt;Then we simply the subalgebra of \(GL(2)\)-invariant differential operators asour quantization of \(A\). Call this subalgebra \(U\). We can define Hamiltonianreduction analogously by taking central quotients. So we need to understandthe center \(Z(U)\), but this is just the subalgebra generated byquantizations of \(Z_1\) and \(Z_2\), i.e. the subalgebra of all elements whoseassociated graded lies in \(Z(A)\).&lt;/p&gt;&lt;p&gt;More to come: stability conditions, \(\mathbb{D}\)-affineness, and maybe proofsof some of my claims.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>The 1PI effective action</title>
       <link>https://jmf1sh.github.io/posts/2012-11-07-1pi-effective-action/</link>
       <pubDate>Wed, 07 Nov 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-07-1pi-effective-action/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In this post I&amp;rsquo;d like to try to understand the 1PI effective action that isoften of interest. Suppose we have a QFT in some bosonic field \(\phi(x)\) takingvalues in a vector space (this is important). Then its vev\(\phi_{cl}(x) := \langle \phi(x) \rangle\) is just an ordinary (but possiblydistributional) field on spacetime. The question is, what is the field equationsatisfied by \(\phi_{cl}\)? I.e., if we average over quantum effects by replacingall fields by their vevs, what is the action that governs this (now completelyclassical) theory? The 1PI effective action answers exactly this question.&lt;/p&gt;&lt;p&gt;Consider the generating functional&lt;/p&gt;&lt;p&gt;\[ Z[J] = \int e^{-S[\phi]+\langle \phi, J \rangle} \mathcal{D}\phi \]&lt;/p&gt;&lt;p&gt;Then for a given source \(J\), define the \(J\)-vev of \(\phi(x)\) to be&lt;/p&gt;&lt;p&gt;\[ \phi_J(x) = \frac{\partial \log Z[J]}{\partial J}. \]&lt;/p&gt;&lt;p&gt;Now let&amp;rsquo;s take \(\Gamma\) to be the Legendre transform of \(\log Z\) with respectto \(J\):&lt;/p&gt;&lt;p&gt;\[ \Gamma[\phi_J] = \langle J, \phi_J \rangle - \log Z[J] \]&lt;/p&gt;&lt;p&gt;Then we compute:&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \Gamma}{\partial \phi_J} = J + \frac{\partial J}{\partial \phi_J} \phi_J -\frac{\partial \log Z[J]}{\partial J} \frac{\partial J}{\partial \phi_J} = J. \]&lt;/p&gt;&lt;p&gt;Now consider the situation without a background source, i.e. \(J = 0\). Then\(\phi_0 = \phi_{cl}\) and we find&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \Gamma}{\partial \phi_{cl}} = 0 \]&lt;/p&gt;&lt;p&gt;Hence, \(\phi_{cl}\) satisfies the Euler-Lagrange equations associated to thefunctional \(\Gamma\). Note that from the Legendre transform, \(\Gamma\) takesquantum effects (i.e. Feynman diagrams with loops) into account, even thoughthe field and the equations are purely classical!&lt;/p&gt;&lt;p&gt;By studying these equations, we might find instanton solutions (or solitons in Lorentz signature).&lt;/p&gt;&lt;p&gt;Now for the name. Some combinatorics and algebra (which I will skip!) show that\(\Gamma[\phi_{cl}]\) is itself a generating functional for certain correlationfunctions, then 1PI correlation functions:&lt;/p&gt;&lt;p&gt;\[ \frac{\partial^n \Gamma}{\partial \phi(x_1) \cdots \partial \phi(x_n)} = \langle \phi(x_1) \cdots \phi(x_n) \rangle_{1PI}. \]&lt;/p&gt;&lt;p&gt;The 1PI subscript means that the RHS is computed in perturbation theory bysumming over only the connection 1PI (1 particle irreducible) Feynman diagrams.&lt;/p&gt;&lt;p&gt;Warning: As usual, there are regularization issues, both in the UV and IR. UVdivergences can be solved by a cutoff (if we only care about effective fieldtheory), but IR divergences are much more technical. For this reason (andothers), it is sometimes preferable to try to understand the low energy dynamicsby studying the Wilsonian effective action. As the Wilsonian effective actiondoes not take IR modes into account, it can avoid many of the difficulties ofthe 1PI effective action.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Spontaneous symmetry breaking in QFT</title>
       <link>https://jmf1sh.github.io/posts/2012-11-05-spontaneous-symmetry-breaking-qft/</link>
       <pubDate>Mon, 05 Nov 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-05-spontaneous-symmetry-breaking-qft/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In this post I want to try to understand symmetry breaking and the origin of the moduli space of vacua. Most of this can be found in the lectures by Witten in vol. 2 of Quantum Fields and Strings.&lt;/p&gt;&lt;h2 id=&#34;non-example-quantum-mechanics&#34;&gt;Non-Example: Quantum Mechanics&lt;/h2&gt;&lt;p&gt;The main point of confusion for me is that my quantum intuition comes from ordinary quantum mechanics. However, this turns out to be incredibly misleading because for most reasonable quantum mechanical systems, spontaneous symmetry breaking cannot occur. In fact, we&amp;rsquo;ll see that even in field theory, the question of whether spontaneous symmetry breaking can occur is intimately related to the geometry of spacetime. Since quantum mechanics is QFT in \(0+1\) dimensions (i.e., the spatial part of spacetime is just a point), spontaneous symmetry breaking is forbidden.&lt;/p&gt;&lt;p&gt;Consider a particle in one spatial dimension, with Hamiltonian&lt;/p&gt;&lt;p&gt;\[ H = -\frac{\hbar^2}{2} + (a^2-x^2)^2. \]&lt;/p&gt;&lt;p&gt;The classical ground states are given by the stationary solutions \(x(t) = \pm a\). Hence we might expect that the quantum Hamiltonian has a degenerate ground state, i.e. the eigenspace of the lowest eigenvalue has dimension greater than one. However, this is not the case!&lt;/p&gt;&lt;p&gt;Sketch of proof: Define a function \(E(\phi)\) on the unit sphere in \(L^2(\mathbb{R})\). If \(\phi\) is a global minimum, then it necessarily satisfies \(H\psi = E_0 \phi\) where \(E_0\) is the lowest eigenvalue of \(H\). On the other hand, \(E(\phi) = E(|\phi|)\) so \(|\phi|\) is also a global minimum, hence satisfies \(H|\phi| = E_0|\phi|\). This equation is elliptic, so by elliptic regularity \(|\phi|\) must be at least \(C^1\), and hence \(\phi(x)\) has constant phase, so we might as well take \(\phi(x)\) to be real and positive. Any other ground state \(\psi\) would have these properties, and hence \((\phi,\psi) \neq 0\). Hence the eigenspace is 1-dimensional and the ground state is not degenerate.&lt;/p&gt;&lt;p&gt;Now by the Stone-von Neumann theorem, there is a unique irreducible representation of the canonical commutation relations on a separable Hilbert space, and by the argument above there is a unique (up to scale) vector \(|\Omega\rangle\) which is the ground state of the Hamiltonian, called the vacuum vector. So for QM, we find a unique representation on \(\mathcal{H}\) together with a unique vacuum vector \(|\Omega\rangle \in \mathcal{H}\). The point I want to stress here is that the Poisson algebra of observables together with the Hamiltonian determine the data \(\mathcal{H}, |\Omega\rangle)\) in an essentially unique way, so there is no ambiguity in quantization and no further choices need to be made.&lt;/p&gt;&lt;h2 id=&#34;qft-in-finite-volume&#34;&gt;QFT in Finite Volume&lt;/h2&gt;&lt;p&gt;Now we&amp;rsquo;ll argue that a similar symmetry breaking phenomenon should be expected whenever the spatial part of spacetime has finite volume. We&amp;rsquo;ll have to use formal path integral arguments, so of course this won&amp;rsquo;t be totally rigorous. Suppose we have two representations \(\mathcal{H}_\pm\) with vacua \(|\Omega\rangle_\pm\). Then we consider the direct sum \(\mathcal{H} = \mathcal{H}_+ \oplus \mathcal{H}_-\). Then by construction, we should have&lt;/p&gt;&lt;p&gt;\[ (\Omega_+, e^{-tH} \Omega_-) = 0 \]&lt;/p&gt;&lt;p&gt;since \(|\Omega\rangle_\pm\) are orthogonal eigenstates of \(H\). On the other hand, we can compute this inner product using the Feynman-Kac formula. The semi-classical approximation to the path integral yields&lt;/p&gt;&lt;p&gt;\[ (\Omega_+, e^{-tH} \Omega_-) = C \exp\left(- \frac{S(t) V}{\hbar} \right) \]&lt;/p&gt;&lt;p&gt;Where \(S(t)\) is the classical least action and \(V\) is the volume of space. If \(V &amp;lt; \infty\), the right hand side is non-zero, contradicting our assumptions! Hence the vacuum is non-degenerate. So we find that QFT with finite spatial volume is much like QM, at least as far as symmetry breaking is concerned.&lt;/p&gt;&lt;p&gt;Note that this argument is essentially just a formal manipulation of the path integral, so you should expect a result of this form independent of the particular regularization scheme used to define the path integral.&lt;/p&gt;&lt;h2 id=&#34;qft-in-infinite-volume&#34;&gt;QFT in Infinite Volume&lt;/h2&gt;&lt;p&gt;Now we consider the case \(V = \infty\), i.e. a non-compact space. Then the preceding argument fails spectacularly, as does the Stone-von Neumann theorem. So there is no guarantee of a unique irreducible representation of the algebra, and no guarantee of a unique vacuum vector.&lt;/p&gt;&lt;p&gt;So we see that the situation is significantly more complicated. We can expect a moduli space \(\mathcal{M}\) of vacua of the theory, and the low energy effective theory is described by a \(\sigma\)-model with target \(\mathcal{M}\). I&amp;rsquo;ll try to discuss this in more detail in follow-up posts.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Seiberg-Witten theory and the Riemann-Hilbert problem</title>
       <link>https://jmf1sh.github.io/posts/2012-11-04-seiberg-witten-riemann-hilbert/</link>
       <pubDate>Sun, 04 Nov 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-11-04-seiberg-witten-riemann-hilbert/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;References:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Introduction to Seiberg-Witten theory and its stringy origin&lt;/li&gt;&lt;li&gt;Seiberg-Witten and follow-up&lt;/li&gt;&lt;/ul&gt;&lt;h2 id=&#34;the-classical-moduli-space-of-vacua&#34;&gt;The Classical Moduli Space of Vacua&lt;/h2&gt;&lt;p&gt;For definiteness, we&amp;rsquo;ll consider just the case of \(SU(2)\) considered by Seiberg and Witten. There is a scalar Higgs field \(\phi\). The classical vacua of the theory are given by the absolute minima of the potential energy, which in this case is proportional to&lt;/p&gt;&lt;p&gt;\[ \mathrm{Tr}[\phi, \phi^\dagger]^2 \]&lt;/p&gt;&lt;p&gt;Hence at the minimum, \([\phi,\phi^\dagger]=0\) and \(\phi\) is diagonalizable. Hence the classical moduli space of vacua \(\mathcal{M}_{cl}\) is just \(\mathbb{C}\), with complex coodinate \(a\), corresponding to the Higgs field&lt;/p&gt;&lt;p&gt;\[ \phi = \left( \begin{array}{rr}a &amp;amp; 0 \cr 0 &amp;amp; -a\end{array} \right) \]&lt;/p&gt;&lt;p&gt;Actually, due to gauge invariance, it is better to introduce another copy of the complex plane \(\mathcal{B}\) with local coordinate \(u = \frac{1}{2} Tr \phi^2 = a^2\). Then we can think of \(\mathcal{M}_{cl}\) as a branched cover of \(\mathcal{B}\), with \(a\) a (local) choice of square root of \(u\).&lt;/p&gt;&lt;p&gt;The goal is to understand the low energy effective theory. We introduce a cutoff \(\Lambda\) to define the quantum theory, and integrate out all degrees of freedom except for the low momentum modes of \(\phi\) (in particular, we integrate out the gauge field d.o.f.). The result is a \(\sigma\)-model with target \(\mathcal{M}_{cl}\). The kinetic term of the \(\sigma\)-model is governed by the metric on \(\mathcal{M}_{cl}\), hence the low energy effective action determines a metric on \(\mathcal{M}_{cl}\).&lt;/p&gt;&lt;p&gt;We&amp;rsquo;ll see that 1-loop calculations introduce monodromy, so that in the quantum theory, &amp;ldquo;functions&amp;rdquo; on \(\mathcal{M}_{cl}\) are actually sections of non-trivial bundles over \(\mathcal{M}_{cl}\), and furthermore that the metric receives corrections from instantons (or BPS states). So what we really would like to understand/construct is the quantum moduli space of vacua \(\mathcal{M}\), which will be some non-trivial modification of \(\mathcal{M}_{cl}\). The key to the Seiberg-Witten solution is that susy allows us to reduce the problem to finding a specified set of holomorphic functions (in the \(u\) coordinate) satsfying certain monodromies, and that once we know the monodromies the solution is given to us by the Riemann-Hilbert correspondence.&lt;/p&gt;&lt;h2 id=&#34;the-riemann-hilbert-correspondence&#34;&gt;The Riemann-Hilbert Correspondence&lt;/h2&gt;&lt;p&gt;Let \(X\) be \(\mathbb{P}^1\) with punctures at the points \(z_1, \ldots, z_n\). Let \(U\) be the universal cover of \(X\) and let \(G\) be the fundamental group of \(X\) (pick some basepoint away from the punctures). A set of monodromy matrices is exactly what is needed to specify a representation \(V\) of \(G\). Since \(U / G = X\), we can form the associated bundle \(E = U \times_G V\) over \(X\). The (trivial) \(G\)-connection on \(U \to X\) induces a flat connection \(\nabla\) on \(E\). This gives a map from representations of \(G\) to flat connections on \(X\).&lt;/p&gt;&lt;p&gt;Conversely, given a flat connection on \(X\), the monodromy about the punctures determines a representation of \(G\). Hence monodromy is a map from flat connections on \(X\) to representations of \(G\). The Riemann-Hilbert correspondence is that these two maps are bijections, modulo the natural notions of equivalence (conjugacy and gauge transformations).&lt;/p&gt;&lt;h2 id=&#34;gross-overview-of-the-seiberg-witten-approach&#34;&gt;Gross Overview of the Seiberg-Witten Approach&lt;/h2&gt;&lt;p&gt;We are now ready to sketch the &amp;ldquo;big picture&amp;rdquo; idea of Seiberg and Witten, which applies not only to their \(N=2, d=4\) example but also to certain other compactifications of the \(N=1, d=6\) theory (in particular, the one considered by Gaiotto-Moore-Neitzke).&lt;/p&gt;&lt;p&gt;As discussed above, the theory will have a classical moduli space of vacua \(\mathcal{M}\), which turns out to be a complex manifold (or variety, and possibly with singularities). We&amp;rsquo;ll let \(u\) be an abstract local complex coordinate on \(\mathcal{M}\). Supersymmetry then tells us that the main quantities we are interested in (to compute the low energy effective action) are holomorphic in \(u\) (away from the singularities/punctures of \(\mathcal{M}\)!). The general outline is as follows:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Identify functions \(f_i(u)\) which by susy are holomorphic in \(u\).&lt;/li&gt;&lt;li&gt;Compute the 1-loop corrections to \(f_i(u)\).&lt;/li&gt;&lt;li&gt;Compute monodromies of the corrected \(f_i(u)\).&lt;/li&gt;&lt;li&gt;Find the desired \(f_i(u)\) by solving the Riemann-Hilbert problem for these monodromies.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Now, to be more clear, it is a consequence of susy that the renormalized quantities \(f_i(u)\) are given schematically by&lt;/p&gt;&lt;p&gt;\[ f_{i, \mathrm{ren}}(u) = f_{i, \mathrm{cl}}(u) + f_{i,1}(\frac{u}{\Lambda}) + \sum_{k=0}^\infty c_{i,k} \left(\frac{\Lambda}{u} \right)^k \]&lt;/p&gt;&lt;p&gt;Here, \(f_{i,\mathrm{cl}}(u)\) is the classical function, \(f_{i,1}(u)\) is the one-loop correction, and the terms in the series are corrections coming from instantions (BPS states). Non-renormalization theorems due to susy guarantee that there are no higher loop corrections. One expects the instanton series to converge, and hence the monodromy is completely determined by the one-loop calculation. This is the key: by Riemann-Hilbert, the monodromy determines the \(f_i(u)\) uniquely&amp;ndash;solving the Riemann-Hilbert problem is equivalent to computing the infinitely-many instantion corrections!&lt;/p&gt;&lt;p&gt;Now in general, solving the Riemann-Hilbert problem is difficult, so this reduction is of a theoretical but not necessarily practical nature. The second main idea of Seiberg and Witten is that we can solve this Riemann-Hilbert problem explicitly by introducing a family of curves \({C_u}_{u\in\mathcal{B}}\), called Seiberg-Witten curves (or spectral curves).&lt;/p&gt;&lt;h2 id=&#34;electric-magnetic-duality&#34;&gt;Electric-Magnetic Duality&lt;/h2&gt;&lt;p&gt;An absolutely key requirement of the Seiberg-Witten construction is electric-magnetic duality. Maxwell&amp;rsquo;s equations in vacuum are&lt;/p&gt;&lt;p&gt;\[ dF = 0, \ \ \ d\ast F = 0. \]&lt;/p&gt;&lt;p&gt;Here \(F\) is a 2-form, and \(\ast F\) is its Hodge dual, a \((d-2)\)-form in \(d\)-dimensions. The first equation implies that \(F = dA\) for some 1-form \(A\), and we normally think of the second equation as the Euler-Lagrange equations for the action written in terms of \(A\). However, we could equally well take the starting point to be the second equation, taking \(\ast F = dB\), and take the first equation to be the Euler-Lagrange equations for \(B\). The problem with either of these approaches is that they allow particles of either electric or magnetic charge, but not both.&lt;/p&gt;&lt;p&gt;To put electric and magnetic charge on equal footing, we introduce fields \(F\) and \(F_D\) (a 2-form and a (d-2)-form). Then the Lagrangian is (up to factors that I&amp;rsquo;m too lazy to care about)&lt;/p&gt;&lt;p&gt;\[ \mathcal{L} = \mathrm{Tr} F \wedge F_D \]&lt;/p&gt;&lt;p&gt;However, to recover Maxwell&amp;rsquo;s equations, we need to impose \(\ast F_D = F\) as a constraint. So to get the right equations of motion, introduce an auxiliary field \(\lambda\) (a Lagrange multiplier), and modify the Lagrangian:&lt;/p&gt;&lt;p&gt;\[ \mathcal{L} = \mathrm{Tr} F \wedge F_D + \lambda(F - \ast F_D) \]&lt;/p&gt;&lt;p&gt;Variation with respect to \((F, F_D, \lambda)\) will reproduce Maxwell&amp;rsquo;s equations exactly, but in this form the EM duality is manifest. Since EM duality exchanges electric and magnetic charges, we should consider how to modify the Lagrangian to couple the field to EM sources. Let \(J_e, J_m\) be the electric and magnetic currents, respectively. Up to conventions, Maxwell&amp;rsquo;s equations read&lt;/p&gt;&lt;p&gt;\[ dF = J_m, \ \ \ d F_D = J_e. \]&lt;/p&gt;&lt;p&gt;Then we take the Lagrangian to be&lt;/p&gt;&lt;p&gt;\[ \mathcal{L} = \mathrm{Tr} F \wedge F_D + \lambda(F - \ast F_D) + F \wedge J_e + J_m \wedge F_D \]&lt;/p&gt;&lt;p&gt;to reproduce the right equations of motion.&lt;/p&gt;&lt;p&gt;In this form, we can consider particles with electric or magnetic charge (or both&amp;ndash;dyons). If our gauge group has rank \(r\), then the lattice of electric charges is \(\mathbb{Z}^r\), while the lattice of magnetic charges is \((\mathbb{Z}^\ast)^r\). Hence the lattice of electromagnetic charges is&lt;/p&gt;&lt;p&gt;\[ \Gamma = \mathbb{Z}^r \oplus (\mathbb{Z}^\ast)^r \]&lt;/p&gt;&lt;p&gt;which comes with a natural symplectic pairing&lt;/p&gt;&lt;p&gt;\[\langle \cdot, \cdot \rangle: \Gamma \otimes \Gamma \to \mathbb{Z}.\]&lt;/p&gt;&lt;p&gt;(You might ask why we take the natural sympletic pairing as opposed to the natrual symmetric pairing. This is because there is actually a larger \(SL(2,\mathbb{Z})\) symmetry of the theory which preserves the symplectic pairing but not the symmetric pairing.)&lt;/p&gt;&lt;p&gt;Now there is an obvious source of symplectic lattices. Simply let \(C\) be a genus \(r\) compact Riemann surface. Then \(\Gamma = H_1(C, \mathbb{Z})\) is a symplectic lattice of rank \(2r\), where the symplectic pairing is now given by the intersection pairing. In fact, we can say more&amp;ndash;if we take \(a\)- and \(b\)-cycles as generators, these form a Darboux (symplectic) basis of \(\Gamma\).&lt;/p&gt;&lt;p&gt;Back to the gauge theory problem. Recall that the 1-loop calculation and consideration of BPS states leads to a set of monodromy data on \(\mathcal{B}\). Suppose now that we could find a complex surface \(C \to \mathcal{B}\) whose fibers \(C_u\) are (possibly singular) genus \(r\) curves, and such that the monodromies of \(\Gamma_u := H_1(C_u, \mathbb{Z})\) agree with the given monodromies. Then we can solve the Riemann-Hilbert problem by doing geometry on this family, i.e. by finding holomorphic sections of certain associated bundles.&lt;/p&gt;&lt;h2 id=&#34;the-su2-seiberg-witten-solution&#34;&gt;The SU(2) Seiberg-Witten Solution&lt;/h2&gt;&lt;p&gt;We will now specialize to the case considered in the original paper of Seiberg and Witten. I will only construct the family&amp;ndash;the details of the solution will follow in a subsequent post.&lt;/p&gt;&lt;p&gt;In this case, the group has rank \(r=1\), so we should be looking for a family of elliptic curves. In this case, the solution is almost obvious, given what I&amp;rsquo;ve said above. Seiberg and Witten argue that the moduli space \(\mathcal{B}\) must be \(\mathbb{C} \setminus {\Lambda^2, -\Lambda^2}\). The punctures at \(\pm \Lambda^2\) come from BPS states whose mass goes to zero at those values of \(u\). So the monodromy consists of three matrices, \(M_\infty, M_\pm\), the monodromies computed around \(\infty\) and \(\pm \Lambda^2\). These generate a certain modular subgroup \(G\) of \(SL(2, \mathbb{Z})\), allowing us to realize \(\mathcal{B}\) as the modular curve \(H / G\) (where \(H\) is the upper half-plane). Now, the space of elliptic curves is just \(H / SL(2, \mathbb{Z})\). So given any \(u \in \mathbb{B}\), we pick a lift \(\tilde{u}\) in \(H\) and let \(C_u\) be the corresponding elliptic curve. This is exactly the family needed to solve the Riemann-Hilbert problem!&lt;/p&gt;&lt;p&gt;Next time: details of this construction, including exact formulas, and some words about instanton counting.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>BPS states and wall-crossing</title>
       <link>https://jmf1sh.github.io/posts/2012-10-29-bps-wall-crossing/</link>
       <pubDate>Mon, 29 Oct 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-10-29-bps-wall-crossing/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;This is the first in what I hope will become a series of posts on BPS statecounting and wall-crossing. I&amp;rsquo;m participating in gLab, and our most immediategoal is to understand the Kontsevich-Soibelman wall-crossing formula (KSWCF) inthe context of quadratic differentials on a (punctured) Riemann surface,following the lectures of Kontsevich and Neitzke at IHES.&lt;/p&gt;&lt;p&gt;The purpose of these posts is to keep a written record of my attempts tounderstand the physics behind the WCF as well as the work ofGaiotto-Moore-Neitzke.&lt;/p&gt;&lt;p&gt;References:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Witten&amp;rsquo;s lectures on dynamics of QFT&lt;/li&gt;&lt;li&gt;Gaiotto-Moore-Neitzke&lt;/li&gt;&lt;li&gt;Kontsevich-Soibelman&lt;/li&gt;&lt;li&gt;Seiberg and Witten&lt;/li&gt;&lt;li&gt;Distler&amp;rsquo;s blogpost, and&lt;/li&gt;&lt;li&gt;This post on the n-Category cafe (note: Bridgeland&amp;rsquo;s talk relates quadratic differentials to stability conditions).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Video Lectures:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;IHES Lectures by Neitzke and Kontsevich&lt;/li&gt;&lt;li&gt;Lectures by Moore on the (2,0) d=6 superconformal theory&lt;/li&gt;&lt;li&gt;PITP 2010 (Gaiotto, Moore, Witten, Seiberg, others!)&lt;/li&gt;&lt;li&gt;Neitzke: What is a BPS state?&lt;/li&gt;&lt;li&gt;Gauge fields and strings&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Physics Setup:&lt;/p&gt;&lt;p&gt;Warning: I&amp;rsquo;m still trying to sort this all out, so a lot of this will be fuzzyand/or completely wrong. I will try to point out the points of confusion.&lt;/p&gt;&lt;p&gt;We will start with some kind of family of susy gauge theories (or rather, asingle  &amp;ldquo;theory&amp;rdquo; with a family of vacua, depending on what asymptotic boundaryconditions we specify in the path integral). We let \(\mathcal{B}\) be some kindof manifold (or variety, possibly with singularities?), and\({\mathcal{H}_u}_{u \in \mathcal{B}}\) a family (bundle) of Hilbert spaces,depending on \(u \in \mathcal{B}\). Concretely, \(\mathcal{B}\) will parametrize thevacuum expectation values (VEVs) of the scalar fields of the theory. (Note, fornon-scalar fields we can typically expect VEVs to vanish, for example by lookingat the action of the Lorentz group.) Actually, to be more precise, \(\mathcal{B}\)parametrizes the Coulomb branch&amp;ndash;where the VEVs break the gauge symmetry to amaximal torus (as opposed to the Higgs branch, where the VEVs just break thegauge group to a smaller subgroup).&lt;/p&gt;&lt;p&gt;The next ingredient is a lattice \(\Gamma\), the charge lattice, which is supposedto parametrize all possible electric and magnetic charges. Since electric andmagnetic charges are dual, this lattice has a pairing\(\Gamma \otimes \Gamma \to \mathbb{Z}\) which is symplectic (or possibly justPoisson?). (Actually, maybe we should think of \(\Gamma\) as being a bundle oflattices over \(\mathcal{B}\), but this isn&amp;rsquo;t completely clear to me.) The latticegives a grading of \(\mathcal{H}\):&lt;/p&gt;&lt;p&gt;\[ \mathcal{H} = \bigoplus_{\gamma \in \Gamma} \mathcal{H}_\gamma \].&lt;/p&gt;&lt;p&gt;Now, the Hilbert spaces \(\mathcal{H}_u\) are supposed to carry representations ofthe \(\mathcal{N}=2\) susy algebra, with central charge \(Z\). On any state ofcharge \(\gamma\) above the point \(u \in \mathcal{B}\), the central charge \(Z\) actsas a scalar, which we denote by \(Z_\gamma(u)\). Manipulations with the susyalgebra show the BPS bound \(M \geq |Z_\gamma(u)|\), where \(M\) is the mass of astate with charge \(\gamma\). A state is called BPS if it saturates this bound.&lt;/p&gt;&lt;p&gt;Finally, I&amp;rsquo;ll end this post by attempting to define (or at least motivate) thewalls of marginal stability. In all known examples, we have&lt;/p&gt;&lt;p&gt;\[ |Z_{\gamma_1 + \gamma_2}(u)|^2 = |Z_{\gamma_1}(u)|^2 + |Z_{\gamma_2}(u)|^2 +2 \mathrm{Re}(Z_{\gamma_1}(u) \bar{Z}_{\gamma_2}(u) ) \]&lt;/p&gt;&lt;p&gt;If the cross-term is negative, then it is possible to form stable bound states(since the mass of a BPS state of charge \(\gamma_1+\gamma_2\) is strictly lessthan the sum of the corresponding masses); and it is impossible to form stablebound states if the cross-term is positive. This (naive!) dichotomy tells usthat there is something very special about the intermediate case. For a pair ofcharges \(\gamma_1, \gamma_2\) we define a wall in \(\mathcal{B}\) by&lt;/p&gt;&lt;p&gt;\[ W(\gamma_1, \gamma_2) = {u \in \mathcal{B} \ | \ \mathrm{Re}(Z_{\gamma_1}(u)\bar{Z}_{\gamma_2}(u)) = 0 } \]&lt;/p&gt;&lt;p&gt;and we define \(W \subset \mathcal{B}\) to be the union of all the walls.&lt;/p&gt;&lt;p&gt;The idea of wall-crossing is the following. We define some functions\(\Omega(\gamma; u)\) on \(\mathcal{B} \setminus W\) which are locally constant.These functions are supposed to count the number of BPS states of charge\(\gamma\) (where count really means take the trace of a particular operator over\(\mathcal{H}_{\gamma, \mathrm{BPS}}\)). The wall-crossing formula is an explicitformula that relates \(\Omega(\gamma; u_+)\) and \(\Omega(\gamma; u_-)\) for\(u_+, u_-\) on opposite sides of a wall in \(\mathcal{B}\). There are twoapplications of WCF:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;We pick some particular \(u \in \mathcal{B}\) for which \(\Omega\) isparticularly easy to calculate (&amp;ldquo;extreme stability&amp;rdquo;). Then by KSWCF we actuallyknow how to compute \(\Omega\) on all of \(\mathcal{B} \setminus W\).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gaiotto-Moore-Neitzke study a certain QFT whose low energy effective actionis a sigma model with target space \(\mathcal{M}\), the moduli space of Higgsbundles over a Riemann surface. The invariants \(\Omega(\gamma; u)\) together withKSWCF allow them to compute the low energy effective action explicitly, givingan explicit construction of holomorphic Darboux coordinates on \(\mathcal{M}\).This is enough to recover the full hyperkahler metric on \(\mathcal{M}\), in localcoordinates!&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Tasklist (incomplete!):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Define susy algebra, derive BPS bound&lt;/li&gt;&lt;li&gt;Understand/construct the charge lattice and its pairing&lt;/li&gt;&lt;li&gt;Sketch that 3d sigma model with \(\mathcal{N}=4\) has a hyperkahler target&lt;/li&gt;&lt;li&gt;Sketch/understand why the low energy effective action has target Higgs&lt;/li&gt;&lt;li&gt;Understand computation of effective action: Seiberg-Witten curves and all that&lt;/li&gt;&lt;li&gt;Understand how KSWCF implies consistency of the Darboux coordinates&lt;/li&gt;&lt;/ul&gt;</description>
     </item>
   
     <item>
       <title>Seiberg-Witten theory video lectures</title>
       <link>https://jmf1sh.github.io/posts/2012-10-22-seiberg-witten-video-lectures/</link>
       <pubDate>Mon, 22 Oct 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-10-22-seiberg-witten-video-lectures/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I found some lectures by Sara Pasquetti on Seiberg-Witten theory here:&lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=jvNRbdlp-Sg&#34;&gt;Lecture 1&lt;/a&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=uz61-ryl_Ck&#34;&gt;Lecture 2&lt;/a&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6AWOrAYkCTU&#34;&gt;Lecture 3&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Unfortunately, it seems that the quality is so poor that it is impossible to read the blackboard!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>A toy model for effective theory from extra dimensions</title>
       <link>https://jmf1sh.github.io/posts/2012-08-27-toy-model-extra-dimensions/</link>
       <pubDate>Mon, 27 Aug 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-08-27-toy-model-extra-dimensions/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I wanted to see how the Fourier transform can turn field theory into many-particle mechanics. This is just silly fooling around, so you shouldn&amp;rsquo;t take what follows too seriously (there are much better models of extra dimensions, to be sure!).&lt;/p&gt;&lt;p&gt;Take \(\phi(t, s)\) to be a field on a cylinder of radius \(R\). We consider the action&lt;/p&gt;&lt;p&gt;\[ S = \frac{1}{R} \int_{-\infty}^\infty \int_0^{R} |\nabla \phi|^2 ds dt \]&lt;/p&gt;&lt;p&gt;Expand \(\phi(t, s)\) in Fourier series:&lt;/p&gt;&lt;p&gt;\[ \phi(t,s ) = \sum_n \phi_n(t) e^{2 \pi i n s / R} \]&lt;/p&gt;&lt;p&gt;Then in Lorentzian signature, we have&lt;/p&gt;&lt;p&gt;\[ \int_0^{R} |\nabla \phi|^2 d\theta = R \sum_n \dot{\phi}_n^2 - \left(\frac{2\pi n}{R}\right)^2 \phi_n^2. \]&lt;/p&gt;&lt;p&gt;Putting this back into the action, we find&lt;/p&gt;&lt;p&gt;\[ S = \sum_n \int_{-\infty}^\infty \dot{\phi}_n^2- \left(\frac{2\pi n}{R}\right)^2 \phi_n^2 dt. \]&lt;/p&gt;&lt;p&gt;This is the action for infinitely many harmonic oscillators, with frequencies \(\omega_n = 2\pi |n| / R\). Recall that the energy levels of the harmonic oscillator are \(k\omega\) for \(k = 0, 1, \ldots\). So supposing that only a finite energy \(E\) is accessible in some particular experiment, we can only excite those modes \(\phi_n\) for which&lt;/p&gt;&lt;p&gt;\[ \frac{2\pi |n|}{R} &amp;lt; E. \]&lt;/p&gt;&lt;p&gt;In particular, only finitely many \(\phi_n\) may be excited at energies below \(E\), effectively reducing the field theory on the cylinder to many-particle quantum mechanics.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Generating functions</title>
       <link>https://jmf1sh.github.io/posts/2012-07-26-generating-functions/</link>
       <pubDate>Thu, 26 Jul 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-07-26-generating-functions/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2012/07/generating-functions.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;method-of-generating-functions&#34;&gt;Method of Generating Functions&lt;/h2&gt;&lt;p&gt;Let \(X\) and \(Y\) be two smooth manifolds, and let \(M = T^\ast X, N = T^\ast Y\) with corresponding symplectic forms \(\omega_M\) and \(\omega_N\).&lt;/p&gt;&lt;p&gt;Question: How can we produce symplectomorphisms \(\phi: M \to N\)?&lt;/p&gt;&lt;p&gt;The most important construction from classical mechanics is the method of generating functions. I will outline this method, shameless stolen from Ana Cannas da Silva&amp;rsquo;s lecture notes.&lt;/p&gt;&lt;p&gt;Suppose we have a smooth function \(f \in C^\infty(X \times Y)\). Then its graph \(\Gamma\) is a submanifold of \(M \times N\): \( \Gamma = { (x,y, df_{x,y}) \in M \times N }\). Since \(M \times N\) is a product, we have projections \(\pi_M, \pi_N\), and this allows us to write the graph as&lt;/p&gt;&lt;p&gt;\[ \Gamma = { (x, y, df_x, df_y) }\]&lt;/p&gt;&lt;p&gt;Now there is a not-so-obvious trick: we consider the twisted graph \(\Gamma^\sigma\) given by&lt;/p&gt;&lt;p&gt;\[ \Gamma^\sigma =  {(x,y, df_x, -df_y) } \]&lt;/p&gt;&lt;p&gt;Note the minus sign.&lt;/p&gt;&lt;p&gt;Proposition If \(\Gamma^\sigma\) is the graph of a diffeomorphism \(\phi: M \to N\), then \(\phi\) is a symplectomorphism.&lt;/p&gt;&lt;p&gt;Proof By construction, \(\Gamma^\sigma\) is a Lagrangian submanifold of \(M \times N\) with respect to the twisted symplectic form \(\pi_M^\ast \omega_M - \pi_N^\ast \omega_N\). It is a standard fact that a diffeomorphism is a symplectomorphism iff its graph is Lagrangian with respect to the twisted symplectic form, so we&amp;rsquo;re done.&lt;/p&gt;&lt;p&gt;Now we have:&lt;/p&gt;&lt;p&gt;Modified question: Given \(f \in C^\infty(M \times N)\), when is its graph the graph of a diffeomorphism \(\phi: M \to N\)?&lt;/p&gt;&lt;p&gt;Pick coordinates \(x\) on \(X\) and \(y\) on \(Y\), with corresponding momenta \(\xi\) and \(\eta\). Then if \(\phi(x,\xi) = (y,\eta)\), we obtain&lt;/p&gt;&lt;p&gt;\[ \xi = d_x f, \ \eta = -d_y f \]&lt;/p&gt;&lt;p&gt;Note the simlarity to Hamilton&amp;rsquo;s equations. By the implicit function theorem, we can construct a (local) diffeomorphism \(\phi\) as long as \(f\) is sufficiently non-degenerate.&lt;/p&gt;&lt;h2 id=&#34;different-types-of-generating-functions&#34;&gt;Different Types of Generating Functions&lt;/h2&gt;&lt;p&gt;We now concentrate on the special case of \(M = T^\ast \mathbb{R} = \mathbb{R} \times \mathbb{R}^\ast\). Note that this is a cotangent bundle in two ways: \(T^\ast \mathbb{R} \cong T^\ast \mathbb{R}^\ast\). Hence we can construct local diffeomorphisms \(T^\ast \mathbb{R} \to T^\ast \mathbb{R}\) in four ways, by taking functions of the forms&lt;/p&gt;&lt;p&gt;\[ f(x_1, x_2), \ f(x_1, p_2), \ f(p_1, x_2), \ f(p_1, p_2) \]Origins from the Action Principle, and Hamilton-Jacobi&lt;/p&gt;&lt;p&gt;Suppose that we have two actions&lt;/p&gt;&lt;p&gt;\[ S_1 = \int p_1 \dot{q}_1 - H_1 dt, \ S_2 = \int p_2 \dot{q}_2 - H_2 dt \]&lt;/p&gt;&lt;p&gt;which give rise to the same dynamics. Then the Lagrangians must differ by a total derivative, i.e.&lt;/p&gt;&lt;p&gt;\[ p_1 \dot{q}_1 - H_1 = p_2 \dot{q}_2 - H_2  + \frac{d f}{dt} \]&lt;/p&gt;&lt;p&gt;Suppose that \(f = -q_2 p_2 + g(q_1, p_2, t)\). Then we have&lt;/p&gt;&lt;p&gt;\[ p_1 \dot{q}_1 - H_1 = -q_2 \dot{p}_2 - H_2 + \frac{\partial g}{\partial t} + \frac{\partial g}{\partial q_1}\dot{q}_1 + \frac{\partial g}{\partial p_2} \dot{p_2} \]&lt;/p&gt;&lt;p&gt;Comparing coefficients, we find&lt;/p&gt;&lt;p&gt;\[ p_1 = \frac{\partial g}{\partial q_1}, \ q_2 = \frac{\partial g}{\partial p_2}, \ H_2 = H_1 + \frac{\partial g}{\partial t} \]&lt;/p&gt;&lt;p&gt;Now suppose that the coordinates \((q_2, p_2)\) are chosen so that Hamilton&amp;rsquo;s equations become&lt;/p&gt;&lt;p&gt;\[ \dot{q_2} = 0, \ \dot{p}_2 = 0 \]&lt;/p&gt;&lt;p&gt;Then we must have \(H_2 = 0\), i.e.&lt;/p&gt;&lt;p&gt;\[ H_1 + \frac{\partial g}{\partial t} = 0 \]&lt;/p&gt;&lt;p&gt;Now we also have \(\partial H_2 / \partial p_2 = 0\), so this tells us that \(g\) is independent of \(p_2\), i.e. \(g = g(q_1, t)\). Since \(p_1 = \partial g / \partial q_1\), we obtain&lt;/p&gt;&lt;p&gt;\[ \frac{\partial g}{\partial t} + H_1(q_1, \frac{\partial g}{\partial q_1}) = 0 \]&lt;/p&gt;&lt;p&gt;This is the Hamilton-Jacobi equation, usually written as&lt;/p&gt;&lt;p&gt;\[ \frac{\partial S}{\partial t} + H(x, \frac{\partial S}{\partial x}) = 0 \]&lt;/p&gt;&lt;p&gt;Note the similarity to the Schrodinger equation! In fact, one can derive the Hamilton-Jacobi equation from the Schrodinger equation by taking a wavefunction of the form&lt;/p&gt;&lt;p&gt;\[ \psi(x,t) = A(x,t) \exp({\frac{i}{\hbar} S(x,t)}) \]&lt;/p&gt;&lt;p&gt;and expanding in powers of \(\hbar\). This also helps to motivate the path integral formulation of quantum theory.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>KAM</title>
       <link>https://jmf1sh.github.io/posts/2012-07-23-kam-1/</link>
       <pubDate>Mon, 23 Jul 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-07-23-kam-1/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In this post I want to sketch the idea of KAM, following these lecture notes.&lt;/p&gt;&lt;h2 id=&#34;integrable-systems&#34;&gt;Integrable Systems&lt;/h2&gt;&lt;p&gt;I don&amp;rsquo;t want to worry too much about details, so for now we&amp;rsquo;ll define anintegrable system to be a Hamiltonian system \((M, \omega, H)\) for which we canchoose local Darboux coordinates \((I, \phi)\) with \(I \in \mathbb{R}^N\) and\(\phi \in T^N\), such that the Hamiltonian is a function of \(I\) only. Defining\(\omega_j := \partial H / \partial I_j\), Hamilton&amp;rsquo;s equations then read&lt;/p&gt;&lt;p&gt;\[\begin{aligned}\dot{I}_j &amp;amp;= 0, \cr\dot{\phi}_j &amp;amp;= \omega_j(I).\end{aligned}\]&lt;/p&gt;&lt;p&gt;Hence we obtain linear motion on the torus as our dynamics. Note in particularthat the sets \({I = \mathrm{const}}\) are tori, and that the dynamics areconstrained to these tori. We call these tori &amp;ldquo;invariant&amp;rdquo;.&lt;/p&gt;&lt;p&gt;Now suppose that our Hamiltonian \(H\) is of the form&lt;/p&gt;&lt;p&gt;\[ H(I, \phi) = h(I) + f(I, \phi) \]&lt;/p&gt;&lt;p&gt;with \(f\) &amp;ldquo;small&amp;rdquo;. What can be said of the dynamics? Specifically, do there existinvariant tori? KAM theory lets us formulate this question in a precise way, andgives an explicit quantitative answer (as long as \(f\) is nice enough, and smallenough).&lt;/p&gt;&lt;p&gt;I want to sketch the idea of the KAM theorem, completely ignoring analyticaldetails.&lt;/p&gt;&lt;h2 id=&#34;constructing-the-symplectomorphism&#34;&gt;Constructing the Symplectomorphism&lt;/h2&gt;&lt;p&gt;Suppose we could find a symplectomorphism\[\Phi: (I, \phi) \mapsto (\tilde{I}, \tilde{\phi})\]such that \(H(I, \phi) = H(\tilde{I})\). Then our system would still be integrable(just in new action-angle coordinates), and we&amp;rsquo;d be done. There are tworelatively easy ways of constructing symplectomorphisms: integrating symplecticvector fields, and generating functions. In the lecture notes, generatingfunctions are used, so let&amp;rsquo;s take a minute to discuss them.&lt;/p&gt;&lt;p&gt;Proposition Let \(\Sigma(\tilde{I}, \phi)\) be a smooth function and suppose thatthe transformation&lt;/p&gt;&lt;p&gt;\[ I = \frac{\partial \Sigma}{\partial \phi},\tilde{\phi} = \frac{\partial \Sigma}{\partial \tilde{I}}\]&lt;/p&gt;&lt;p&gt;can be inverted to produce a diffeomorphism\(\Phi: (I, \phi) \mapsto (\tilde{I}, \tilde{\phi})\). Then \(\Phi\) is asymplectomorphism.&lt;/p&gt;&lt;p&gt;Proof&lt;/p&gt;&lt;p&gt;\[ dI = \frac{\partial^2 \Sigma}{\partial \phi \partial \tilde{I}} d \tilde{I} \]&lt;/p&gt;&lt;p&gt;\[ d\tilde{\phi} = \frac{\partial^2 \Sigma}{\partial \phi \partial \tilde{I}} d\phi \]&lt;/p&gt;&lt;p&gt;Hence&lt;/p&gt;&lt;p&gt;\[ dI \wedge d\phi = \frac{\partial^2 \Sigma}{\partial \phi \partial \tilde{I}} d \tilde{I} \wedge d\phi = d\tilde{I} \wedge d\tilde{\phi}. \]&lt;/p&gt;&lt;p&gt;We want a symplectomorphism \(\Phi\) such that&lt;/p&gt;&lt;p&gt;\[ H \circ \Phi(\tilde{I}, \tilde{\phi}) = \tilde{h}(\tilde{I} \]&lt;/p&gt;&lt;p&gt;If \(\Phi\) came from a generating function \(\Sigma\), then we have&lt;/p&gt;&lt;p&gt;\[ H(\frac{\partial \Sigma}{\partial \phi}, \phi) = \tilde{h}(\tilde{I}) \]&lt;/p&gt;&lt;p&gt;Expanding things, we have&lt;/p&gt;&lt;p&gt;\[ h(\frac{\partial \Sigma}{\partial \phi}) + f(\frac{\partial \Sigma}{\partial \phi}, \phi) = \tilde{h}(\tilde{I}). \]&lt;/p&gt;&lt;p&gt;If \(f\) is small, then we might expect \(\Phi\) to be close to the identity, andhence \(\Sigma\) ought to be close to the generating function for the identity(which is \(\langle I, \phi \rangle\)). So we take&lt;/p&gt;&lt;p&gt;\[ \Sigma(\tilde{I}, \phi) = \langle \tilde{I}, \phi \rangle + S(\tilde{I}, \phi) \]&lt;/p&gt;&lt;p&gt;where \(S\) should be &amp;ldquo;small&amp;rdquo;. So we linearize the equation in \(S\):&lt;/p&gt;&lt;p&gt;\[ \langle \omega(\tilde{I}), \frac{\partial S}{\partial \phi} \rangle + f(\tilde{I}, \phi) = \tilde{h}(\tilde{I}) - h(\tilde{I}) \]&lt;/p&gt;&lt;p&gt;Now we can expand \(S\) and \(f\) in Fourier series and solve coefficient-wise. Thisgives a formal solution \(S(\tilde{I}, \phi)\) of the equation&lt;/p&gt;&lt;p&gt;\[ \langle \omega, \frac{\partial S}{\partial \phi} \rangle + f(\tilde{I}, \phi) = 0. \]&lt;/p&gt;&lt;h2 id=&#34;getting-it-to-work&#34;&gt;Getting it to Work&lt;/h2&gt;&lt;p&gt;Unfortunately, the Fourier series for \(S\) has no chance to converge, so insteadwe take a finite truncation. If we assume \(f\) is analytic, its Fouriercoefficients decay exponentially fast, so this provides a very good approximatesolution to the linearized equation (and we can give an explicit bound in termsof a certain norm of \(f\)). Call this function \(S_1\). We then use \(S_1\) toconstruct a symplectomorphism \(\Phi_1\).&lt;/p&gt;&lt;p&gt;Now we take&lt;/p&gt;&lt;p&gt;\[ H_1(I, \phi) = H \circ \Phi_1(I, \phi) = h_1(I) + f_1(I, \phi). \]&lt;/p&gt;&lt;p&gt;Some hard analysis then shows that \(h - h_1\) is small, and \(f_1\) is much smallerthan f.&lt;/p&gt;&lt;h2 id=&#34;the-induction-step&#34;&gt;The Induction Step&lt;/h2&gt;&lt;p&gt;The above arguments sketch a method to put the system &amp;ldquo;closer&amp;rdquo; to an integrableform. By carefully controlling \(\epsilon\)&amp;rsquo;s and \(\delta\)&amp;rsquo;s, one then shows thatiterated sequence \(\Phi_1, \Phi_2 \circ \Phi_1, \ldots\) converges to somelimiting symplectomorphism \(\Phi_\infty\).&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Circle diffeomorphisms</title>
       <link>https://jmf1sh.github.io/posts/2012-07-13-circle-diffeomorphisms-1/</link>
       <pubDate>Fri, 13 Jul 2012 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-07-13-circle-diffeomorphisms-1/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;This is the first of a series of posts based on these lecture notes on KAM theory. For now I just want to outline section 2, which is a toy model of KAM thoery.&lt;/p&gt;&lt;p&gt;Circle Diffeomorphisms&lt;/p&gt;&lt;p&gt;We consider a map \(\phi: \mathbb{R} \to \mathbb{R}\) defined by&lt;/p&gt;&lt;p&gt;\[ \phi(x) = x + \rho + \eta(x) \]&lt;/p&gt;&lt;p&gt;where \(\rho\) is its rotation number and \(\eta(x)\) is &amp;ldquo;small&amp;rdquo;.&lt;/p&gt;&lt;p&gt;Define \(S_\sigma\) to be the strip \({ |\mathrm{Im} z|&amp;lt;\sigma} \subset \mathbb{C}\) and let \(B_\sigma\) be the space of holomorphic functions bounded on \(S_\sigma\) with sup norm \(|\cdot|_\sigma\).&lt;/p&gt;&lt;p&gt;Goal: Show that if \(|\eta|_\sigma\) is sufficiently small, then there exists some diffeomorphism \(H(x)\) such that&lt;/p&gt;&lt;p&gt;\[ H^{-1} \circ \phi \circ H (x) = x + \rho \]&lt;/p&gt;&lt;p&gt;i.e. that \(\phi\) is conjugate to a pure rotation.&lt;/p&gt;&lt;p&gt;Linearization&lt;/p&gt;&lt;p&gt;The idea is that if \(\eta\) is small, then \(H\) should be close to the identity, so we suppose that&lt;/p&gt;&lt;p&gt;\[ H(x) = x + h(x) \]&lt;/p&gt;&lt;p&gt;where \(h(x)\) is small. Plugging this into the equation above and discarding higher order terms yields&lt;/p&gt;&lt;p&gt;\[ h(x+\rho) - h(x) = \eta(x) \]&lt;/p&gt;&lt;p&gt;Since \(\eta\) is periodic, we Fourier transform both sides to obtain an explicit formula for the Fourier coefficients of \(h(x)\). We have to show several things:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;The Fourier series defining \(h(x)\) converges in some appropriate sense.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The function \(H(x) = x + h(x)\) is a diffeomorphism.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The composition \(\tilde{\phi} = H^{-1} \circ \phi \circ H\) is closer to a pure rotation than \(\phi\), in the sense that&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;\[ \tilde{\phi}(x) = x + \rho + \tilde{\eta}(x) \]&lt;/p&gt;&lt;p&gt;where \(|\tilde{\eta}| \ll |\eta|\).&lt;/p&gt;&lt;p&gt;Newton&amp;rsquo;s Method&lt;/p&gt;&lt;p&gt;Carrying out the analysis, one finds that for appropriate epsilons and deltas, if \(\eta \in B_\sigma\) then \(H \in B_{\sigma - \delta}\) and that \(|\tilde{\eta}|_{\sigma-\delta} \leq C |\eta|_\sigma^2\). By carefully choosing the deltas, we can iterate this procedure (composing the \(H\)&amp;rsquo;s) to obtain a well-defined limit \(H_\infty \in B_{\sigma/2}\) such that&lt;/p&gt;&lt;p&gt;\[ H_\infty^{-1} \circ \phi \circ H_\infty (x) = x + \rho, \]&lt;/p&gt;&lt;p&gt;as desired.&lt;/p&gt;&lt;p&gt;So in fact the idea of the proof is extremely simple, and all of the hard work is in proving some estimates.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Gaussian integrals and Wick&#39;s theorem</title>
       <link>https://jmf1sh.github.io/posts/2012-03-03-gaussian-integrals-wick/</link>
       <pubDate>Sat, 03 Mar 2012 15:00:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-03-03-gaussian-integrals-wick/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;We saw in the last update that the generating function \(Z[J]\) can be expressedas&lt;/p&gt;&lt;p&gt;\[ Z[J] = e^{\frac{1}{2} J \cdot A^{-1} J} \]&lt;/p&gt;&lt;p&gt;(at least as long as we&amp;rsquo;ve normalize things so that \(Z[0] = 1\). Now thewonderful thing is that this is something we can compute explicitly:&lt;/p&gt;&lt;p&gt;\[ Z[J] = \sum_{n = 0}^{\infty} \frac{(\frac{1}{2} A^{-1}_{ij} J^i J^j)^n}{n!} = \sum_{n=0}^\infty \frac{(A^{-1}_{ij} J^i J^j)^n}{2^n n!} \]&lt;/p&gt;&lt;p&gt;For example, in the one-dimensional case (taking \(A = 1\)) we get&lt;/p&gt;&lt;p&gt;\[ Z[J] = \sum_{n=0}^\infty \frac{J^{2n}}{2^n n!} \]&lt;/p&gt;&lt;p&gt;On the other hand, by the definition of the generating function we have&lt;/p&gt;&lt;p&gt;\[ Z[J] = \sum_{n=0}^\infty \frac{\langle x^n \rangle}{n!} J^n \]&lt;/p&gt;&lt;p&gt;Comparing coefficients, we find&lt;/p&gt;&lt;p&gt;\[ \frac{\langle x^{2n} \rangle}{(2n)!} = \frac{1}{2^n n!} \]&lt;/p&gt;&lt;p&gt;so that&lt;/p&gt;&lt;p&gt;\[ \langle x^{2n} \rangle = \frac{(2n)!}{2^n n!}. \]&lt;/p&gt;&lt;p&gt;Let&amp;rsquo;s give a combinatorial description. Given \(2n\) objects, in how many ways can we divide them into pairs? If we care about the order in which we pick the pairs, then we have&lt;/p&gt;&lt;p&gt;\[ {2n \choose 2}{2n - 2 \choose 2} \cdots {2n-(2n-2) \choose 2} = \frac{(2n)!}{2^n} \]&lt;/p&gt;&lt;p&gt;Of course, there are \(n!\) ways of ordering the \(n\) pairs, so after dividing by this (to account for the overcounting) we get exactly the expression for \(\langle x^{2n} \rangle\). This is the first case of Wick&amp;rsquo;s theorem.&lt;/p&gt;&lt;p&gt;Now consider the general multidimensional case. Given \(I = (i_1, \cdots, i_{2n})\), we define a contraction to be&lt;/p&gt;&lt;p&gt;\[ \langle x^{j_1} x^{k_1} \rangle \cdots \langle x^{j_n} x^{k_n} \rangle \]&lt;/p&gt;&lt;p&gt;where \(j_1, k_1, \cdots, j_n, k_n\) is a choice of parition of \(I\) into pairs.&lt;/p&gt;&lt;p&gt;Theorem (Wick&amp;rsquo;s theorem, Isserlis&#39; theorem) The expectation value&lt;/p&gt;&lt;p&gt;\[ \langle x^{i_1} \cdots x^{i_{2n}} \rangle \]&lt;/p&gt;&lt;p&gt;is the sum over all full contractions. There are \((2n)!/ 2^n n!\) terms in the sum.&lt;/p&gt;&lt;p&gt;Proof This follows from our formula for the power series of the generatingfunction. The reason is that the coefficient of  \(J^I\) in\((\frac{1}{2} A^{-1}_{ij} J^i J^k)^n\) is exactly given by summing productsof \(A^{-1}_{ij}\) over partitions of \(I\) into pairs, and the \(n!\) in thedenominator takes care of the overcounting.&lt;/p&gt;&lt;p&gt;Next up: perturbation theory and Feynman diagrams.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Introduction to Gaussian integrals</title>
       <link>https://jmf1sh.github.io/posts/2012-03-03-introduction-to-gaussian/</link>
       <pubDate>Sat, 03 Mar 2012 09:00:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-03-03-introduction-to-gaussian/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;As a warm-up for more serious stuff, I&amp;rsquo;d like to discuss Gaussian integralsover \(\mathbb{R}^d\). Gaussian integrals are the main tool for perturbativequantum field theory, and I find that understanding Gaussian integrals infinite dimensions is an immense aid to understanding how perturbative QFTworks. So let&amp;rsquo;s get started.&lt;/p&gt;&lt;h2 id=&#34;the-basics&#34;&gt;The Basics&lt;/h2&gt;&lt;p&gt;Let \(A\) be some \(d \times d\) symmetric positive definite matrix. We areinterested in the integral&lt;/p&gt;&lt;p&gt;\[ \int_{-\infty}^\infty \exp(-\frac{x \cdot Ax}{2}) dx. \]&lt;/p&gt;&lt;p&gt;Out of laziness, I will suppress the limits of integration and just write this as&lt;/p&gt;&lt;p&gt;\[ \int e^{-S(x)} dx. \]&lt;/p&gt;&lt;p&gt;where \(S(x) = x \cdot Ax / 2\). Now for a function \(f(x)\), we define theexpectation value \(\langle f(x) \rangle\) to be&lt;/p&gt;&lt;p&gt;\[ \langle f(x) \rangle_0 = \int f(x) e^{-S(x)} dx \]&lt;/p&gt;&lt;p&gt;Occasionally, we might care about the normalized expectation value&lt;/p&gt;&lt;p&gt;\[ langle f(x) \rangle = \frac{\langle f(x) \rangle_0}{\langle 1 \rangle_0} = \frac{1}{\langle 1 \rangle_0} \int f(x) e^{-S(x)} dx. \]&lt;/p&gt;&lt;p&gt;We mostly care about asymptotics, so we will typically think of a function\(f(x)\) as being a polynomial (or Taylor series). So what we&amp;rsquo;re reallyinterested in is&lt;/p&gt;&lt;p&gt;\[ \langle x^I \rangle = c\int x^I e^{-S(x)} dx, \]&lt;/p&gt;&lt;p&gt;where \(I\) is a multi-index.&lt;/p&gt;&lt;h2 id=&#34;the-partition-function&#34;&gt;The Partition Function&lt;/h2&gt;&lt;p&gt;Let us define \(Z[J]\) by&lt;/p&gt;&lt;p&gt;\[ Z[J] = \int e^{-S(x) + J \cdot x} dx. \]&lt;/p&gt;&lt;p&gt;Now the great thing is that&lt;/p&gt;&lt;p&gt;\[ \langle x^I \rangle = \left. \frac{d^I}{dJ^I} \right|_{J = 0} Z[J], \]&lt;/p&gt;&lt;p&gt;so that once we know \(Z[J]\), we can calculate anything. So let&amp;rsquo;s try to computeit. We have&lt;/p&gt;&lt;p&gt;\[\begin{aligned}(Ax - J) \cdot A^{-1} (Ax - J) &amp;amp;= (Ax - J) \cdot (x - A^{-1} J) \cr&amp;amp;= x \cdot Ax - x \cdot J - J \cdot x + J \cdot A^{-1} J \cr&amp;amp;= x \cdot Ax - 2 x \cdot J + J \cdot A^{-1} J.\end{aligned}\]So we see that&lt;/p&gt;&lt;p&gt;\[ -\frac{1}{2} x \cdot A x + J \cdot x = \frac{1}{2} J \cdot A^{-1} J -\frac{1}{2} (x-A^{-1}J) \cdot A(x - A^{-1} J). \]&lt;/p&gt;&lt;p&gt;So, after a change of variales \(x \mapsto x - A^{-1} J\) we find&lt;/p&gt;&lt;p&gt;\[ Z[J] = e^{\frac{1}{2} J \cdot A^{-1} J} Z[0]. \]&lt;/p&gt;&lt;p&gt;Now the argument in the exponential is&lt;/p&gt;&lt;p&gt;\[ \frac{1}{2} A^{-1}_{ij} J^i J^j \]&lt;/p&gt;&lt;p&gt;So we find that&lt;/p&gt;&lt;p&gt;\[\langle x^i x^j \rangle = \frac{d^2}{dx^i dx^j} Z[J]|_{J=0} = A_{ij}^{-1}\]&lt;/p&gt;&lt;p&gt;Now we are ready to prove Wick&amp;rsquo;s theorem and discuss Feynman diagrams, whichwe&amp;rsquo;ll do in the next post.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Geometry of curved spacetime, part 5</title>
       <link>https://jmf1sh.github.io/posts/2012-02-25-geometry-of-spacetime-part-5/</link>
       <pubDate>Sat, 25 Feb 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-02-25-geometry-of-spacetime-part-5/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&lt;p&gt;Following last time, we are almost ready to write down the Einstein equations.Before doing any math, let&amp;rsquo;s understand what we&amp;rsquo;re trying to do. Minkowskirealized that Einstein&amp;rsquo;s special relativity was best understood by combiningspace and time into 4-dimensional spacetime, with Lorentzian metric&lt;/p&gt;&lt;p&gt;\[ ds^2 = -dt^2 + dx^2 + dy^2 + dz^2. \]&lt;/p&gt;&lt;p&gt;The spacetime approach works wonderfully and even explains the Lorentzinvariance of Maxwell&amp;rsquo;s equations (indeed, it was Maxwell&amp;rsquo;s equations thatmotivated Einstein to postulate his principle of relativity). However, (forreasons that I may discuss later) gravity is not a &amp;ldquo;force&amp;rdquo; but rather thegeometry of spacetime itself.&lt;/p&gt;&lt;p&gt;By mass-energy equivalence (which is one of the most basic consequences ofrelativity), the gravitational field, whatever it is, must couple to thestress-energy tensor \(T_{ij}\). I won&amp;rsquo;t get into details, but the stress-energytensor is a familiar object from physics that roughly tells you what theenergy-momentum density/flux is in each direction at every point in spacetime.If the matter is completely static, then it is ok to think of this as measuringthe mass density, but for nonstatic matter it also takes things like pressureinto account.&lt;/p&gt;&lt;p&gt;Now, as I said above, the gravitational field is just the geometry of spacetime,which is measured by the metric tensor \(g_{ij}\). Mass-energy equivalence saysthat it must couple to the stress-energy tensor \(T_{ij}\). The simplest fieldequation then would be&lt;/p&gt;&lt;p&gt;\[ G_{ij} = c T_{ij} \]&lt;/p&gt;&lt;p&gt;where \(G_{ij}\) is some tensor built out of \(g_{ij}\) and its derivatives, and \(c\)is some constant. The equations of Newtonian gravity are 2nd order in thegravitational field, so if we want these equations to reduce to Newton&amp;rsquo;s in theappropriate limit, \(G_{ij}\) should only depend on the metric and its first twoderivatives. Now there is an obvious 2nd rank tensor satisfying theseconstraints: \(R_{ij}\), the Ricci tensor. However, this turns out to becompletely wrong (except in the vacuum).&lt;/p&gt;&lt;p&gt;Any reasonable matter will satisfy local energy-momentum conservation,&lt;/p&gt;&lt;p&gt;\[ \nabla_j T^{ij} = 0. \]&lt;/p&gt;&lt;p&gt;It turns out that the Ricci tensor does not satisfy this condition in general.So to look for the right tensor \(G_{ij}\), we turn to the Bianchi identity.&lt;/p&gt;&lt;h2 id=&#34;the-bianchi-identity&#34;&gt;The Bianchi Identity&lt;/h2&gt;&lt;p&gt;As discussed in the previous post, the curvature of a connection is theendomorphism-valued 2-form&lt;/p&gt;&lt;p&gt;\[ F = d\Omega - \Omega \wedge \Omega \]&lt;/p&gt;&lt;p&gt;where \(\Omega\) is the matrix of 1-forms telling us how to take the covariantderivative of a frame, i.e.&lt;/p&gt;&lt;p&gt;\[ \nabla_i e_j = \Omega_{ij} \otimes e_j. \]&lt;/p&gt;&lt;p&gt;Since a connection can be extended to all tensor powers in a natural way, we canconsider the covariant derivative of the curvature \(F\) (thought of as a sectionof the appropriate bundle). Quick calcluation:&lt;/p&gt;&lt;p&gt;\[\begin{aligned}\nabla F &amp;amp;= \nabla(d\Omega - \Omega \wedge \Omega) \cr&amp;amp;= d^2 \Omega - d\Omega \wedge \Omega + \Omega \wedge d\Omega \cr&amp;amp; \ \ + d\Omega \wedge \Omega - \Omega \wedge \Omega \wedge \Omega \cr&amp;amp; \ \ - \Omega \wedge d\Omega + \Omega \wedge \Omega \wedge \Omega \cr&amp;amp;= 0.\end{aligned}\]&lt;/p&gt;&lt;p&gt;Thus the endomorphism valued 3-form \(\nabla F\) is identically 0. Writing \(F\) incomponents as \(R_{ijkl}\), this is equivalent to&lt;/p&gt;&lt;p&gt;\[ R_{ijkl|m} +  R_{ijlm|k} + R_{ijmk|l} = 0. \]&lt;/p&gt;&lt;p&gt;Now let&amp;rsquo;s contract:&lt;/p&gt;&lt;p&gt;\[\begin{aligned}0 &amp;amp;= g^{ik} g^{jl} R_{ijkl|m} + g^{ik} g^{jl} R_{ijlm|k} + g^{ik} g^{jl} R_{ijmk|l}\cr&amp;amp;= g^{ik} R_{ik|m} - g^{ik}R_{im|k} - g^{jl} R_{jm|l} \cr&amp;amp;= \nabla_m S - 2 \nabla^k R_{mk}\end{aligned}\]&lt;/p&gt;&lt;p&gt;So we see that the tensor&lt;/p&gt;&lt;p&gt;\[ G_{ij} = R_{ij} - \frac{S}{2} g_{ij} \]&lt;/p&gt;&lt;p&gt;is divergence free. This yields the Einstein field equations:&lt;/p&gt;&lt;p&gt;\[ R_{ij} - \frac{S}{2} g_{ij} = c T_{ij}. \]&lt;/p&gt;&lt;p&gt;Actually, there is another obvious divergence free tensor: \(g_{ij}\) itself. Soa more general form is&lt;/p&gt;&lt;p&gt;\[ G_{ij} + \Lambda g_{ij} = c T_{ij} \]&lt;/p&gt;&lt;p&gt;where \(\Lambda\) is a constant called the cosmological constant.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Geometry of curved spacetime, part 4</title>
       <link>https://jmf1sh.github.io/posts/2012-02-06-geometry-of-spacetime-part-4/</link>
       <pubDate>Mon, 06 Feb 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-02-06-geometry-of-spacetime-part-4/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Today I had to try to explain connections and curvature in local frames (as opposed to coordinates), and I really feel that Wald&amp;rsquo;s treatment of this is just awful (this is one of the few complaints I have with an otherwise classic textbook). It is particularly baffling since the treatment in Misner, Thorne, and Wheeler is just perfect. What follows is the modern math (as opposed to physics) point of view. This is more abstract than any introductory GR (or even Riemannian geometry) text I&amp;rsquo;ve seen, but in this case the abstraction absolutely clarifies and simplifies things.&lt;/p&gt;&lt;p&gt;Let \(M\) be a smooth manifold and suppose \(E\) is a smooth vector bundle over \(M\). A connection on \(E\) is a map \(\nabla\) taking sections of \(E\) to sections of \(T^\ast M \otimes E\), \(\mathbb{R}\)-linear and satisfying the Leibniz rule&lt;/p&gt;&lt;p&gt;\[ \nabla(f\sigma) = df \otimes \sigma + f \nabla \sigma. \]&lt;/p&gt;&lt;p&gt;Now consider the sheaf of \(E\)-valued \(p\)-forms on \(M\). Call it \(\Omega^p(E)\). Then we can extend the connection to a map&lt;/p&gt;&lt;p&gt;\[ \nabla: \Omega^p(E) \to \Omega^{p+1}(E) \]&lt;/p&gt;&lt;p&gt;via the Leibniz rule:&lt;/p&gt;&lt;p&gt;\[ \nabla(\eta \otimes \sigma) = d\eta \otimes \sigma + (-1)^p \eta \wedge \nabla \sigma. \]&lt;/p&gt;&lt;p&gt;Let us define the curvature \(F\) associated to a connection \(\nabla\) by the composition&lt;/p&gt;&lt;p&gt;\[ F = \nabla^2: \Omega^p(E) \to \Omega^{p+2}(E). \]&lt;/p&gt;&lt;p&gt;Claim \(F\) is \(C^\infty\)-linear, i.e. it is tensorial.&lt;/p&gt;&lt;p&gt;Proof&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\nabla(\nabla(f \sigma)) &amp;amp;= \nabla( df \otimes \sigma + f \nabla \sigma) \cr&amp;amp;= d^2 f \otimes \sigma - df \wedge \nabla \sigma + df \wedge \nabla \sigma + f \nabla^2 \sigma \cr&amp;amp;= f \nabla^2 \sigma.\end{aligned} \]&lt;/p&gt;&lt;p&gt;So far we have not made any additional choices (beyond \(\nabla\)). In order toactually compute something locally, we have to make some choices. Let\(\hat{e}_a\) be a frame, i.e. a local basis of sections of \(E\). Then\(\nabla \hat{e}_a\) is an \(E\)-valued 1-form, hence it can be expressed as a sum&lt;/p&gt;&lt;p&gt;\[ \nabla \hat{e}_a = \sum_b \omega_a^b \otimes \hat{e}_b \]&lt;/p&gt;&lt;p&gt;where the coefficients \(\omega_a^b\) are 1-forms, often called the connection1-forms. Let \(\Omega\) denote the matrix of 1-forms whose entries are exactly\(\omega_a^b\).&lt;/p&gt;&lt;p&gt;Claim Let \(\sigma = \sigma^a \hat{e}_a\). Then we have&lt;/p&gt;&lt;p&gt;\[ \nabla \sigma = d\sigma + \Omega \sigma. \]&lt;/p&gt;&lt;p&gt;Proof The coefficients \(\sigma^a\) are functions (i.e. scalars), so\(\nabla \sigma^a = d\sigma^a\). Using the Leibniz rule we have&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\nabla(\sigma^a \hat{e}_a) &amp;amp;= (\nabla \sigma^a) \hat{e}_a + \sigma^a \nabla \hat{e}_a \cr&amp;amp;= d\sigma^a \hat{e}_a + \sigma^a \omega_a^b \hat{e}_b \cr&amp;amp;= d\sigma^a \hat{e}_a + \omega_c^a \sigma^c \hat{e}_a \cr&amp;amp;= (d\sigma + \Omega \sigma)^a \hat{e}_a.\end{aligned} \]&lt;/p&gt;&lt;p&gt;Claim The curvature satisfies \(F = d\Omega - \Omega \wedge \Omega\).&lt;/p&gt;&lt;p&gt;Proof Just apply the above formula twice using Leibniz.&lt;/p&gt;&lt;p&gt;Connection 1-forms from Christoffel symbols. Suppose now that we are in theRiemannian setting and we already know the Christoffel symbols in somecoordinates. Then we can express our frame \(\hat{e}_a\) in terms of coordinatevector fields, i.e.\[ \hat{e}_a = \hat{e}_a^i \frac{\partial}{\partial x^i} \]Then we have that\[\nabla_j \hat{e}_a^i = \frac{\partial \hat{e}_a^i }{\partial x^j} + \Gamma^i_{jk} \hat{e}_a^k\]&lt;/p&gt;&lt;p&gt;So, as a vector-valued 1-form, we have\[\nabla \hat{e} = \frac{\partial \hat{e}_a^i}{\partial x^j} dx^j \otimes \frac{\partial}{\partial x^i} + \Gamma^i_{jk} \hat{e}_a^k dx^j \otimes \frac{\partial}{\partial x^i}.\]&lt;/p&gt;&lt;p&gt;Juggling things a bit using the metric, we find\[\nabla \hat{e}_a = \frac{\partial \hat{e}_a^i}{\partial x^j} \hat{e}^b_i dx^j \otimes \hat{e}_b + \Gamma^i_{jk} \hat{e}_a^k \hat{e}_i^b dx^j \otimes \hat{e}_b.\]&lt;/p&gt;&lt;p&gt;So the connection 1-forms are given by\[\omega_a^b = \frac{\partial \hat{e}_a^i}{\partial x^j} \hat{e}^b_i dx^j + \Gamma^i_{jk} \hat{e}_a^k \hat{e}_i^b dx^j.\]&lt;/p&gt;&lt;p&gt;To come later (if I ever get around to it): some explicit computations.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Geometry of curved spacetime, part 3</title>
       <link>https://jmf1sh.github.io/posts/2012-02-04-geometry-of-spacetime-part-3/</link>
       <pubDate>Sat, 04 Feb 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-02-04-geometry-of-spacetime-part-3/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Today, some numerology. The Riemann curvature tensor is a tensor \(R_{abcd}\) satisfying the identities:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;\(R_{abcd} = -R_{bacd}.\)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;\(R_{abcd} = R_{cdba}. \)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;\(R_{abcd} + R_{acdb} + R_{adbc} = 0. \) (First Bianchi)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;\(R_{abcd|e} + R_{acec|d} + R_{abde|c} = 0. \) (Second Bianchi)&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;By 1, the number of independent \(ab\) indices is \(N = n(n-1)/2\), and similarly for \(cd\). By 2, the number of independent pairs of indices is \(N(N+1)/2\). Now the cyclic constraint 3 can be written as&lt;/p&gt;&lt;p&gt;\[ R_{[abcd]} = 0, \]&lt;/p&gt;&lt;p&gt;and thus constitutes \({n \choose 4}\) equations. So the number of independent components is&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}N(N+1)/2 - {n \choose 4} &amp;amp;= \frac{n(n-1)((n(n-1)/2+1)}{4} - \frac{n(n-1)(n-2)(n-3)}{24} \cr&amp;amp;= \frac{(n^2-n)(n^2-n+2)}{8} - \frac{(n^2-n)(n^2-5n+6}{24} \cr&amp;amp;= \frac{n^4-2n^3+3n^2+2n}{8} - \frac{n^4-6n^3+11n^2-6n}{24} \cr&amp;amp;= \frac{2n^4-2n^2}{24} \cr&amp;amp;= \frac{n^4-n^2}{12} \cr&amp;amp;= \frac{n^2(n^2-1)}{12}\end{aligned} \]&lt;/p&gt;&lt;p&gt;Now consider the Weyl tensor \(C_{abcd}\) which is defined as the completely trace-free part of the Rienmann tensor. The trace is determined by the Ricci tensor \(R_{ab}\) which as \(n(n+1)/2\) indepdendent components, so the Weyl tensor has&lt;/p&gt;&lt;p&gt;\[ \frac{n^2(n^2-1)}{12} - \frac{n^2-n}{2} = \frac{n^4-7n^2+6n}{12} \]&lt;/p&gt;&lt;p&gt;independent components. Now, for \(n = 1\) we see that \(R_{abcd}\) has no independent components, i.e. it vanishes identically. In \(n=2\), it has only 1 independent component, and so the scalar curvature determines everything. In \(n=3\), it has 6 independent components. Note that in this case, the Weyl tensor has no independent components, i.e. it is identically 0. So we see that in \(n = 2, 3\) every Riemannian manifold is conformally flat. So things only start to get really interesting in \(n=4\), where the Riemann tensor has 20 independent components, and the Weyl tensor has 10.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Path integrals, part 3</title>
       <link>https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-2/</link>
       <pubDate>Sat, 04 Feb 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-2/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Consider the heat equation&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \psi}{\partial t} = -\hat{H} \psi \]&lt;/p&gt;&lt;p&gt;We find similarly&lt;/p&gt;&lt;p&gt;\[ \langle x_N|U_t|x_0\rangle = \int \exp \sum_{j=0}^{N-1} ik_j(x_j - x_{j+1}) -\Delta t H(x_j, k_j) dx dk. \]&lt;/p&gt;&lt;p&gt;Now take \(H(x,k) = k^2/2m + V(x)\) and complete the square:&lt;/p&gt;&lt;p&gt;\[ ik_j(x_j - x_{j+1}) - \Delta t k_j^2/2m - \Delta tV(x_j) + ik_{j+1}(x_{j+1} - x_{j+2}) - k_{j+1}^2/2m - V(x_{j+1}) \]&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}ik_j a_j - \Delta t k_j^2/2m &amp;amp;= -(-2mi k_j a_j / \Delta t + k_j^2) \Delta t/2m \cr&amp;amp;= -(k_j^2 -2mi k_j a_j/\Delta t -m^2 a_j^2/(\Delta t)^2 + m^2 a_j^2/(\Delta t)^2) \Delta t/2m \cr&amp;amp;= -(k_j -mia_j/\Delta t)^2 \Delta t/2m -ma_j^2/2\Delta t\end{aligned} \]&lt;/p&gt;&lt;p&gt;Combining things together, we have that the heat kernel is given by&lt;/p&gt;&lt;p&gt;\[ \langle y|e^{-t \hat{H}}|x\rangle = \int e^{-S_{\textrm{euc}}} \mathcal{D}x \]&lt;/p&gt;&lt;p&gt;That is, Schwartz kernel of time evolution operator is given by the oscialltory Lorentzian signature path integral, whereas the heat kernel is given by the exponentially decaying path integral (better chance of being well-defined). Most importantly, the heat kernel contains most of the essential information about the spectrum of \(\hat{H}\), which is really all we need in order to understand the dynamics.&lt;/p&gt;&lt;p&gt;See ABC of Instantons. (I never understood the title of Nekrasov&amp;rsquo;s &amp;ldquo;ABCD of Instantons&amp;rdquo; until I found this classic).&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Path integrals, part 3</title>
       <link>https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-3/</link>
       <pubDate>Sat, 04 Feb 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-3/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;In my previous posts on path integrals, I described (rather tersely) how the path integral, suitably defined and interpreted, can be used to compute the Schwartz kernel of the operators \(e^{iHt}\) (Lorentzian signature) and \(e^{-Ht}\) (Euclidean signature).&lt;/p&gt;&lt;p&gt;Suppose that we understand the spectrum of \(H\) completely (nb: for a given system described by \(H\), this is the goal). For example, suppose we know that the spectrum of \(H\) consists of discrete eigenvalues \(E_n, n = 0, \cdots\) with corresponding eigenvectors \(|n\rangle\),&lt;/p&gt;&lt;p&gt;\[ H|n\rangle = E_n|n\rangle. \]&lt;/p&gt;&lt;p&gt;(For simplicity, I assume there is no continuous spectrum and that the eigenvalues are nondegenerate.) Then we have&lt;/p&gt;&lt;p&gt;\[ e^{-iHt} = \sum_n e^{-i E_n t} \langle n|n\rangle \]&lt;/p&gt;&lt;p&gt;and&lt;/p&gt;&lt;p&gt;\[ e^{-Ht} = \sum_n e^{-E_n t} \langle n|n\rangle \]&lt;/p&gt;&lt;p&gt;Now the second expression turns out to be very useful. Assume the eigenvalues are ordered so that&lt;/p&gt;&lt;p&gt;\[ E_0 &amp;lt; E_1 &amp;lt; \cdots \]&lt;/p&gt;&lt;p&gt;Then we can write&lt;/p&gt;&lt;p&gt;\[ e^{-Ht} = e^{-E_0 t} |0\rangle + \sum_{n \geq 1} e^{-(E_n-E_0)t}|n\rangle \]&lt;/p&gt;&lt;p&gt;Now suppose that \(v\) is some vector which is close to the ground state, in the sense that&lt;/p&gt;&lt;p&gt;\[ \langle v|0\rangle \neq 0 \]&lt;/p&gt;&lt;p&gt;(This is obviously a generic condition, so if we just pick \(v\) randomly we can expect this to be true.) Then we can consider&lt;/p&gt;&lt;p&gt;\[ e^{-Ht} v = e^{-E_0 t} v_0 |0\rangle + \sum_{n \geq 1} e^{-(E_n-E_0)t} v_n|n\rangle \]&lt;/p&gt;&lt;p&gt;Now for \(n \geq 1\), \(E_n-E_0\) is strictly positive, and so for large \(t\) all of the higher terms are exponentially damped. So, we have the asymptotic&lt;/p&gt;&lt;p&gt;\[ e^{-Ht} v \sim e^{-E_0 t }v_0|0\rangle \]&lt;/p&gt;&lt;p&gt;Next comes the really interesting part. Multiply on the right by a position-representation eigenbra \(\langle x|\):&lt;/p&gt;&lt;p&gt;\[ \langle x|e^{-Ht} v \sim e^{-E_0 t} v_0 \langle x|0\rangle \]&lt;/p&gt;&lt;p&gt;Now \(v_0\) is an irrelevant constant, so we might as well take it to be 1 (rescale \(v\) as necessary). The expression \(\langle x|0\rangle\) is exactly the ground state wavefunction in the position representation! Call it \(\psi_0(x)\). So to conclude: the large-t asymptotic of the expression \(\langle x|e^{-Ht}v\) is (up to an overall constant) given by \(e^{-E_0 t} \psi_0(x)\), hence we can recover both the ground state energy and the ground state wavefunction. But the value of this expression is exactly given by the Euclidean path integral. So we have a correspondence:&lt;/p&gt;&lt;p&gt;Asymptotics of Euclidean path integral \(\leftarrow\rightarrow\) The spectrum of \(H\).&lt;/p&gt;&lt;p&gt;Coming next: instantons.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Geometry of curved spacetime, part 2</title>
       <link>https://jmf1sh.github.io/posts/2012-01-26-geometry-of-spacetime-part-2/</link>
       <pubDate>Thu, 26 Jan 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-01-26-geometry-of-spacetime-part-2/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Disclaimer: as before, these are (incredibly) rough notes intended for a tutorial. I may clean them up a bit later but for now it will seem like a lot of unmotivated equations (with typos!!).&lt;/p&gt;&lt;p&gt;The Energy Functional&lt;/p&gt;&lt;p&gt;\[ S = \int_0^T |\dot{\gamma}|^2 dt \]&lt;/p&gt;&lt;p&gt;Letting \(V^i = \dot{\gamma}^i\), this is&lt;/p&gt;&lt;p&gt;\[ S = \int_0^T g_{ij}(\gamma(t)) V^i V^j dt = \int_0^T L dt \]&lt;/p&gt;&lt;p&gt;where the Lagrangian \(L\) is&lt;/p&gt;&lt;p&gt;\[ L = g_{ij} V^i V^j \]&lt;/p&gt;&lt;p&gt;Now,&lt;/p&gt;&lt;p&gt;\[ \frac{\partial L}{\partial x^k} = (\partial_k g_{ij}) V^i V^j \]&lt;/p&gt;&lt;p&gt;and&lt;/p&gt;&lt;p&gt;\[ \frac{\partial L}{\partial V^k} = g_{ij} \delta^i_k V^j + g_{ij} V^i \delta^i_k = 2 g_{jk} V^j \]&lt;/p&gt;&lt;p&gt;Now,&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} \frac{\partial L}{\partial V^k} = 2 (\partial_i g_{jk}) V^i V^j + 2 g_{jk} \dot{V}^j \]&lt;/p&gt;&lt;p&gt;Plugging these expressions into the Euler-Lagrange equations, we have&lt;/p&gt;&lt;p&gt;\[ 2 g_{jk} \dot{V}^j + \left(\partial_i g_{jk} + \partial_j g_{ik}- \partial_k g_{ij}\right) V^i V^j = 0 \]&lt;/p&gt;&lt;p&gt;Multiplying by the inverse metric, we have&lt;/p&gt;&lt;p&gt;\[ \dot{V}^k + \frac{g^{kl}}{2} \left( \partial_i g_{jl} + \partial_j g_{il} - \partial_l g_{ij} \right) V^i V^j = 0 \]&lt;/p&gt;&lt;p&gt;Which is the geodesic equation (recall the formula for the Christoffel symbols).&lt;/p&gt;&lt;p&gt;Orthonormal Frames (Lorentzian and Riemannian) (tetrads, vielbeins, vierbeins, &amp;hellip;)&lt;/p&gt;&lt;p&gt;Locally, we can find an orthonormal basis of vector fields \(e^\mu_i\). Greek indicates coordinates, whereas Latin indicates label in the basis. These necessarily satisfy&lt;/p&gt;&lt;p&gt;\[ g_{\mu\nu} e^\mu_i e^\nu_j = \eta_{ij} \]&lt;/p&gt;&lt;p&gt;where \(\eta_{ij}\) is the flat/constant metric (of whatever signature we are working in).&lt;/p&gt;&lt;p&gt;Methods for Computing Curvature (from Wald)&lt;/p&gt;&lt;ol start=&#34;0&#34;&gt;&lt;li&gt;Getting the Christoffel symbols from the geodesic equation.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;See e.g. sphere or spherical coordinates.&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Coordinates. By definition,&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;\[ \nabla_a \nabla_b \omega_c = \nabla_b \nabla_a \omega_c + {R_{abc}}^d \omega_d \]&lt;/p&gt;&lt;p&gt;Writing things explicitly, this gives&lt;/p&gt;&lt;p&gt;\[ R_{abc}^d = \partial_b \Gamma^d_{ac} - \partial_a \Gamma^d_{bc}\]&lt;/p&gt;&lt;p&gt;\[+\Gamma^e_{ac}\Gamma^d_{be} - \Gamma^e_{bc}\Gamma^d_{ae}\]&lt;/p&gt;&lt;p&gt;(todo: fix typesetting.)&lt;/p&gt;&lt;p&gt;Do this for eg unit sphere in \(\mathbb{R}^3\).&lt;/p&gt;&lt;ol start=&#34;2&#34;&gt;&lt;li&gt;Curvature in Frames (equivalent to coordinates but totally different flavor)&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;(note: Misner-Thorne-Wheeler seems much better than Wald for this stuff).&lt;/p&gt;&lt;p&gt;Using MTW notation. Fix a frame \(\mathbf{e_\mu}\) and a dual frame \(\omega^\mu\). The connection 1-forms are defined by&lt;/p&gt;&lt;p&gt;\[ 0 = d\omega^\mu + \alpha^\mu_\nu \wedge \omega^\nu \]&lt;/p&gt;&lt;p&gt;We also have&lt;/p&gt;&lt;p&gt;\[ dg_{\mu\nu} = \omega_{\mu\nu} + \omega_{\nu\mu}\]&lt;/p&gt;&lt;p&gt;So metric compatibility yields&lt;/p&gt;&lt;p&gt;\[ \omega_{\mu\nu} = -\omega_{\nu\mu}\]&lt;/p&gt;&lt;p&gt;Antisymmetry means fewer independent components. In this language, the curvature 2-form is given by&lt;/p&gt;&lt;p&gt;\[ R^\mu_\nu = d\alpha^\mu_\nu + \alpha^\mu_\sigma \wedge \alpha^\sigma_\nu \]&lt;/p&gt;&lt;p&gt;Gaussian Coordinates&lt;/p&gt;&lt;p&gt;Via Wald. Suppose \(S \subset M\) is a codimension 1 submanifold. If \(S\) is not null, we can find a normal vector field \(n^a\) which is everywhere orthogonal to \(S\) and has unit length. (Probably also need orientation to make it unique!) We can pick any coordinates \(x^1, \cdots, x^{n-1}\) on \(S\), and we pick the last coordinate to be the distance to \(S\), measured along a geodesic with initial tangent vector \(n^a\) (i.e. we use exponential coordinates in the normal direction).&lt;/p&gt;&lt;p&gt;Once we pick these coordinates, we obtain a family of hypersurfaces \(S_t\) given by&lt;/p&gt;&lt;p&gt;\(x^n = t\). These have the property that they are orthogonal to the normal geodesics through \(S\). Proof: (X are vector fields which are tangent to \(S_t\))&lt;/p&gt;&lt;p&gt;\[ n^b \nabla_b (n_a X^a) = n_a n^b \nabla_b X^a \]&lt;/p&gt;&lt;p&gt;\[= n_a X^b \nabla_b n^a \]&lt;/p&gt;&lt;p&gt;\[= \frac{1}{2}X^b \nabla_b (n^a n_a) = 0 \]&lt;/p&gt;&lt;p&gt;(first: geodesic, second: they lie-commute since they are coordinate vector fields).&lt;/p&gt;&lt;p&gt;Jacobi Fields, Focusing and Growth, Conjugate Points&lt;/p&gt;&lt;p&gt;Geodesic deviation. Suppose we have a 1-parameter family of geodesics \(\gamma_s\) with tangent \(T^a\) and deviation \(X^a\). (draw pictures!) By the geodesic equation, we have&lt;/p&gt;&lt;p&gt;\[ T^a \nabla_a T^b = 0 \]&lt;/p&gt;&lt;p&gt;What can we say about \(X^a\)? By change of affine parameter if necessary, we can assume that \(T^a\) and \(X^a\) are coordinate vector fields, and in particular they commute. So&lt;/p&gt;&lt;p&gt;\[ X^a \nabla_a T^b = T^a \nabla_a X^b \]&lt;/p&gt;&lt;p&gt;Then it is easy to see that \(X^a T_a\) is constant, and so (again by change of parameter if necessary) we can assume that it is 0. Now set \(v^a = T^b \nabla_b X^a\). We interpret this as the relative velocity of nearby geodesics. Similarly, we have the acceleration&lt;/p&gt;&lt;p&gt;\[ a^a = T^c \nabla_c v^a = T^b \nabla_b (T^c \nabla_c X^a) \]&lt;/p&gt;&lt;p&gt;Some manipulation shows that&lt;/p&gt;&lt;p&gt;\[ a^a = -R_{cbd}^a X^b T^c T^d \]&lt;/p&gt;&lt;p&gt;This is the geodesic deviation equation. (Positive curvature -&amp;gt; focus, negative curvature -&amp;gt;growth.)&lt;/p&gt;&lt;p&gt;Now we can work this in reverse. Suppose I have a single geodesic with tangent \(T^a\). If I have some vector field \(X^a\) on the geodesic, under what conditions will it integrate to give me a family of geodesics? The above shows that we must have&lt;/p&gt;&lt;p&gt;\[ T^a \nabla_a (T^b \nabla_b X^c) = -R_{abd}^c X^b T^a T^d \]&lt;/p&gt;&lt;p&gt;Solutions to this equation are called Jacobi vector fields.&lt;/p&gt;&lt;p&gt;Definition Points p, q on a geodesic are said to be conjugate if there exists a Jacobi field on the geodesics which vanishes at p and q. (Picture time!)&lt;/p&gt;&lt;p&gt;Definition (Cut Locus in Riemannian Signature) For \(p \in M\), we define the cut locus in \(T_p M\) to be those vectors \(v \in T_p M\) for which \(\exp(tv)\) is length minimizing on \([0,1]\) but fails to be length-minimizing on \([0,1+\epsilon]\) for and \(\epsilon\). The cut locus in M is the image of the cut locus in \(T_p M\) under the exponential map.&lt;/p&gt;&lt;p&gt;eg. Sphere, antipodes.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Geometry of curved spacetime, part 1</title>
       <link>https://jmf1sh.github.io/posts/2012-01-19-geometry-of-spacetime-part-1/</link>
       <pubDate>Thu, 19 Jan 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-01-19-geometry-of-spacetime-part-1/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I&amp;rsquo;m TAing a course on general relativity this semester, and I&amp;rsquo;m covering some of the geometry background in tutorials. Since I need to prepare some material for these, I thought there was no harm in putting it up on this blog. So here we go.&lt;/p&gt;&lt;p&gt;Throughout, we&amp;rsquo;ll let \(M\) be a smooth manifold equipped with a metric \(g\). Whenever it makes life easier, I&amp;rsquo;ll assume that \(g\) is positive definite (rather than Lorentzian). For a point \(p \in M\), denote its tangent space by \(T_p M\).&lt;/p&gt;&lt;p&gt;Theorem 1 For any \(p \in M\), there exist a neighborhood \(U\) of 0 in \(T_p M\) and a neighborhood \(V\) of \(p\) in \(M\), and a diffeomorphism \(\exp_p: U \to V\) called exponential map. This map takes lines through the origin in \(T_p M\) to geodesics in \(M\) passing through \(p\).&lt;/p&gt;&lt;p&gt;Theorem 2 In exponential coordinates, the components of the metric are&lt;/p&gt;&lt;p&gt;\[ g_{ij} = \delta_{ij} + O(|x|^2) \]&lt;/p&gt;&lt;p&gt;Corollary 3 In exponential coordinates, the Christoffel symbols vanish at \(p\).&lt;/p&gt;&lt;p&gt;Corollary 4 The Christoffel symbols are not the components of a tensor.&lt;/p&gt;&lt;p&gt;Corollary 5 Not all metrics are equivalent: there is a local invariant, called the curvature.&lt;/p&gt;&lt;p&gt;Construction of exponential map. The metric on \(M\) induces a (constant) metric \(g_{ij}\) on \(T_p M\). By a linear change of coordinates on \(T_p M\), we can assume that this induced metric is just \(g_{ij} = \delta_{ij}\). Now the geodesic equation on \(M\) is a 2nd order ODE which has a unique solution once we specify an initial condition. An initial condition is just a pair \((p,v)\) consisting of a point \(p \in M\) and tangent vector \(v \in T_p M\). Since we have fixed \(p\), each \(v \in T_p M\) gives a unique geodesic through \(p\). Call it \(\gamma_v(t)\). Then define the exponential map as follows:&lt;/p&gt;&lt;p&gt;\[ \exp_p(v) := \gamma_v(1) \]&lt;/p&gt;&lt;p&gt;The fact that this map is well-defined, smooth, and 1-1 (at least locally) follows from the standard existence and uniqueness theorem for ODEs. So to see that it is a diffeomorphism near \(0\), we can just compute its differential and apply the inverse function theorem.&lt;/p&gt;&lt;p&gt;The easy way out. By construction, every geodesic through 0 is of the form \(\gamma_v(t) = tv\). Plugging this into the geodesic equation,&lt;/p&gt;&lt;p&gt;\[ \dot{v} + \Gamma(x)^i_{jk} v^j v^k = 0 \]&lt;/p&gt;&lt;p&gt;we see that at 0, \(\Gamma^i_{jk}\) vanishes, and in particular, the first partial derivatives of the metric vanish.&lt;/p&gt;&lt;p&gt;The hard way: the differential of \(exp\) at 0. First, taylor expand the velocity of a geodesic, and evaluate at time \(t = 1\):&lt;/p&gt;&lt;p&gt;\[ v(t) = v + \dot{v} + \frac{1}{2} \ddot{v} + \cdots \]&lt;/p&gt;&lt;p&gt;Now, by the geodesic equation, \(\dot{v}\) is \(O(v^2)\). Similarly, by differentiating the geodesic equation, we find that all of the higher time derivatives are also \(O(v^2)\). So we find that the exponential map is just the identity + \(O(v^2)\), and hence its differential at 0 is just the identity.&lt;/p&gt;&lt;p&gt;Now, we have argued that in exponential coordinates, the Christoffel symbols vanish at 0. Recall that for any tensor \(T\), if the components of \(T\) vanish at some point \(p\) in one coordinate system, then \(T\) is identically 0 at that point (i.e. its components vanish at that point in all coordinate systems). If the Christoffel symbols were a tensor, then, the above shows that they must be identically zero at all points in \(M\), in all coordinate systems. But this is absolutely not the case&amp;ndash;even in flat \(\mathbb{R}^n\), we can pick coordinates so that the Christoffel symbols do not vanish. Hence they are not a tensor.&lt;/p&gt;&lt;p&gt;Aside Though the Christoffel symbols are not a tensor, they are the components of something which does have a coordinate indepdendent definition: a connection 1-form. A connection 1-form is not a tensor but rather a section of a certain associated bundle. More on this in future posts.&lt;/p&gt;&lt;p&gt;Claim Suppose \(\gamma\) is a curve in \(M\) with tangent vector \(T\), and suppose \(V\) is a vector field defined on \(\gamma\). Then \(\nabla_T V\) is well-defined, independent of the smooth extension of \(V\).&lt;/p&gt;&lt;p&gt;Proof Suppose \(V\) and \(W\) are two smooth vector field that agree on \(\gamma\). We would like to show that&lt;/p&gt;&lt;p&gt;\[ \nabla_T V = \nabla_T W \]&lt;/p&gt;&lt;p&gt;i.e., this directional derivative depends only on their restriction to \(\gamma\). It suffices to prove this pointwise. In coordinates, we have&lt;/p&gt;&lt;p&gt;\[ \nabla_T V = T^k \frac{\partial V^i}{\partial x^k} + \Gamma^i_{jk} V^j T^k \]&lt;/p&gt;&lt;p&gt;and similarly for \(W\). The terms involving Christoffel symbols do not depend on derivatives of \(V\) or \(W\), so they agree by assumption. If \(T\) is zero at a point, there is nothing to show. So assume that \(T\) is nonzero at some point. Then near this point, we can choose coordinates \(x^i\) such that&lt;/p&gt;&lt;p&gt;\[ \gamma(t) = (t, 0) \]&lt;/p&gt;&lt;p&gt;so that&lt;/p&gt;&lt;p&gt;\[ T = (1, 0) \]&lt;/p&gt;&lt;p&gt;Then \(V\) and \(W\) agree when \(x^i = 0\) for \(i \geq 2\), and hence their partials agree. We have&lt;/p&gt;&lt;p&gt;\[ T^k \frac{\partial V^i}{\partial x^k} = \frac{V^i}{\partial x^1} = T^k \frac{\partial W^i}{\partial x^k} \]&lt;/p&gt;&lt;p&gt;Explicit Formulas for Christoffel Symbols. Using properties of covariant derivatives, we find&lt;/p&gt;&lt;p&gt;\[ 0 = \nabla_k g_{ij} = \frac{\partial g_{ij}}{\partial x^k} - \Gamma^l_{ki} g_{lj} - \Gamma^l_{kj} g_{il} \]&lt;/p&gt;&lt;p&gt;So&lt;/p&gt;&lt;p&gt;\[ \Gamma_{kij} + \Gamma_{kji} = g_{ij,k} \]&lt;/p&gt;&lt;p&gt;\[ \Gamma_{ijk} + \Gamma_{ikj} = g_{jk,i} \]&lt;/p&gt;&lt;p&gt;\[ \Gamma_{jki} + \Gamma_{jik} = g_{ki,j} \]&lt;/p&gt;&lt;p&gt;Taking (2) + (3) - (1) gives&lt;/p&gt;&lt;p&gt;\[ 2\Gamma_{ijk} = g_{jk,i} + g_{ki,j} - g_{ij,k} \]&lt;/p&gt;&lt;p&gt;Hence&lt;/p&gt;&lt;p&gt;\[ \Gamma_{ij}^k = \frac{g^{kl}}{2}\left(g_{jl,i} + g_{li,j} - g_{ij,l} \right) \]&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Path integrals, part 1</title>
       <link>https://jmf1sh.github.io/posts/2012-01-16-path-integrals-part-1/</link>
       <pubDate>Mon, 16 Jan 2012 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2012-01-16-path-integrals-part-1/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Consider the Hilbert space \(\mathcal{H} = L^2(\mathbb{R})\) with Lebesgue measure and a Hamiltonian \(H = T(k) + V(x)\) (a sum of kinetic and potential energy). Then the quantum hamiltonian \(\hat{H}\) acts as&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}(\hat{H}\psi)(y) &amp;amp;= \frac{1}{2\pi} \int e^{ik(y-x)} T(k) \psi(x) dx dk + V(y)\psi(y) \cr&amp;amp;= \frac{1}{2\pi}\int e^{ik(y-x)} H(k,x) \psi(x) dx dk \cr\end{aligned} \]&lt;/p&gt;&lt;p&gt;Now consider the Schrodinger equation&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \psi}{\partial t} = i \hat{H} \psi. \]&lt;/p&gt;&lt;p&gt;We would like to obtain a formula for the solution operator \(U_t = e^{-i \hat{H} t}\). Let us consider its Schwartz kernel \(\langle{y}|U_t|{x}\rangle\). Let \(N\) be a large integer so that \(\Delta t = t/N\) is &amp;ldquo;small&amp;rdquo;. Then we can write&lt;/p&gt;&lt;p&gt;\[ U_t = U_{\Delta t}^N, \]&lt;/p&gt;&lt;p&gt;Now consider a single term:&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\langle{y}|U_{\Delta t}|x\rangle &amp;amp;\simeq \langle{y}|1-i\Delta{t}\hat{H}|x\rangle \cr&amp;amp;= \delta(y-x) -i \Delta t \langle x|\hat{H}|y\rangle \cr&amp;amp;= \frac{1}{2\pi}\int e^{ik(y-x)}( 1 - i \Delta t H(k,x)) dk \cr&amp;amp;\simeq \frac{1}{2\pi}\int e^{ik(y-x) - i \Delta t H(k,x)} dk\cr\end{aligned} \]&lt;/p&gt;&lt;p&gt;Now we have (taking \(x_0 = x\) and \(x_N = y\))&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}\langle y|U_t|x\rangle &amp;amp;= \int dx_1 \cdots dx_{N-1} \cr&amp;amp; \ \times \langle x_N|U_{\Delta t}|x_{N-1}\rangle \cdots \langle x_1|U_{\Delta t}|x_0\rangle \cr&amp;amp;= \frac{1}{(2\pi)^N} \int dx_1 \cdots dx_{N-1} dk_0 \cdots dk_{N-1} \cr&amp;amp; \ \times \ e^{ik_N(x_N-x_{N-1}) - i \Delta t H(k_{N-1},x_{N-1})} \cdotse^{-ik_N(x_1-x_0) - i \Delta t H(k_0,x_0)} \cr&amp;amp;= \frac{1}{(2\pi)^N} \int dx_1 \cdots dx_{N-1} dk_0 \cdots dk_{N-1} \cr&amp;amp; \ \times \ \exp \sum_{j=0}^{N-1} ik_j(x_{j+1} - x_j) - i \Delta t H(k_j,x_j)\end{aligned} \]&lt;/p&gt;&lt;p&gt;Note this kind of integral seems like it should have a natural interpretation in symplectic or contact geometry, since the expression \(dxdk/(2\pi)^N\) is very nealy the Liouville measure. This is the most general form of the path integral.&lt;/p&gt;&lt;p&gt;Now assume that \(H(k,x) = k^2/2m + V(x)\). Then the \(k\)-dependent terms have the form&lt;/p&gt;&lt;p&gt;\[ \int e^{ik(y-x) - i\Delta t k^2/2m}. \]&lt;/p&gt;&lt;p&gt;Complete the square&lt;/p&gt;&lt;p&gt;\[ \begin{aligned}ik(y-x) -i\Delta t k^2/2m &amp;amp;= -\frac{i \Delta t}{2m} (k^2 - \frac{2m}{\Delta t}k(y-x)) \cr&amp;amp;= -\frac{i \Delta t}{2m} (k^2 - \frac{2m}{\Delta t}k(y-x) + \frac{m^2}{\Delta t^2}(y-x)^2 -\frac{m^2}{\Delta t^2}(y-x)^2) \cr&amp;amp;= -\frac{i \Delta t}{2m}(k - \frac{m}{\Delta t}(y-x))^2 + \frac{i m}{2 \Delta t}(y-x)^2\end{aligned} \]&lt;/p&gt;&lt;p&gt;Now, using that\[ \int e^{-ak^2} = \sqrt{\frac{\pi}{a}} \]We have\[ \int e^{-\frac{i \Delta t}{2m}(k-\frac{m}{\Delta t}(y-x))^2} = \sqrt{\frac{2\pi m}{i \Delta t}} \]Putting it altogether, we get the more familiar version of the path integral,&lt;/p&gt;&lt;p&gt;\[ \begin{aligned} \langle y|U_t|x\rangle &amp;amp;\simeq C^N \int dx_1 \cdots dx_{N-1} \cr&amp;amp; \ \times \ \exp i\sum_{j=0}^{N-1} \frac{m}{2\Delta t}(x_{j+1}-x_j)^2 - V(x_j) \Delta t\end{aligned} \]&lt;/p&gt;&lt;p&gt;where&lt;/p&gt;&lt;p&gt;\[ C = \frac{1}{2\pi} \sqrt{\frac{2 \pi m}{i \Delta t}} = \sqrt{\frac{m}{2\pi i \Delta t}} \]&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Lattice quantum mechanics in 1d</title>
       <link>https://jmf1sh.github.io/posts/2011-11-12-lattice-quantum-mechanics-1d/</link>
       <pubDate>Sat, 12 Nov 2011 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-11-12-lattice-quantum-mechanics-1d/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;For some reason I&amp;rsquo;ve been interested in lattice QFT recently, especially lattice gauge theory (note to self: a miniproject for the Christmas break is to understand the paper by Kogut and Susskind &lt;a href=&#34;http://prd.aps.org/abstract/PRD/v11/i2/p395_1)&#34;&gt;http://prd.aps.org/abstract/PRD/v11/i2/p395_1)&lt;/a&gt;. As a warm-up, I thought I would try understanding plain-old 1D QM on the lattice, and writing some code to see if I got results that are at all reasonable.&lt;/p&gt;&lt;p&gt;The Setup: We will take as our space of states \(\mathscr{H} = L^2([0,1])\) and hamiltonian&lt;/p&gt;&lt;p&gt;\[ H = -\frac{d^2}{dx^2} + V(x). \]&lt;/p&gt;&lt;p&gt;for some real function \(V(x)\) defined on \([0,1]\).&lt;/p&gt;&lt;p&gt;Now fix some large positive integer \(N\). Let \(\epsilon = 1/N\). We will consider the subspace \(\mathscr{H}_N\) of \(\mathscr{H}\) spanned by those functions that are constant on the subintervals \(i\epsilon, (i+1)\epsilon)\). Such a function is defined (a.e.) by the \(N\) values it takes on these intervals, so we may identify \(\mathscr{H}_N \cong \mathbb{C}^N\) as vector spaces. Let us denote elements of \(\mathscr{H}_N\) by \(\psi_i\) for \(i = 0, \ldots, N-1\). Thinking of these as the values of a function \(\psi(x)\) at \(x = i\epsilon\), we see that the inner product on \(\mathscr{H}_N\) is given by&lt;/p&gt;&lt;p&gt;\[(\phi, \psi) = \int_0^1 \bar{\phi}(x) \psi(x) dx = \sum_{i=0}^{N-1} \bar{\phi}_i \psi(i)\]&lt;/p&gt;&lt;p&gt;So we see that with these identifications, \(\mathscr{H}_N\) is just \(\mathbb{C}^N\) with the usual hermitian inner product.&lt;/p&gt;&lt;p&gt;Now, we can approximate \(d/dx\) with the forward and backward difference operators&lt;/p&gt;&lt;p&gt;\begin{aligned}(D_+ \psi)_i &amp;amp;= \frac{\psi_{i+1} - \psi_i}{\epsilon} \cr(D_-\psi)_i &amp;amp;= \frac{\psi_i - \psi_{i-1}}{\epsilon}\end{aligned}&lt;/p&gt;&lt;p&gt;Note: throughout I will assume periodic boundary conditions to make life easy. In this case we have \(\psi_{i+N} = \psi_i\).&lt;/p&gt;&lt;p&gt;Now consider&lt;/p&gt;&lt;p&gt;\begin{aligned}(D_+\phi, \psi) &amp;amp;= \epsilon^{-1} \sum_i \left( \bar{\phi}_{i+1}\psi_i - \bar{\phi}_i \psi_i \right) \cr&amp;amp;= \epsilon^{-1} \sum_i \left( \bar{\phi}_i \psi_{i-1} - \bar{\phi}_i \psi_i \right) \cr&amp;amp;= -(\phi, D_-\psi).\end{aligned}&lt;/p&gt;&lt;p&gt;Thus we have \(D_+^\ast = -D_-\). Similarly, \(D_-^\ast = -D_+\). Then the operator \(D = (D_+ + D_-)/2\) approximates \(d/dx\) and satisfies \(D^\ast = -D\) (as it should!), and the discrete Laplacian \(D^2\) is self-adjoint.&lt;/p&gt;&lt;p&gt;Finally, we can form the discrete hamiltonian \(H_N\) by taking \(H_N = -D^2 + \hat{V}\), where \(\hat{V}\) is the operator \(\psi_i \mapsto V(x_i) \psi_i\), where \(x_i = i\epsilon\).&lt;/p&gt;&lt;p&gt;Note: typically one further imposes Dirichlet or Neumann boundary conditions. This corresponds to projecting to a smaller subspace of \(\mathscr{H}_N\).&lt;/p&gt;&lt;p&gt;I wrote some Sage code to test this. With \(V(x) = 0\), and \(N = 500\), here is one of the lowest-energy states:&lt;/p&gt;&lt;figure class=&#34;placement&#34;&gt;    &lt;img src=&#34;https://jmf1sh.github.io/img/state.png&#34;/&gt; &lt;/figure&gt;&lt;p&gt;Rather encouraging.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Susskind on string theory</title>
       <link>https://jmf1sh.github.io/posts/2011-10-05-susskind-string-theory/</link>
       <pubDate>Wed, 05 Oct 2011 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-10-05-susskind-string-theory/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Found this and thought I&amp;rsquo;d share:&lt;/p&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=25haxRuZQUk&amp;amp;feature=list_related&amp;amp;playnext=1&amp;amp;list=SPA2FDCCBC7956448F&#34;&gt;Lectures on String Theory by Susskind&lt;/a&gt;&lt;/p&gt;&lt;p&gt;This is a series of introductory lectures on string theory by cofounder Leonard Susskind. Regardless of whether you think string theory has anything to say about the universe we live it, it&amp;rsquo;s very cool to hear about its origins from one of the people who dreamt it up.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 6</title>
       <link>https://jmf1sh.github.io/posts/2011-09-01-classical-mechanics-part-6/</link>
       <pubDate>Thu, 01 Sep 2011 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-09-01-classical-mechanics-part-6/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2011/09/classical-mechanics-6-poisson-brackets.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Last time we saw that a classical mechanical system which has a Lagrangian formulation can (under some mild assumptions) be repackaged as a symplectic manifold \((M, \omega)\) together with a smooth function \(H\) called the Hamiltonian. The equations of motion then become&lt;/p&gt;&lt;p&gt;\[ \dot{x} = X_H \]&lt;/p&gt;&lt;p&gt;where \(X_H\) is the Hamiltonian vector field associated with \(H\) (sometimes called the symplectic gradient of \(H\)). This identifies solutions to the equations of motion with certain curves in the manifold \(M\), which together form a 1-parameter group of diffeomorphisms (in fact, symplectomorphisms) of \(M\).&lt;/p&gt;&lt;p&gt;Today, I&amp;rsquo;d like to discuss a dual formulation. Instead of thinking of the equations of motion as describing evolution of the points of \(M\), we will instead think of the equations of motion as describing evolution of the functions on \(M\). We will see later that this is the classical analog of the Heisenberg picture in quantum mechanics.&lt;/p&gt;&lt;p&gt;Definition An observable on \(M\) is a smooth real-valued function on \(M\).&lt;/p&gt;&lt;p&gt;Suppose we have a classical mechanical system \(M, \omega, H\). By integrating the equations of motion, we obtain a 1-parameter family of symplectomorphisms \(\phi_t\). For any point \(x \in M\), the curve \(x(t)\) defined by&lt;/p&gt;&lt;p&gt;\[ x(t) = \phi_t(x) \]&lt;/p&gt;&lt;p&gt;solved Hamilton&amp;rsquo;s equations.&lt;/p&gt;&lt;p&gt;Now suppose we have some observable \(f\). Its value along any solution to the equations of motion is&lt;/p&gt;&lt;p&gt;\[ f(x(t) = f(\phi_t(x)) = f_t(x) \]&lt;/p&gt;&lt;p&gt;where \(f_t := f \circ \phi_t\). So, if we only care about the values of observables along any solution to the equations of motion, the transformation&lt;/p&gt;&lt;p&gt;\[ x \mapsto x(t) = \phi_t(x) \]&lt;/p&gt;&lt;p&gt;\[ f \mapsto f \]&lt;/p&gt;&lt;p&gt;which is the Schrodinger picture, is indistinguishable from the transformation&lt;/p&gt;&lt;p&gt;\[ x \mapsto x \]&lt;/p&gt;&lt;p&gt;\[ f \mapsto f_t = f \circ \phi_t \]&lt;/p&gt;&lt;p&gt;which we will call the Heisenberg picture. What is the analog of Hamilton&amp;rsquo;s equations for the Heisenberg picture? Let us compute:&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} f_t = \frac{d}{dt}f(\phi_t) = df \circ \frac{d}{dt}\phi_t \]&lt;/p&gt;&lt;p&gt;Since \(\phi_t\) is generated by the vector field \(X_H\), we obtain&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} f_t = X_H(f) = df(X_H) = \omega^{-1}(dH, df) \]&lt;/p&gt;&lt;p&gt;For two observables \(f\) and \(g\), let us define the Poisson bracket of \(f\) and \(g\) as&lt;/p&gt;&lt;p&gt;\[ \{f, g\} := \omega^{-1}(df, dg). \]&lt;/p&gt;&lt;p&gt;Then we have&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} f_t = \{H, f_t \} \]&lt;/p&gt;&lt;p&gt;which is called the Heisenberg equation of motion.&lt;/p&gt;&lt;p&gt;Theorem The Poisson bracket \({\cdot, \cdot}\) satisfies the following properties:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;It is \(\mathbb{R}\)-linear and skew-symmetric.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It satisfies the Jacobi identity.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It satisfies the Leibniz rule \(\{fg,h\} = f\{g,h\} + \{f,h\}g\).&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Proof Too lazy for now! But it&amp;rsquo;s really easy.&lt;/p&gt;&lt;p&gt;Now let \(\mathscr{A} = C^\infty(M, \mathbb{R})\) be the commutative algebra of observables. This has an additional structure: the Poisson bracket \(\{,\}\), so we will call \(\mathscr{A}\) a Poisson algebra.&lt;/p&gt;&lt;p&gt;Now let us consider something completely crazy. Consider the following generalization of mechanical system.&lt;/p&gt;&lt;p&gt;Tentative Definition A mechanical system is an algebra \(\mathscr{A}\) together with a Poisson bracket \(\{\cdot, \cdot\}\) on \(\mathscr{A}\) and an element \(H \in \mathscr{A}\) called the Hamiltonian. The Heisenberg equations of motion are&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} f_t = \{H, f_t\} \]&lt;/p&gt;&lt;p&gt;for any \(f \in \mathscr{A}\).&lt;/p&gt;&lt;p&gt;This definition is a little too vague at the moment, since without specifying a topology on \(\mathscr{A}\) we have no way of making sense of the Heisenberg equation. However, up to this caveat, this definition of mechanical system captures the essence of all of classical mechanics, classical field theory, quantum mechanics, and quantum field theory!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 5</title>
       <link>https://jmf1sh.github.io/posts/2011-08-25-classical-mechanics-part-5/</link>
       <pubDate>Thu, 25 Aug 2011 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-25-classical-mechanics-part-5/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2011/08/classical-mechanics-5-symplectic.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;As we saw in the previous post, the equations of motion for a mechanical system can be cast into a 1st order form called Hamilton&amp;rsquo;s equations, which are naturally interpreted as describing a path in the phase space \(T^\ast M\) associated to the configuration space \(M\). Let us investigate the geometry of \(T^\ast M\) see why Hamilton&amp;rsquo;s equations are so nice.&lt;/p&gt;&lt;p&gt;Definition The canonical (or sometimes tautological) 1-form on the cotangent bundle \(T^\ast M\) is the 1-form \(\theta\) defined by&lt;/p&gt;&lt;p&gt;\[ \theta_{(q,p)}(X) = p(\pi_\ast X), \]&lt;/p&gt;&lt;p&gt;where \(\pi_\ast\) is the pushforward induced by the natural projection \(\pi: T^\ast M \to TM\). In other words, the form is defined by&lt;/p&gt;&lt;p&gt;\[ \theta_{(q,p)} = \pi^\ast p. \]&lt;/p&gt;&lt;p&gt;Definition The canonical symplectic form on the cotangent bundle \(T^\ast M\) is the 2-form \(\omega\) defined by&lt;/p&gt;&lt;p&gt;\[ \omega = -d\theta. \]&lt;/p&gt;&lt;p&gt;Let \(\omega_\flat: T M \to T^\ast M\) be the map given by \(X \mapsto \iota(X)\omega\).&lt;/p&gt;&lt;p&gt;Proposition The canonical symplectic form satisfies the following two conditions:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;It is closed, i.e. \(d\omega = 0\).&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;It is nondegenerate, i.e. the map \(\omega_\flat\) is invertible with inverse \(\omega^\sharp: T^\ast M \to TM\).&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Proof The first property follows from \(d^2 = 0\). To prove the second, suppose we have local coordinates \(q^i\) on \(M\) with cotangent coordinates \(p^i\). Then it is easily seen that&lt;/p&gt;&lt;p&gt;\[ \theta = p^i dq^i, \]&lt;/p&gt;&lt;p&gt;so that&lt;/p&gt;&lt;p&gt;\[ \omega = dq^i \wedge dp^i, \]&lt;/p&gt;&lt;p&gt;from which nondegeneracy is obvious.&lt;/p&gt;&lt;p&gt;Definition Any 2-form on a manifold \(N\) (not necessarily a cotangent bundle) which satisfies the above two properties will be called symplectic. A pair \((N, \omega)\) will be called symplectic if \(\omega\) is a symplectic 2-form on \(N\).&lt;/p&gt;&lt;p&gt;Definition Given a function \(H\) on a symplectic manifold \((N, \omega)\), the Hamiltonian vector field associated to \(H\) is the vector field \(X_H\) uniquely defined by&lt;/p&gt;&lt;p&gt;\[ dH = \omega_\flat X_H. \]&lt;/p&gt;&lt;p&gt;Proposition For \(N = T^\ast M\) a cotangent bundle with the canonical symplectic form, Hamilton&amp;rsquo;s equations with respect to a Hamiltonian function \(H\) describe the flow of the vector field \(X_H\).&lt;/p&gt;&lt;p&gt;Proof Again pick local coordinates \(q\) and \(p\). Then the inverse map \(\omega^\sharp\) is given by&lt;/p&gt;&lt;p&gt;\[ dq \mapsto -\frac{\partial}{\partial p} \]&lt;/p&gt;&lt;p&gt;\[ dp \mapsto \frac{\partial}{\partial q} \]&lt;/p&gt;&lt;p&gt;Since&lt;/p&gt;&lt;p&gt;\[ dH = \frac{\partial H}{\partial q} dq + \frac{\partial H}{\partial p} dp, \]&lt;/p&gt;&lt;p&gt;we see that&lt;/p&gt;&lt;p&gt;\[ X_H = \frac{\partial H}{\partial p} \frac{\partial}{\partial q} - \frac{\partial H}{\partial q} \frac{\partial}{\partial p} \]&lt;/p&gt;&lt;p&gt;But then the equation describing the flow of \(X_H\) is (in components)&lt;/p&gt;&lt;p&gt;\[ \dot{q} = \frac{\partial H}{\partial p} \]&lt;/p&gt;&lt;p&gt;\[ \dot{p} = -\frac{\partial H}{\partial q} \]&lt;/p&gt;&lt;p&gt;which are exactly Hamilton&amp;rsquo;s equations.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 4</title>
       <link>https://jmf1sh.github.io/posts/2011-08-23-classical-mechanics-part-4/</link>
       <pubDate>Tue, 23 Aug 2011 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-23-classical-mechanics-part-4/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2011/08/classical-mechanics-4-hamiltons.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Recall from last time that a classical mechanical system consists of a manifold \(M\) (the configuration space) and a function \(L\) on the tangent bundle \(TM\). The equations of motion for a path \(x(t)\) in \(M\) are the 2nd order Euler-Lagrange equations:&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}\left( \frac{\partial L}{\partial v}(x, \dot{x}) \right) = \frac{\partial L}{\partial x}(x, \dot{x}) \]&lt;/p&gt;&lt;p&gt;Hamilton discovered a way of recasting these equations as a first order system for a path in a related manifold, the cotangent bundle \(T^\ast M\). The benefits are twofold: in addition to reducing the equations to a first order system (at the cost of introducing new variables), it turns out that this framework makes it much easier to find conserved quantities and prove theorems about mechanical systems. So let&amp;rsquo;s see what he did.&lt;/p&gt;&lt;p&gt;Theorem Under mild assumptions on \(L\), there is a function \(H\) on \(T^\ast M\) constructed canonically out of \(L\) such that solutions of the Euler-Lagrange equations are in 1-1 correspondence with solutions \(q(t), p(t)\) on \(T^\ast M\) of Hamilton&amp;rsquo;s equations&lt;/p&gt;&lt;p&gt;\[ \dot{q} = \frac{\partial H}{\partial p}(q, p) \]&lt;/p&gt;&lt;p&gt;\[ \dot{p} = -\frac{\partial H}{\partial q}(q,p) \]&lt;/p&gt;&lt;p&gt;Furthermore, if the original Lagrangian function \(L\) is not explicitly time-dependent, then the function \(H\) is constant for any solution of the equations of motion.&lt;/p&gt;&lt;p&gt;To start with, introduce coordinates \(x, v\) on \(TM\) as before. We will define new coordinates \(q,p\) as follows:&lt;/p&gt;&lt;p&gt;\[ q(x,v) = x \]&lt;/p&gt;&lt;p&gt;\[ p(x,v) = \frac{\partial L}{\partial x}(x,v) \]&lt;/p&gt;&lt;p&gt;Our assumption on \(L\) will be the following: the above formulas can be inverted to obtain \(x\) and \(v\) as functions of \(q\) and \(p\). It is easily seen from the definition of \(p\) that under a coordinate transformation (of \(x\)), it behaves as a 1-form, so the coordinates \(q\) and \(p\) can be interpreted as local coordinates on the cotangent bundle \(T^\ast M\). We construct the Hamiltonian as&lt;/p&gt;&lt;p&gt;\[ H(q,p) = p\cdot v(q,p) - L(x(q,p), v(q,p)) \]&lt;/p&gt;&lt;p&gt;(this is the Legendre transform&amp;ndash;more later). Of course, the above formula is not well-defined if we cannot solve for \(x\) and \(v\) in terms of \(p\) and \(q\)&amp;ndash;hence the assumption. Now we check:&lt;/p&gt;&lt;p&gt;\[ \frac{\partial H}{\partial p} = v + p \frac{\partial v}{\partial p} - \frac{\partial L}{\partial x} \frac{\partial x}{\partial p} -\frac{\partial L}{\partial v}\frac{\partial v}{\partial p} = v + p\frac{\partial v}{\partial p} - p\frac{\partial v}{\partial p} = v\]&lt;/p&gt;&lt;p&gt;Since \(\dot{x} = v\), this is the first of Hamilton&amp;rsquo;s equations.&lt;/p&gt;&lt;p&gt;For the second, we perform a similar computation:&lt;/p&gt;&lt;p&gt;\[ \frac{\partial H}{\partial q} = -\frac{\partial L}{\partial x} \frac{\partial x}{\partial q} - \frac{\partial L}{\partial v} \frac{\partial v}{\partial q} = -\frac{\partial L}{\partial x} \]&lt;/p&gt;&lt;p&gt;But the Euler-Lagrange equations say that&lt;/p&gt;&lt;p&gt;\[ \dot{p} = \frac{d}{dt}\frac{\partial L}{\partial v} = \frac{\partial L}{\partial x} = -\frac{\partial H}{\partial x}, \]&lt;/p&gt;&lt;p&gt;so we&amp;rsquo;ve obtained the second of Hamilton&amp;rsquo;s equations.&lt;/p&gt;&lt;p&gt;For the last part, suppose that the Lagrangian does not depend explicitly on time, i.e.&lt;/p&gt;&lt;p&gt;\[ \frac{\partial L}{\partial t} = 0. \]&lt;/p&gt;&lt;p&gt;Then we compute:&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}H = \frac{\partial H}{\partial q}\dot{q} + \frac{\partial H}{\partial p}\dot{p} = \frac{\partial H}{\partial q} \frac{\partial H}{\partial p} - \frac{\partial H}{\partial p} \frac{\partial H}{\partial q} = 0. \]&lt;/p&gt;&lt;p&gt;Hence \(H\) is automatically conserved. For this reason, \(H\) is often called the energy of the system.&lt;/p&gt;&lt;p&gt;Later, we will see that conserved quantities correspond to symmetries, and conservation of energy is a statement about the symmetry corresponding to time translation.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 3</title>
       <link>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-3/</link>
       <pubDate>Fri, 19 Aug 2011 21:00:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-3/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2011/08/classical-mechanics-3-hamiltons-action.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;We saw before that Newton&amp;rsquo;s 2nd law can be written in a more general form as&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} \frac{\partial L}{\partial v}(x, \dot{x}) = \frac{\partial L}{\partial x}(x, \dot{x}), \]&lt;/p&gt;&lt;p&gt;known as the Euler-Lagrange equations. Hamilton discovered a principle that explains the origin of these equations. Consider some path of the system given by a curve \(\gamma\), i.e.&lt;/p&gt;&lt;p&gt;\[ x(t) = \gamma(t) \]&lt;/p&gt;&lt;p&gt;\[ \dot{x}(t) = \frac{d}{dt}\gamma(t) \]&lt;/p&gt;&lt;p&gt;Then we may define a quantity associated with the path \(\gamma\):&lt;/p&gt;&lt;p&gt;\[ S = \int L(\gamma, \dot{\gamma})dt \]&lt;/p&gt;&lt;p&gt;called the action. Hamilton discovered the following.&lt;/p&gt;&lt;p&gt;Theorem The path taken by a mechanical system is one which extremizes the action.&lt;/p&gt;&lt;p&gt;To prove this, suppose we perturb the path a small amount, while leaving the endpoints fixed, i.e. \(\gamma \mapsto \gamma + \epsilon (\delta\gamma)\) with \(\epsilon &amp;gt; 0\) small and \(\delta\gamma\) a path that is \(0\) at its endpoints. Then&lt;/p&gt;&lt;p&gt;\[ L(\gamma + \epsilon\delta\gamma, \dot\gamma + \epsilon\delta\dot{\gamma}) = L(\gamma, \dot{\gamma}) + \epsilon \frac{\partial L}{\partial x}\delta\gamma + \epsilon \frac{\partial L}{\partial v} \delta\dot\gamma + o(\epsilon^2) \]&lt;/p&gt;&lt;p&gt;Thus&lt;/p&gt;&lt;p&gt;\[ S[\gamma + \epsilon\delta\gamma] = S[\gamma] + \epsilon \int \frac{\partial L}{\partial x} \delta \gamma dt + \epsilon \int \frac{\partial L}{\partial v} \delta \dot\gamma dt + o(\epsilon^2) \]&lt;/p&gt;&lt;p&gt;Integrating by parts, and using the fact that \(\delta\gamma\) is \(0\) on the endpoints, we have&lt;/p&gt;&lt;p&gt;\[ \int \frac{\partial L}{\partial v}\delta\dot\gamma dt = -\int \frac{d}{dt} \frac{\partial L}{\partial v} \delta\gamma dt \]&lt;/p&gt;&lt;p&gt;Combining the above, we have&lt;/p&gt;&lt;p&gt;\[ \frac{\delta S}{\delta \gamma}(\delta \gamma) = \int \left(\frac{\partial L}{\partial x} - \frac{d}{dt}\frac{\partial L}{\partial v} \right) \delta\gamma dt \]&lt;/p&gt;&lt;p&gt;Thus the variational derivative of \(S\) is&lt;/p&gt;&lt;p&gt;\[ \frac{\delta S}{\delta \gamma} = \frac{\partial L}{\partial x} - \frac{d}{dt} \frac{\partial L}{\partial v} \]&lt;/p&gt;&lt;p&gt;So a path \(\gamma\) is a critical point of \(S\) (i.e. it extremizes \(S\)) if and only if the Euler-Lagrange equations are satisfied.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 2</title>
       <link>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-2/</link>
       <pubDate>Fri, 19 Aug 2011 15:00:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-2/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2011/08/classical-mechanics-2-euler-lagrange.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;After the previous post, we are now familiar with Newton&amp;rsquo;s 2nd law&lt;/p&gt;&lt;p&gt;\[ \mathbf{F} = m\mathbf{a}, \]&lt;/p&gt;&lt;p&gt;which (suitably interpreted) holds for any system of \(N\) particles. However, this equation requires the use of cartesian coordinates, which for many systems may not be the most convenient choice. Suppose we have some other coordinates \(q^i = q^i(x^j)\). What is the correct analogue of Newton&amp;rsquo;s 2nd law for the \(q\)-coordinates?&lt;/p&gt;&lt;p&gt;To make life easier, we will assume for now that the force \(\mathbf{F}\) is conservative; i.e.&lt;/p&gt;&lt;p&gt;\[ \mathbf{F} = -\nabla V(x) \]&lt;/p&gt;&lt;p&gt;for some potential function \(V(x)\). Under this assumption, Newton&amp;rsquo;s 2nd law is&lt;/p&gt;&lt;p&gt;\[ m\mathbf{a} + \nabla V(x) = 0. \]&lt;/p&gt;&lt;p&gt;Let us define the function \(T\) by&lt;/p&gt;&lt;p&gt;\[ T(x,v) = \frac{1}{2}m |v|^2, \]&lt;/p&gt;&lt;p&gt;and define the function \(L\) as&lt;/p&gt;&lt;p&gt;\[ L(x,v) = T(x,v) - V(x). \]&lt;/p&gt;&lt;p&gt;Then we have immediately that Newton&amp;rsquo;s 2nd law is equivalent to&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}\frac{\partial L}{\partial v}(x, \dot{x}) - \frac{\partial L}{\partial x}(x,\dot{x})  = 0. \]&lt;/p&gt;&lt;p&gt;Why go through the trouble of introducing these auxiliary functions and rewriting Newton&amp;rsquo;s 2nd law in this way? The answer lies in the following theorem.&lt;/p&gt;&lt;p&gt;Theorem For any choice of coordinates \(y = y(x)\), Newton&amp;rsquo;s 2nd law is equivalent to the equations&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}\frac{\partial \tilde{L}}{\partial w}(y, \dot{y}) - \frac{\partial \tilde{L}}{\partial y}(y,\dot{y})  = 0, \]&lt;/p&gt;&lt;p&gt;where \(w = dY_x(v)\) and \(\tilde{L}(y,w) = L(x(y,w), v(y,w)\). These equations are called the Euler-Lagrange equations.&lt;/p&gt;&lt;p&gt;The proof of this theorem is a straightforward calculation using the chain rule. Let \(M\) denote the manifold \(\mathbb{R}^{3N}\) (or some open subset thereof). The coordinate change \(y = y(x) \) can be thought of as a diffeomorphism \(Y: M \to M\) given by \(x \mapsto y(x) \). The differential \( dY: TM \to TM\) is also a diffeomorphism. In coordinates, we have&lt;/p&gt;&lt;p&gt;\[ y = y(x) \]&lt;/p&gt;&lt;p&gt;\[ w = dY_x(v)  = Jv \]&lt;/p&gt;&lt;p&gt;where \(y,w\) are coordinates on the target \(TM\).&lt;/p&gt;&lt;p&gt;Now we need to compute the derivatives of \(\tilde{L}\).&lt;/p&gt;&lt;p&gt;\[ \frac{\partial L}{\partial x} = \frac{\partial \tilde{L}}{\partial y}\frac{\partial y}{\partial x} + \frac{\partial \tilde{L}}{\partial w}\frac{\partial w}{\partial x} = \tilde{L}_y J + \tilde{L}_w H v \]&lt;/p&gt;&lt;p&gt;where \(J\) is the matrix of mixed partials and \(H\) is the Hessian matrix.&lt;/p&gt;&lt;p&gt;\[ \frac{\partial L}{\partial v} = \frac{\partial \tilde{L}}{\partial y} \frac{\partial y}{\partial v} + \frac{\partial \tilde{L}}{\partial w} \frac{\partial w}{\partial v} = \tilde{L}_w J \]&lt;/p&gt;&lt;p&gt;Then we have&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}\left( \tilde{L}_w J \right) = \frac{d}{dt}\tilde{L}_w J + \tilde{L}_w H \dot{x}  \]&lt;/p&gt;&lt;p&gt;Subtracting \(\frac{\partial L}{\partial x}\) from this and using the calculation above, we obtain&lt;/p&gt;&lt;p&gt;\[ \left( \frac{d}{dt} \tilde{L}_w - \tilde{L}_y \right) J \]&lt;/p&gt;&lt;p&gt;and since \(J\) is invertible, this is \(0\) if and only if \(\frac{d}{dt} \tilde{L}_w - \tilde{L}_y\) is.&lt;/p&gt;&lt;p&gt;But this is exactly what we wanted to prove!&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Classical mechanics, part 1</title>
       <link>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-1/</link>
       <pubDate>Fri, 19 Aug 2011 09:00:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-1/</guid>
       <description>&lt;p&gt;Articles in this series&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-1/&#34;&gt;Part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-2/&#34;&gt;Part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-3/&#34;&gt;Part 3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-23-classical-mechanics-part-4/&#34;&gt;Part 4&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-25-classical-mechanics-part-5/&#34;&gt;Part 5&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-09-01-classical-mechanics-part-6/&#34;&gt;Part 6&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;This is a surpisingly hard topic, and someday I would like to make an honest attempt at it. But Feynman did it better than I ever could! See &amp;ldquo;What is a Force?&amp;rdquo; from the Feynman Lectures on Physics, available here: here &lt;a href=&#34;http://strangebeautiful.com/other-texts/feynman-phys-lects-1_12.pdf&#34;&gt;pdf&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I promise to update eventually.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Updated outline</title>
       <link>https://jmf1sh.github.io/posts/2011-08-17-updated-outline/</link>
       <pubDate>Wed, 17 Aug 2011 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2011-08-17-updated-outline/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the&lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I was thinking about how to put this blog to use, and especially how to make itworthwhile for myself. In 2010, I ran a learning seminar on math/physics whichin my opinion was extremely successful. I made detailed notes for nearly all ofthe talks, and I had several people ask me at the end of the seminar to givethem copies of the notes I had made. We managed to do something very special inthe seminar, and I think it&amp;rsquo;s worth writing up notes from the best talks (andreorganizing/elaborating/etc. when necessary) and putting them online for all tosee. It gives me a chance to practice my math writing, and if I ever run anotherseminar of this flavor (or teach a course, or write a book&amp;hellip;) then a lot of thework will already be done for me.&lt;/p&gt;&lt;p&gt;Here is a rough outline of the topics we covered (or that need to be covered asbackground):&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Classical mechanics and symplectic geometry&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2010-01-08-hyperkaehler-reduction/&#34;&gt;Hyperkähler reduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2010-01-27-legendre-transform/&#34;&gt;Legendre transform&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-1/&#34;&gt;Classical mechanics, part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-2/&#34;&gt;Classical mechanics, part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-19-classical-mechanics-part-3/&#34;&gt;Classical mechanics, part 3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-23-classical-mechanics-part-4/&#34;&gt;Classical mechanics, part 4&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-08-25-classical-mechanics-part-5/&#34;&gt;Classical mechanics, part 5&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-09-01-classical-mechanics-part-6/&#34;&gt;Classical mechanics, part 6&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2015-08-18-classical-partition-function/&#34;&gt;Classical partition function&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-29-equations-of-motion-noether/&#34;&gt;Noether&amp;rsquo;s theorem&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-07-26-generating-functions/&#34;&gt;Generating functions for symplectomorphisms&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Completely integrable systems.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-07-23-kam-1/&#34;&gt;KAM theory&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Special relativity.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Classical field theory.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Classical electrodynamics.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;General relativity&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-01-19-geometry-of-spacetime-part-1/&#34;&gt;Geometry of spacetime, part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-01-26-geometry-of-spacetime-part-2/&#34;&gt;Geometry of spacetime, part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-02-04-geometry-of-spacetime-part-3/&#34;&gt;Geometry of spacetime, part 3&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-02-06-geometry-of-spacetime-part-4/&#34;&gt;Geometry of spacetime, part 4&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-02-25-geometry-of-spacetime-part-5/&#34;&gt;Geometry of spacetime, part 5&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Quantization (canonical, deformation, geometric, etc.)&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2011-11-12-lattice-quantum-mechanics-1d/&#34;&gt;Lattice quantum mechanics&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-22-quantum-hamiltonian-reduction/&#34;&gt;Quantum Hamiltonian reduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-24-moyal-product/&#34;&gt;Moyal product&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-12-13-weyl-wigner-transform/&#34;&gt;Weyl-Wigner transform&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Path integrals in quantum mechanics.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-01-16-path-integrals-part-1/&#34;&gt;Path integrals, part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-2/&#34;&gt;Path integrals, part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-02-04-path-integrals-part-3/&#34;&gt;Path integrals, part 3&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Perturbation theory and Feynman diagrams.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-03-03-introduction-to-gaussian/&#34;&gt;Introduction to Gaussian integrals&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-03-03-gaussian-integrals-wick/&#34;&gt;Gaussian integrals and Wick&amp;rsquo;s theorem&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Feynman rules for QED.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Berezin integration and quantization of fermionic fields.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Gauge fields.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Clifford algebras and spin&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-05-clifford-algebras-part-1/&#34;&gt;Clifford algebras, part 1&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-06-clifford-algebras-part-2/&#34;&gt;Clifford algebras, part 2&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-03-18-clifford-algebras-part-3/&#34;&gt;Clifford algebras, part 3&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;BRST quantization and related topics&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-12-23-brst/&#34;&gt;BRST&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-12-28-brst-lie-algebra/&#34;&gt;BRST Lie algebra&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-12-21-fadeev-popov-ghosts/&#34;&gt;Fadeev-Popov ghosts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-12-23-fadeev-popov-ghosts-continued/&#34;&gt;Fadeev-Popov ghosts, continued&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-05-14-quantum-bv-complex/&#34;&gt;Quantum BV complex&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Path integral proof of the index theorem&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Additional topics in quantum field theory&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-05-spontaneous-symmetry-breaking-qft/&#34;&gt;Spontaneous symmetry breaking&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-10-22-seiberg-witten-video-lectures/&#34;&gt;Lectures on Seiberg-Witten theory&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-10-29-bps-wall-crossing/&#34;&gt;BPS and wall-crossing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-04-seiberg-witten-riemann-hilbert/&#34;&gt;Seiberg-Witten theory and Riemann-Hilbert correspondance&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-11-07-1pi-effective-action/&#34;&gt;1PI effective action&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Virasoro algebra and CFT&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2012-07-13-circle-diffeomorphisms-1/&#34;&gt;Circle diffeomorphisms&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-02-23-virasoro-algebra/&#34;&gt;Virasoro algebra&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&#34;https://jmf1sh.github.io/posts/2014-12-11-virasoro-algebra-free-boson/&#34;&gt;Virasoro algebra for a free boson&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;As you can see, it was an ambitious seminar! I will update the outline as I gothrough my old notes and start posting them.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Legendre transform</title>
       <link>https://jmf1sh.github.io/posts/2010-01-27-legendre-transform/</link>
       <pubDate>Wed, 27 Jan 2010 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2010-01-27-legendre-transform/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;. The original post can still be found &lt;a href=&#34;https://mathphysseminar.blogspot.com/2010/01/legendre-transform.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yesterday, I gave an introductory talk on Hamiltonian mechanics and symplectic geometry. The starting point is the Legendre transform. First, begin with a configuration space \(Q\). The Lagrangian \(\mathcal{L}\) is a smooth function on \(TQ\). In local coordinates \(q^i\) on \(Q\), we have coordinates \((q_i, v_i)\) on \(TQ\), where the \(v^i\) are the components of the tangent vector&lt;/p&gt;&lt;p&gt;\(v = v_i \partial_i \in T_q Q\). Typically, the Lagrangian will be of the form&lt;/p&gt;&lt;p&gt;\[ \mathcal{L}(q,v) = \frac{1}{2} g(v,v) - V(q), \]&lt;/p&gt;&lt;p&gt;where \(g\) is some metric on \(Q\). Now we introduce new coordinates \(p_i\) defined by&lt;/p&gt;&lt;p&gt;\[ p_i = \frac{\partial \mathcal{L}}{\partial v^i}. \]&lt;/p&gt;&lt;p&gt;If \(\mathcal{L}\) is (strictly?) convex in \(v\) then we can solve for \(v^i\) as a function of \((q^i, p_j)\). It is easy to check that the \(p_i\) transform as covectors, and so this gives a diffeomorphism \(TQ \to T^\ast Q\)(which depends on \(\mathcal{L}\)). For example, in the above Lagrangian,&lt;/p&gt;&lt;p&gt;\[ \frac{\partial \mathcal{L}}{\partial v} = g(v, -), \]&lt;/p&gt;&lt;p&gt;which is just the dual of \(v\) with respect to the metric \(g\). So for Lagrangians of this form, the map \(TQ \to T^\ast Q\) is just the one given by the metric.&lt;/p&gt;&lt;p&gt;Now comes the interesting part. There is a natural way to turn \(\mathcal{L}\), which is a function on \(TQ\), into a function \(H\) on \(T^\ast Q\), in such a way that if we repeat this process, we will get back the original function \(\mathcal{L}\) on \(TQ\). This is the Legendre transform:&lt;/p&gt;&lt;p&gt;\[ \mathcal{H} = pv - L. \]&lt;/p&gt;&lt;p&gt;Now suppose we have a curve \(q(t), \dot{q}(t) \in TQ\) that satisfies the Euler-Lagrange equations. Then by the identification \(TQ = T^\ast Q\), this gives a curve \((q(t), p(t)) \in T^\ast Q\). What equation does it satisfy? We have&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt} p = \frac{d}{dt} \frac{\partial \mathcal{L}}{\partial v} = \frac{\partial \mathcal{L}}{\partial q} = -\frac{\partial H}{\partial q}, \]&lt;/p&gt;&lt;p&gt;and&lt;/p&gt;&lt;p&gt;\[ \frac{d}{dt}q = v = \frac{\partial H}{\partial p}. \]&lt;/p&gt;&lt;p&gt;These are Hamilton&amp;rsquo;s equations, and they say that the curve \(\gamma = (q(t), p(t)) \in T^\ast Q\) is just an integral curve of the symplectic gradient of \(H\)! So classical mechanics is really just about flows of Hamiltonian vector fields on symplectic manifolds.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Hyperkahler reduction</title>
       <link>https://jmf1sh.github.io/posts/2010-01-08-hyperkaehler-reduction/</link>
       <pubDate>Fri, 08 Jan 2010 00:00:00 -0500</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2010-01-08-hyperkaehler-reduction/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Yesterday I gave a talk on hyperkahler reduction&amp;ndash;my first invited talk ever. I thought I should summarize it here.&lt;/p&gt;&lt;p&gt;A hyperkahler manifold is just a Kahler manifold \( (M, g, I)\) together with two additional integrable complex structures \(J,K\) such that \(I,J,K\) satisfy the quaternion relations, and \(J\) and \(K\) are compatible with the metric. Hyperkahler manifolds are modeled on \(\mathbb{H}^n\), analogous to the way that Kahler manifolds are modeled on \(\mathbb{C}^n\)&lt;/p&gt;&lt;p&gt;When \(G\) acts on a Kahler manifold \(M\) preserving the Kahler structure, then (under relatively weak&lt;/p&gt;&lt;p&gt;hypotheses) a momentum map exists and we can use this to define a quotient \(M//G\), which turns out to be Kahler. Similarly, if \(M\) is hyperkahler and \(G\) preserves the hyperkahler structure, then we have a hyperkahler quotient \(M///G\).&lt;/p&gt;&lt;p&gt;So far I haven&amp;rsquo;t said anything interesting. There are two basic questions: (1) do any interesting manifolds actually arise in this way? and (2) what theorems about symplectic/Kahler quotients have analogues in hyperkahler quotients?&lt;/p&gt;&lt;p&gt;It turns out that question (1) is related to the Yang-Mills equations over \(\mathbb{R}^4\). (Of course, \(\mathbb{R}^4 = \mathbb{H}\), so maybe this is not that surprising, since moduli spaces love to inherit geometry from their parents). Depending on choices of Lagrangian, base manifold, etc. you get different moduli spaces of solutions. In general, these moduli spaces are given as quotients of infinite dimensional spaces of connections by the action of some infinite dimensional Lie group of gauge transformations. In 4-dimensions, this frequently turns out to be an infinite-dimensional hyperkahler quotient! In fact, it turns out that the Yang-Mills functional is very closely related to the momentum map for the action of the gauge transformations. Even more surprisingly, there are cases where this infinite-dimensional quotient can be expressed as a finite-dimensional quotient (see, e.g., the ADHM construction). In the case of the ADHM construction, the space you get is actually just the quotient of \(\mathbb{H}^n\) by a linear action (i.e. a group of matrices). So it turns out that even mere linear actions give you lots of interesting geometry, and lots of questions about these are still open.&lt;/p&gt;&lt;p&gt;Question (2) is close to my own research interests. The hyperkahler quotient is similar to but different from the symplectic quotient. In symplectic quotients, the most basic tool we have is Morse theory using the momentum map. In hyperkahler geometry, we have 3 moment maps, and it&amp;rsquo;s not obvious what to do with them. Frequently, we encode them as a pair \((\mu_\mathbb{R}, \mu_\mathbb{C})\), where&lt;/p&gt;&lt;p&gt;\[ \mu_\mathbb{R} = \mu_1 \]&lt;/p&gt;&lt;p&gt;\[ \mu_\mathbb{C} = \mu_2 + i \mu_3 \]&lt;/p&gt;&lt;p&gt;It turns out that \(\mu_\mathbb{C}\) is holomorphic, and the corresponding form \(\omega_\mathbb{C} = \omega_2 + i \omega_3\) is holomorphic symplectic. It&amp;rsquo;s not really clear what the best way of packaging the momentum maps is, and this is an important question because we would like to do Morse theory in some way using the momentum maps.&lt;/p&gt;&lt;p&gt;This leads to one possible way of bypassing these problems. Penrose introduced the idea of twistor spaces. A hyperkahler manifold has a lot of data: \(g, I, J, K, \omega_1, \omega_2, \omega_3\) with lots of relations. But there is an interesting symmetry: if \((x_1, x_2, x_3) \in S^2\), then \(I_x = x_1 I + x_2 J + x_3 K\) turns out to be another integrable complex structure. So in fact we have an \(S^2\) family of Kahler structures. But \(S^2 = \mathbb{CP}^1\), which is complex (and in fact Kahler), so we have a Kahler family of Kahler structures. Since everything in question is complex, why not try to encode our data holomorphically?&lt;/p&gt;&lt;p&gt;The twisor construction does just that. For \(Z = M \times \mathbb{CP}^1\). Give it the (almost) complex structure \(I = (I_x, I_0)\) where \(I_0\) is the complex structure on \(\mathbb{CP}^1\). One can check (using the Newlander-Nirenberg theorem) that \(I\) is integrable, so \(Z\) is a complex manifold (and, importantly, is not just the product \(M \times \mathbb{CP}^1\) as a complex manifold). Now we need to put some holomorphic data on \(Z\).&lt;/p&gt;&lt;p&gt;First, we have the projection \(p: Z \to \mathbb{CP}^1\). This is holomorphic and makes \(Z\) a fiber bundle over \(\mathbb{CP}^1\).&lt;/p&gt;&lt;p&gt;Second, we need the symplectic forms. Let \(T_F\) be the vertical subbundle of the tangent bundle to \(Z\). Let \(\zeta\) be a complex coordinate on \(\mathbb{CP}^1\) Now define&lt;/p&gt;&lt;p&gt;\[ \omega = (\omega_2 + i\omega_3) + 2\zeta \omega_1 - \zeta^2 (\omega_2 - i\omega_3).\]&lt;/p&gt;&lt;p&gt;This definition makes sense at least locally, and it makes sense globally thinking of \(\omega\) as a holomorphic seciton of \(\Lambda^2 T_F^\ast \otimes p^\ast O(2)\). It is also symplectic along the fibers.&lt;/p&gt;&lt;p&gt;The third piece of data we need are the &amp;ldquo;twistor lines&amp;rdquo;. Given a point \(m \in M\), the map \(\zeta \mapsto (m, \zeta)\) is a holomorphic section of \(Z\). The normal bundle to any such section turns out to be holomorphically equivalent to \(\mathbb{C}^{2n} \otimes O(1)\).&lt;/p&gt;&lt;p&gt;The last piece of data is a real structure \(\tau\) on \(Z\). We can define it by \(\tau(m,\zeta) = (m, \bar{\zeta}^{-1})\). This is an antiholomorphic involution. It is also compatible with 1-3 in a sense that I won&amp;rsquo;t describe.&lt;/p&gt;&lt;p&gt;It is a theorem that these 4 pieces of data are all we need to recover M and its hyperkahler structure. (For proof, see Hitchin et al., &amp;ldquo;Hyperkahler metrics and supersymmetry&amp;rdquo;.) This might seem like a convoluted construction, but the essential point is that the hyperkahler structure is encoded as holomorphic data on \(Z\)(the only piece data which is not holomorphic is the real structure \(\tau\)), and holomorphic things are very rigid and easier to work with.&lt;/p&gt;&lt;p&gt;In the twistor language, hyperkahler quotients correspond to a kind of twistor holomorphic symplectic quotient. Maybe this is the right way to think about things. Who knows?&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>Fist day of 2010</title>
       <link>https://jmf1sh.github.io/posts/2010-01-04-first-day-of-2010/</link>
       <pubDate>Mon, 04 Jan 2010 09:26:00 +0000</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2010-01-04-first-day-of-2010/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;It&amp;rsquo;s the first (academic) day of 2010. I figured that the best use of this blog is as a log&amp;ndash;that is, to log and plan my work for the semester/year/life. If you want to accomplish goals, the fist thing to do is to write them down! So here we go, crude outline for the next semester:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Work through Milnor&amp;rsquo;s Morse theory book, cover to cover. This should be easy since I&amp;rsquo;m taking a class in morse theory anyway.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Work through Kirwan&amp;rsquo;s thesis cover to cover. I&amp;rsquo;ve already been through quite a bit of it, and the only things that caused me any trouble last summer have since been cleared up.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Work though Gulliemin and Sternberg&amp;rsquo;s Equivariant cohomology book. Again, quite a bit of the material I already know, so this should be doable.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Finish working through HKLR. Really the only remaining part is supersymmetric nonlinear sigma models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The details of the ADHM construction, once and for all. I should know this already.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Hilbert schemes of points on a surface. Really, the hyperkahler metric for the scheme of points on \(\mathbb{C}^2\). Again, I should know this already.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;We&amp;rsquo;ll see how these go&amp;ndash;this is probably ambitious, and many of these will get extended into the summer.&lt;/p&gt;</description>
     </item>
   
     <item>
       <title>In the beginning...</title>
       <link>https://jmf1sh.github.io/posts/2008-08-09-in-the-beginning/</link>
       <pubDate>Sat, 09 Aug 2008 00:00:00 -0400</pubDate>
       
       <guid>https://jmf1sh.github.io/posts/2008-08-09-in-the-beginning/</guid>
       <description>&lt;p&gt;This post has been migrated from my old blog, the &lt;a href=&#34;https://mathphysseminar.blogspot.com/&#34;&gt;math-physics learning seminar&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Well this is the first post. I&amp;rsquo;m on the tail end of a MSc right now, and set to start my PhD in the fall, so I thought it might be interesting to document my (probable) descent into madness. I had thought about doing this at the beginning of my MSc, but I guess I never got around to it. Much of this blog will focus on my own studies/progress, as well as happenings at my university, but I don&amp;rsquo;t plan on trying too hard to keep it strictly academic. We&amp;rsquo;ll see how it goes.&lt;/p&gt;</description>
     </item>
   
 </channel>
</rss>
