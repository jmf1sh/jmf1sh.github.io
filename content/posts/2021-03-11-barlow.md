---
title: "Barlow Twins"
date: 2021-03-11
draft: false
---

Let's try to understand [Barlow twins: self-supervised learning via redundancy reduction](https://arxiv.org/abs/2103.03230).

![barlow training](/img/2021-03-11-barlow-fig-1.png)

The general setup is fairly simple, and similar to BYOL and SimCLR (todo: references). For a given training example $X$, we have a random process $\mathcal{Y}_X$
that allows us to sample different "views"  $Y \sim \mathcal{Y}_X$. In the simplest setting, the training examples consist of images, and we have a fixed random distribution of augmentations and transformations $\mathcal{T}$. In this case the views are defined by $Y = T(X)$ with the transformation $T \sim \mathcal{T}$.

Now suppose that we have a differentiable model $f_\theta$. The goal is for $f_\theta$ to extract a semantically meaningful representation from the samples $Y \mathcal{Y}_X$, which is invariant (i.e. $f_\theta(Y)$ for $Y \sim \mathcal{Y}_X$ should depend only on $X$ and not on the particular sample $Y$). In the case of image transformations and augmentations, we would like $f(T(X)) \approx f_\theta(T'(X))$ for $T, T' \sim \mathcal{T}$. The challenge is to find interesting solutions to this problem.

(nonsense about InfoNCE, MoCo, SimCLR, BYOL, SimCLRv2)

The innovation of BT is the introduction of a new loss function. Let $Y^A$ and $Y^B$ be two views of an example $X$. Denote by $Z^A$ and $Z^B$ the corresponding values of $f_\theta$. We define a cross-correlation matrix $\mathcal{C}_{ij}$ by
$$
\mathcal{C}_{ij} = \frac{\sum_b z^A_{b,i} z^B_{b,j}}{\sqrt{\sum_b(z^A_{b,i})^2} \sqrt{\sum_b(z^A_{b,i})^2} }
$$
Then the BT loss is defined as
$$
\mathcal{L_{BT}} = \sum_i (1-\mathcal{C}_{ii})^2 + \lambda \sum_i \sum_{j \neq i} \mathcal{C}_{ij}^2
$$
to be continued...